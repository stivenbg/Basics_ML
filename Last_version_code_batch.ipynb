{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPlE/GVlEyChoX0hbgIN1/h",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/stivenbg/Basics_ML/blob/main/Last_version_code_batch.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fYms68cAGp4X"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "HGwwZPAVGwbA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "e0dLYg1WGwd0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import pandas as pd\n",
        "from torch.autograd import Variable\n",
        "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n"
      ],
      "metadata": {
        "id": "bEWq1yKoGwgr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Ici je loads mes data eta issue de simulation\n",
        "from google.colab import files\n",
        "uploaded = files.upload()\n",
        "import io\n",
        "df = pd.read_excel(io.BytesIO(uploaded['eta_401_simulations.xlsx']))\n",
        "print(df);\n",
        "eta=df.loc[:,:].to_numpy()\n",
        "eta = np.insert(eta, 0, 0.075857, axis=0)\n",
        "eta=Variable(torch.from_numpy(eta).float(), requires_grad=False).to(device)\n",
        "eta = eta.reshape(401, 30) #On réorganise éta par batch size\n",
        "eta.shape\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 333
        },
        "id": "ZBLh6nvwH5bW",
        "outputId": "fffa1caf-5a60-4ec0-ec9e-a84f8db90da6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-ea45b40a-e2d6-45ca-a309-d0d00764c302\" name=\"files[]\" multiple disabled\n",
              "        style=\"border:none\" />\n",
              "     <output id=\"result-ea45b40a-e2d6-45ca-a309-d0d00764c302\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script>// Copyright 2017 Google LLC\n",
              "//\n",
              "// Licensed under the Apache License, Version 2.0 (the \"License\");\n",
              "// you may not use this file except in compliance with the License.\n",
              "// You may obtain a copy of the License at\n",
              "//\n",
              "//      http://www.apache.org/licenses/LICENSE-2.0\n",
              "//\n",
              "// Unless required by applicable law or agreed to in writing, software\n",
              "// distributed under the License is distributed on an \"AS IS\" BASIS,\n",
              "// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
              "// See the License for the specific language governing permissions and\n",
              "// limitations under the License.\n",
              "\n",
              "/**\n",
              " * @fileoverview Helpers for google.colab Python module.\n",
              " */\n",
              "(function(scope) {\n",
              "function span(text, styleAttributes = {}) {\n",
              "  const element = document.createElement('span');\n",
              "  element.textContent = text;\n",
              "  for (const key of Object.keys(styleAttributes)) {\n",
              "    element.style[key] = styleAttributes[key];\n",
              "  }\n",
              "  return element;\n",
              "}\n",
              "\n",
              "// Max number of bytes which will be uploaded at a time.\n",
              "const MAX_PAYLOAD_SIZE = 100 * 1024;\n",
              "\n",
              "function _uploadFiles(inputId, outputId) {\n",
              "  const steps = uploadFilesStep(inputId, outputId);\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  // Cache steps on the outputElement to make it available for the next call\n",
              "  // to uploadFilesContinue from Python.\n",
              "  outputElement.steps = steps;\n",
              "\n",
              "  return _uploadFilesContinue(outputId);\n",
              "}\n",
              "\n",
              "// This is roughly an async generator (not supported in the browser yet),\n",
              "// where there are multiple asynchronous steps and the Python side is going\n",
              "// to poll for completion of each step.\n",
              "// This uses a Promise to block the python side on completion of each step,\n",
              "// then passes the result of the previous step as the input to the next step.\n",
              "function _uploadFilesContinue(outputId) {\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  const steps = outputElement.steps;\n",
              "\n",
              "  const next = steps.next(outputElement.lastPromiseValue);\n",
              "  return Promise.resolve(next.value.promise).then((value) => {\n",
              "    // Cache the last promise value to make it available to the next\n",
              "    // step of the generator.\n",
              "    outputElement.lastPromiseValue = value;\n",
              "    return next.value.response;\n",
              "  });\n",
              "}\n",
              "\n",
              "/**\n",
              " * Generator function which is called between each async step of the upload\n",
              " * process.\n",
              " * @param {string} inputId Element ID of the input file picker element.\n",
              " * @param {string} outputId Element ID of the output display.\n",
              " * @return {!Iterable<!Object>} Iterable of next steps.\n",
              " */\n",
              "function* uploadFilesStep(inputId, outputId) {\n",
              "  const inputElement = document.getElementById(inputId);\n",
              "  inputElement.disabled = false;\n",
              "\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  outputElement.innerHTML = '';\n",
              "\n",
              "  const pickedPromise = new Promise((resolve) => {\n",
              "    inputElement.addEventListener('change', (e) => {\n",
              "      resolve(e.target.files);\n",
              "    });\n",
              "  });\n",
              "\n",
              "  const cancel = document.createElement('button');\n",
              "  inputElement.parentElement.appendChild(cancel);\n",
              "  cancel.textContent = 'Cancel upload';\n",
              "  const cancelPromise = new Promise((resolve) => {\n",
              "    cancel.onclick = () => {\n",
              "      resolve(null);\n",
              "    };\n",
              "  });\n",
              "\n",
              "  // Wait for the user to pick the files.\n",
              "  const files = yield {\n",
              "    promise: Promise.race([pickedPromise, cancelPromise]),\n",
              "    response: {\n",
              "      action: 'starting',\n",
              "    }\n",
              "  };\n",
              "\n",
              "  cancel.remove();\n",
              "\n",
              "  // Disable the input element since further picks are not allowed.\n",
              "  inputElement.disabled = true;\n",
              "\n",
              "  if (!files) {\n",
              "    return {\n",
              "      response: {\n",
              "        action: 'complete',\n",
              "      }\n",
              "    };\n",
              "  }\n",
              "\n",
              "  for (const file of files) {\n",
              "    const li = document.createElement('li');\n",
              "    li.append(span(file.name, {fontWeight: 'bold'}));\n",
              "    li.append(span(\n",
              "        `(${file.type || 'n/a'}) - ${file.size} bytes, ` +\n",
              "        `last modified: ${\n",
              "            file.lastModifiedDate ? file.lastModifiedDate.toLocaleDateString() :\n",
              "                                    'n/a'} - `));\n",
              "    const percent = span('0% done');\n",
              "    li.appendChild(percent);\n",
              "\n",
              "    outputElement.appendChild(li);\n",
              "\n",
              "    const fileDataPromise = new Promise((resolve) => {\n",
              "      const reader = new FileReader();\n",
              "      reader.onload = (e) => {\n",
              "        resolve(e.target.result);\n",
              "      };\n",
              "      reader.readAsArrayBuffer(file);\n",
              "    });\n",
              "    // Wait for the data to be ready.\n",
              "    let fileData = yield {\n",
              "      promise: fileDataPromise,\n",
              "      response: {\n",
              "        action: 'continue',\n",
              "      }\n",
              "    };\n",
              "\n",
              "    // Use a chunked sending to avoid message size limits. See b/62115660.\n",
              "    let position = 0;\n",
              "    do {\n",
              "      const length = Math.min(fileData.byteLength - position, MAX_PAYLOAD_SIZE);\n",
              "      const chunk = new Uint8Array(fileData, position, length);\n",
              "      position += length;\n",
              "\n",
              "      const base64 = btoa(String.fromCharCode.apply(null, chunk));\n",
              "      yield {\n",
              "        response: {\n",
              "          action: 'append',\n",
              "          file: file.name,\n",
              "          data: base64,\n",
              "        },\n",
              "      };\n",
              "\n",
              "      let percentDone = fileData.byteLength === 0 ?\n",
              "          100 :\n",
              "          Math.round((position / fileData.byteLength) * 100);\n",
              "      percent.textContent = `${percentDone}% done`;\n",
              "\n",
              "    } while (position < fileData.byteLength);\n",
              "  }\n",
              "\n",
              "  // All done.\n",
              "  yield {\n",
              "    response: {\n",
              "      action: 'complete',\n",
              "    }\n",
              "  };\n",
              "}\n",
              "\n",
              "scope.google = scope.google || {};\n",
              "scope.google.colab = scope.google.colab || {};\n",
              "scope.google.colab._files = {\n",
              "  _uploadFiles,\n",
              "  _uploadFilesContinue,\n",
              "};\n",
              "})(self);\n",
              "</script> "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saving eta_401_simulations.xlsx to eta_401_simulations (5).xlsx\n",
            "       0.075857\n",
            "0      0.007478\n",
            "1      0.008593\n",
            "2      0.007291\n",
            "3     -0.002083\n",
            "4      0.029796\n",
            "...         ...\n",
            "12024  0.062115\n",
            "12025  0.016604\n",
            "12026 -0.007365\n",
            "12027 -0.021277\n",
            "12028 -0.103011\n",
            "\n",
            "[12029 rows x 1 columns]\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([401, 30])"
            ]
          },
          "metadata": {},
          "execution_count": 40
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Ici je loads mes data matrice de contrainte\n",
        "from google.colab import files\n",
        "uploaded = files.upload()\n",
        "import io\n",
        "df = pd.read_excel(io.BytesIO(uploaded['B_30_5_ok.xlsx']))\n",
        "print(df);\n",
        "B=df.loc[:,:].to_numpy() #Operateur projection defini par representants de riezs et modes propres\n",
        "B=Variable(torch.from_numpy(B).float(), requires_grad=False).to(device)  "
      ],
      "metadata": {
        "id": "yIyQfiwLTzX6",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 611
        },
        "outputId": "8ad6ec34-037d-4665-8d99-9f4d4dc1925e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-f0e68c47-102b-49dd-8d14-4ad8ed4bb2e1\" name=\"files[]\" multiple disabled\n",
              "        style=\"border:none\" />\n",
              "     <output id=\"result-f0e68c47-102b-49dd-8d14-4ad8ed4bb2e1\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script>// Copyright 2017 Google LLC\n",
              "//\n",
              "// Licensed under the Apache License, Version 2.0 (the \"License\");\n",
              "// you may not use this file except in compliance with the License.\n",
              "// You may obtain a copy of the License at\n",
              "//\n",
              "//      http://www.apache.org/licenses/LICENSE-2.0\n",
              "//\n",
              "// Unless required by applicable law or agreed to in writing, software\n",
              "// distributed under the License is distributed on an \"AS IS\" BASIS,\n",
              "// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
              "// See the License for the specific language governing permissions and\n",
              "// limitations under the License.\n",
              "\n",
              "/**\n",
              " * @fileoverview Helpers for google.colab Python module.\n",
              " */\n",
              "(function(scope) {\n",
              "function span(text, styleAttributes = {}) {\n",
              "  const element = document.createElement('span');\n",
              "  element.textContent = text;\n",
              "  for (const key of Object.keys(styleAttributes)) {\n",
              "    element.style[key] = styleAttributes[key];\n",
              "  }\n",
              "  return element;\n",
              "}\n",
              "\n",
              "// Max number of bytes which will be uploaded at a time.\n",
              "const MAX_PAYLOAD_SIZE = 100 * 1024;\n",
              "\n",
              "function _uploadFiles(inputId, outputId) {\n",
              "  const steps = uploadFilesStep(inputId, outputId);\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  // Cache steps on the outputElement to make it available for the next call\n",
              "  // to uploadFilesContinue from Python.\n",
              "  outputElement.steps = steps;\n",
              "\n",
              "  return _uploadFilesContinue(outputId);\n",
              "}\n",
              "\n",
              "// This is roughly an async generator (not supported in the browser yet),\n",
              "// where there are multiple asynchronous steps and the Python side is going\n",
              "// to poll for completion of each step.\n",
              "// This uses a Promise to block the python side on completion of each step,\n",
              "// then passes the result of the previous step as the input to the next step.\n",
              "function _uploadFilesContinue(outputId) {\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  const steps = outputElement.steps;\n",
              "\n",
              "  const next = steps.next(outputElement.lastPromiseValue);\n",
              "  return Promise.resolve(next.value.promise).then((value) => {\n",
              "    // Cache the last promise value to make it available to the next\n",
              "    // step of the generator.\n",
              "    outputElement.lastPromiseValue = value;\n",
              "    return next.value.response;\n",
              "  });\n",
              "}\n",
              "\n",
              "/**\n",
              " * Generator function which is called between each async step of the upload\n",
              " * process.\n",
              " * @param {string} inputId Element ID of the input file picker element.\n",
              " * @param {string} outputId Element ID of the output display.\n",
              " * @return {!Iterable<!Object>} Iterable of next steps.\n",
              " */\n",
              "function* uploadFilesStep(inputId, outputId) {\n",
              "  const inputElement = document.getElementById(inputId);\n",
              "  inputElement.disabled = false;\n",
              "\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  outputElement.innerHTML = '';\n",
              "\n",
              "  const pickedPromise = new Promise((resolve) => {\n",
              "    inputElement.addEventListener('change', (e) => {\n",
              "      resolve(e.target.files);\n",
              "    });\n",
              "  });\n",
              "\n",
              "  const cancel = document.createElement('button');\n",
              "  inputElement.parentElement.appendChild(cancel);\n",
              "  cancel.textContent = 'Cancel upload';\n",
              "  const cancelPromise = new Promise((resolve) => {\n",
              "    cancel.onclick = () => {\n",
              "      resolve(null);\n",
              "    };\n",
              "  });\n",
              "\n",
              "  // Wait for the user to pick the files.\n",
              "  const files = yield {\n",
              "    promise: Promise.race([pickedPromise, cancelPromise]),\n",
              "    response: {\n",
              "      action: 'starting',\n",
              "    }\n",
              "  };\n",
              "\n",
              "  cancel.remove();\n",
              "\n",
              "  // Disable the input element since further picks are not allowed.\n",
              "  inputElement.disabled = true;\n",
              "\n",
              "  if (!files) {\n",
              "    return {\n",
              "      response: {\n",
              "        action: 'complete',\n",
              "      }\n",
              "    };\n",
              "  }\n",
              "\n",
              "  for (const file of files) {\n",
              "    const li = document.createElement('li');\n",
              "    li.append(span(file.name, {fontWeight: 'bold'}));\n",
              "    li.append(span(\n",
              "        `(${file.type || 'n/a'}) - ${file.size} bytes, ` +\n",
              "        `last modified: ${\n",
              "            file.lastModifiedDate ? file.lastModifiedDate.toLocaleDateString() :\n",
              "                                    'n/a'} - `));\n",
              "    const percent = span('0% done');\n",
              "    li.appendChild(percent);\n",
              "\n",
              "    outputElement.appendChild(li);\n",
              "\n",
              "    const fileDataPromise = new Promise((resolve) => {\n",
              "      const reader = new FileReader();\n",
              "      reader.onload = (e) => {\n",
              "        resolve(e.target.result);\n",
              "      };\n",
              "      reader.readAsArrayBuffer(file);\n",
              "    });\n",
              "    // Wait for the data to be ready.\n",
              "    let fileData = yield {\n",
              "      promise: fileDataPromise,\n",
              "      response: {\n",
              "        action: 'continue',\n",
              "      }\n",
              "    };\n",
              "\n",
              "    // Use a chunked sending to avoid message size limits. See b/62115660.\n",
              "    let position = 0;\n",
              "    do {\n",
              "      const length = Math.min(fileData.byteLength - position, MAX_PAYLOAD_SIZE);\n",
              "      const chunk = new Uint8Array(fileData, position, length);\n",
              "      position += length;\n",
              "\n",
              "      const base64 = btoa(String.fromCharCode.apply(null, chunk));\n",
              "      yield {\n",
              "        response: {\n",
              "          action: 'append',\n",
              "          file: file.name,\n",
              "          data: base64,\n",
              "        },\n",
              "      };\n",
              "\n",
              "      let percentDone = fileData.byteLength === 0 ?\n",
              "          100 :\n",
              "          Math.round((position / fileData.byteLength) * 100);\n",
              "      percent.textContent = `${percentDone}% done`;\n",
              "\n",
              "    } while (position < fileData.byteLength);\n",
              "  }\n",
              "\n",
              "  // All done.\n",
              "  yield {\n",
              "    response: {\n",
              "      action: 'complete',\n",
              "    }\n",
              "  };\n",
              "}\n",
              "\n",
              "scope.google = scope.google || {};\n",
              "scope.google.colab = scope.google.colab || {};\n",
              "scope.google.colab._files = {\n",
              "  _uploadFiles,\n",
              "  _uploadFilesContinue,\n",
              "};\n",
              "})(self);\n",
              "</script> "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saving B_30_5_ok.xlsx to B_30_5_ok (2).xlsx\n",
            "    Unnamed: 0  Unnamed: 1  Unnamed: 2  Unnamed: 3  Unnamed: 4\n",
            "0    -0.110060    1.020169    0.311766    0.014873   -0.024188\n",
            "1    -0.372461    1.044086    0.036917   -0.159778    0.041253\n",
            "2     0.298699    1.019386    0.039257    0.129416   -0.008978\n",
            "3    -0.507648    1.058045    0.152694    0.106740   -0.059194\n",
            "4    -0.249714    1.043524   -0.127728   -0.153658   -0.084113\n",
            "5     0.342856    1.010514   -0.152502   -0.173049   -0.017911\n",
            "6     0.446141    0.974297    0.308551   -0.140721   -0.139692\n",
            "7    -0.178723    1.055231   -0.042378    0.109208    0.102030\n",
            "8    -0.403799    1.040744    0.234490    0.022484   -0.094341\n",
            "9     0.114555    1.015554    0.043995   -0.140372    0.033644\n",
            "10    0.004232    1.033354    0.036413    0.050552    0.017288\n",
            "11   -0.465335    1.057225    0.024900   -0.056785    0.064558\n",
            "12    0.490161    0.994504    0.168576   -0.004098    0.055137\n",
            "13   -0.298811    1.061329   -0.226609    0.003781   -0.098267\n",
            "14   -0.089554    1.028879   -0.035904   -0.168590   -0.040010\n",
            "15   -0.128796    1.046925   -0.050564    0.074798   -0.015974\n",
            "16    0.523696    1.012252   -0.154971    0.047387   -0.029987\n",
            "17    0.423352    1.010921   -0.224759   -0.122791   -0.087244\n",
            "18   -0.057811    1.011759    0.202001   -0.157552   -0.082534\n",
            "19    0.160444    1.010447    0.234592    0.076458   -0.088988\n",
            "20    0.131526    0.987057    0.334439   -0.223837   -0.125115\n",
            "21    0.235239    1.007074    0.181766    0.046997   -0.099919\n",
            "22    0.273972    1.015578   -0.106493   -0.071546   -0.092761\n",
            "23    0.193834    1.010925    0.112284   -0.069528    0.035315\n",
            "24    0.303438    1.006692    0.204776    0.036008    0.087631\n",
            "25    0.256984    1.007850    0.088790   -0.074476    0.021104\n",
            "26    0.431998    1.016185   -0.083501    0.105284   -0.053408\n",
            "27   -0.101736    1.023248    0.107599   -0.184989    0.075694\n",
            "28   -0.113038    1.015669    0.171465   -0.150813   -0.130144\n",
            "29    0.087140    1.020567   -0.025962   -0.112652   -0.053293\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "mu=torch.arange(2, 10.02, 0.02).reshape(-1, 1) # mu va de 1 à 12 paer pas de 0.05"
      ],
      "metadata": {
        "id": "kqGp6LinMoKQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class Net(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(Net, self).__init__()\n",
        "        self.fc1 = nn.Linear(1, 10)\n",
        "        self.tanh = nn.Tanh()\n",
        "        self.fc2 = nn.Linear(10,10)\n",
        "        self.fc3 = nn.Linear(10, 30)\n",
        "\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.fc1(x)\n",
        "        x = self.tanh(x)\n",
        "        x = self.fc2(x)\n",
        "        x = self.tanh(x)\n",
        "        x = self.fc3(x)\n",
        "        x = self.tanh(x)\n",
        "        return x\n"
      ],
      "metadata": {
        "id": "c42pvPLwV08-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "loss_values = []\n",
        "grad_values = []\n",
        "loss=2000\n",
        "\n",
        "\n",
        "model = Net()\n",
        "criterion = nn.MSELoss()\n",
        "optimizer = torch.optim.SGD(model.parameters(), lr=0.0005)\n",
        "\n",
        "\n",
        "for epoch in range(10000):\n",
        "    outputs = model(mu)\n",
        "    loss = criterion(outputs, eta)\n",
        "    loss_values.append(loss.item())\n",
        "\n",
        "    optimizer.zero_grad()\n",
        "    loss.backward()\n",
        "    grad_sum=0\n",
        "\n",
        "    for param in model.parameters():\n",
        "      grad_sum +=param.grad.norm()\n",
        "    grad_values.append(grad_sum.item())\n",
        "    optimizer.step()\n",
        "\n",
        "    with torch.autograd.no_grad():\n",
        "          # Append the current loss value to the loss_values list\n",
        "      loss_values.append(loss.data)\n",
        "      print(epoch,\"Traning Loss:\",loss.data)\n",
        "\n",
        "\n",
        "    #if (epoch+1) % 10 == 0:\n",
        "     #   print ('Epoch [{}/{}], Loss: {:.4f}'.format(epoch+1, 100, loss.item()))\n",
        "\n",
        "plt.plot(loss_values)\n",
        "plt.xlabel(\"Epochs\")\n",
        "plt.ylabel(\"Loss\")\n",
        "\n",
        "#plt.plot(grad_values)\n",
        "#plt.xlabel(\"Epochs\")\n",
        "#plt.ylabel(\"Gradients\")\n",
        "\n",
        "plt.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "_5j_tE_GG9h0",
        "outputId": "38feb525-6fe3-41fc-d6d1-6b09fb5e9072"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1;30;43mLe flux de sortie a été tronqué et ne contient que les 5000 dernières lignes.\u001b[0m\n",
            "5000 Traning Loss: tensor(0.0368)\n",
            "5001 Traning Loss: tensor(0.0368)\n",
            "5002 Traning Loss: tensor(0.0368)\n",
            "5003 Traning Loss: tensor(0.0368)\n",
            "5004 Traning Loss: tensor(0.0368)\n",
            "5005 Traning Loss: tensor(0.0368)\n",
            "5006 Traning Loss: tensor(0.0368)\n",
            "5007 Traning Loss: tensor(0.0368)\n",
            "5008 Traning Loss: tensor(0.0368)\n",
            "5009 Traning Loss: tensor(0.0368)\n",
            "5010 Traning Loss: tensor(0.0368)\n",
            "5011 Traning Loss: tensor(0.0368)\n",
            "5012 Traning Loss: tensor(0.0368)\n",
            "5013 Traning Loss: tensor(0.0368)\n",
            "5014 Traning Loss: tensor(0.0368)\n",
            "5015 Traning Loss: tensor(0.0368)\n",
            "5016 Traning Loss: tensor(0.0368)\n",
            "5017 Traning Loss: tensor(0.0367)\n",
            "5018 Traning Loss: tensor(0.0367)\n",
            "5019 Traning Loss: tensor(0.0367)\n",
            "5020 Traning Loss: tensor(0.0367)\n",
            "5021 Traning Loss: tensor(0.0367)\n",
            "5022 Traning Loss: tensor(0.0367)\n",
            "5023 Traning Loss: tensor(0.0367)\n",
            "5024 Traning Loss: tensor(0.0367)\n",
            "5025 Traning Loss: tensor(0.0367)\n",
            "5026 Traning Loss: tensor(0.0367)\n",
            "5027 Traning Loss: tensor(0.0367)\n",
            "5028 Traning Loss: tensor(0.0367)\n",
            "5029 Traning Loss: tensor(0.0367)\n",
            "5030 Traning Loss: tensor(0.0367)\n",
            "5031 Traning Loss: tensor(0.0367)\n",
            "5032 Traning Loss: tensor(0.0367)\n",
            "5033 Traning Loss: tensor(0.0367)\n",
            "5034 Traning Loss: tensor(0.0367)\n",
            "5035 Traning Loss: tensor(0.0367)\n",
            "5036 Traning Loss: tensor(0.0367)\n",
            "5037 Traning Loss: tensor(0.0367)\n",
            "5038 Traning Loss: tensor(0.0367)\n",
            "5039 Traning Loss: tensor(0.0367)\n",
            "5040 Traning Loss: tensor(0.0367)\n",
            "5041 Traning Loss: tensor(0.0366)\n",
            "5042 Traning Loss: tensor(0.0366)\n",
            "5043 Traning Loss: tensor(0.0366)\n",
            "5044 Traning Loss: tensor(0.0366)\n",
            "5045 Traning Loss: tensor(0.0366)\n",
            "5046 Traning Loss: tensor(0.0366)\n",
            "5047 Traning Loss: tensor(0.0366)\n",
            "5048 Traning Loss: tensor(0.0366)\n",
            "5049 Traning Loss: tensor(0.0366)\n",
            "5050 Traning Loss: tensor(0.0366)\n",
            "5051 Traning Loss: tensor(0.0366)\n",
            "5052 Traning Loss: tensor(0.0366)\n",
            "5053 Traning Loss: tensor(0.0366)\n",
            "5054 Traning Loss: tensor(0.0366)\n",
            "5055 Traning Loss: tensor(0.0366)\n",
            "5056 Traning Loss: tensor(0.0366)\n",
            "5057 Traning Loss: tensor(0.0366)\n",
            "5058 Traning Loss: tensor(0.0366)\n",
            "5059 Traning Loss: tensor(0.0366)\n",
            "5060 Traning Loss: tensor(0.0366)\n",
            "5061 Traning Loss: tensor(0.0366)\n",
            "5062 Traning Loss: tensor(0.0366)\n",
            "5063 Traning Loss: tensor(0.0366)\n",
            "5064 Traning Loss: tensor(0.0366)\n",
            "5065 Traning Loss: tensor(0.0366)\n",
            "5066 Traning Loss: tensor(0.0365)\n",
            "5067 Traning Loss: tensor(0.0365)\n",
            "5068 Traning Loss: tensor(0.0365)\n",
            "5069 Traning Loss: tensor(0.0365)\n",
            "5070 Traning Loss: tensor(0.0365)\n",
            "5071 Traning Loss: tensor(0.0365)\n",
            "5072 Traning Loss: tensor(0.0365)\n",
            "5073 Traning Loss: tensor(0.0365)\n",
            "5074 Traning Loss: tensor(0.0365)\n",
            "5075 Traning Loss: tensor(0.0365)\n",
            "5076 Traning Loss: tensor(0.0365)\n",
            "5077 Traning Loss: tensor(0.0365)\n",
            "5078 Traning Loss: tensor(0.0365)\n",
            "5079 Traning Loss: tensor(0.0365)\n",
            "5080 Traning Loss: tensor(0.0365)\n",
            "5081 Traning Loss: tensor(0.0365)\n",
            "5082 Traning Loss: tensor(0.0365)\n",
            "5083 Traning Loss: tensor(0.0365)\n",
            "5084 Traning Loss: tensor(0.0365)\n",
            "5085 Traning Loss: tensor(0.0365)\n",
            "5086 Traning Loss: tensor(0.0365)\n",
            "5087 Traning Loss: tensor(0.0365)\n",
            "5088 Traning Loss: tensor(0.0365)\n",
            "5089 Traning Loss: tensor(0.0365)\n",
            "5090 Traning Loss: tensor(0.0364)\n",
            "5091 Traning Loss: tensor(0.0364)\n",
            "5092 Traning Loss: tensor(0.0364)\n",
            "5093 Traning Loss: tensor(0.0364)\n",
            "5094 Traning Loss: tensor(0.0364)\n",
            "5095 Traning Loss: tensor(0.0364)\n",
            "5096 Traning Loss: tensor(0.0364)\n",
            "5097 Traning Loss: tensor(0.0364)\n",
            "5098 Traning Loss: tensor(0.0364)\n",
            "5099 Traning Loss: tensor(0.0364)\n",
            "5100 Traning Loss: tensor(0.0364)\n",
            "5101 Traning Loss: tensor(0.0364)\n",
            "5102 Traning Loss: tensor(0.0364)\n",
            "5103 Traning Loss: tensor(0.0364)\n",
            "5104 Traning Loss: tensor(0.0364)\n",
            "5105 Traning Loss: tensor(0.0364)\n",
            "5106 Traning Loss: tensor(0.0364)\n",
            "5107 Traning Loss: tensor(0.0364)\n",
            "5108 Traning Loss: tensor(0.0364)\n",
            "5109 Traning Loss: tensor(0.0364)\n",
            "5110 Traning Loss: tensor(0.0364)\n",
            "5111 Traning Loss: tensor(0.0364)\n",
            "5112 Traning Loss: tensor(0.0364)\n",
            "5113 Traning Loss: tensor(0.0364)\n",
            "5114 Traning Loss: tensor(0.0364)\n",
            "5115 Traning Loss: tensor(0.0363)\n",
            "5116 Traning Loss: tensor(0.0363)\n",
            "5117 Traning Loss: tensor(0.0363)\n",
            "5118 Traning Loss: tensor(0.0363)\n",
            "5119 Traning Loss: tensor(0.0363)\n",
            "5120 Traning Loss: tensor(0.0363)\n",
            "5121 Traning Loss: tensor(0.0363)\n",
            "5122 Traning Loss: tensor(0.0363)\n",
            "5123 Traning Loss: tensor(0.0363)\n",
            "5124 Traning Loss: tensor(0.0363)\n",
            "5125 Traning Loss: tensor(0.0363)\n",
            "5126 Traning Loss: tensor(0.0363)\n",
            "5127 Traning Loss: tensor(0.0363)\n",
            "5128 Traning Loss: tensor(0.0363)\n",
            "5129 Traning Loss: tensor(0.0363)\n",
            "5130 Traning Loss: tensor(0.0363)\n",
            "5131 Traning Loss: tensor(0.0363)\n",
            "5132 Traning Loss: tensor(0.0363)\n",
            "5133 Traning Loss: tensor(0.0363)\n",
            "5134 Traning Loss: tensor(0.0363)\n",
            "5135 Traning Loss: tensor(0.0363)\n",
            "5136 Traning Loss: tensor(0.0363)\n",
            "5137 Traning Loss: tensor(0.0363)\n",
            "5138 Traning Loss: tensor(0.0363)\n",
            "5139 Traning Loss: tensor(0.0363)\n",
            "5140 Traning Loss: tensor(0.0362)\n",
            "5141 Traning Loss: tensor(0.0362)\n",
            "5142 Traning Loss: tensor(0.0362)\n",
            "5143 Traning Loss: tensor(0.0362)\n",
            "5144 Traning Loss: tensor(0.0362)\n",
            "5145 Traning Loss: tensor(0.0362)\n",
            "5146 Traning Loss: tensor(0.0362)\n",
            "5147 Traning Loss: tensor(0.0362)\n",
            "5148 Traning Loss: tensor(0.0362)\n",
            "5149 Traning Loss: tensor(0.0362)\n",
            "5150 Traning Loss: tensor(0.0362)\n",
            "5151 Traning Loss: tensor(0.0362)\n",
            "5152 Traning Loss: tensor(0.0362)\n",
            "5153 Traning Loss: tensor(0.0362)\n",
            "5154 Traning Loss: tensor(0.0362)\n",
            "5155 Traning Loss: tensor(0.0362)\n",
            "5156 Traning Loss: tensor(0.0362)\n",
            "5157 Traning Loss: tensor(0.0362)\n",
            "5158 Traning Loss: tensor(0.0362)\n",
            "5159 Traning Loss: tensor(0.0362)\n",
            "5160 Traning Loss: tensor(0.0362)\n",
            "5161 Traning Loss: tensor(0.0362)\n",
            "5162 Traning Loss: tensor(0.0362)\n",
            "5163 Traning Loss: tensor(0.0362)\n",
            "5164 Traning Loss: tensor(0.0362)\n",
            "5165 Traning Loss: tensor(0.0362)\n",
            "5166 Traning Loss: tensor(0.0361)\n",
            "5167 Traning Loss: tensor(0.0361)\n",
            "5168 Traning Loss: tensor(0.0361)\n",
            "5169 Traning Loss: tensor(0.0361)\n",
            "5170 Traning Loss: tensor(0.0361)\n",
            "5171 Traning Loss: tensor(0.0361)\n",
            "5172 Traning Loss: tensor(0.0361)\n",
            "5173 Traning Loss: tensor(0.0361)\n",
            "5174 Traning Loss: tensor(0.0361)\n",
            "5175 Traning Loss: tensor(0.0361)\n",
            "5176 Traning Loss: tensor(0.0361)\n",
            "5177 Traning Loss: tensor(0.0361)\n",
            "5178 Traning Loss: tensor(0.0361)\n",
            "5179 Traning Loss: tensor(0.0361)\n",
            "5180 Traning Loss: tensor(0.0361)\n",
            "5181 Traning Loss: tensor(0.0361)\n",
            "5182 Traning Loss: tensor(0.0361)\n",
            "5183 Traning Loss: tensor(0.0361)\n",
            "5184 Traning Loss: tensor(0.0361)\n",
            "5185 Traning Loss: tensor(0.0361)\n",
            "5186 Traning Loss: tensor(0.0361)\n",
            "5187 Traning Loss: tensor(0.0361)\n",
            "5188 Traning Loss: tensor(0.0361)\n",
            "5189 Traning Loss: tensor(0.0361)\n",
            "5190 Traning Loss: tensor(0.0361)\n",
            "5191 Traning Loss: tensor(0.0360)\n",
            "5192 Traning Loss: tensor(0.0360)\n",
            "5193 Traning Loss: tensor(0.0360)\n",
            "5194 Traning Loss: tensor(0.0360)\n",
            "5195 Traning Loss: tensor(0.0360)\n",
            "5196 Traning Loss: tensor(0.0360)\n",
            "5197 Traning Loss: tensor(0.0360)\n",
            "5198 Traning Loss: tensor(0.0360)\n",
            "5199 Traning Loss: tensor(0.0360)\n",
            "5200 Traning Loss: tensor(0.0360)\n",
            "5201 Traning Loss: tensor(0.0360)\n",
            "5202 Traning Loss: tensor(0.0360)\n",
            "5203 Traning Loss: tensor(0.0360)\n",
            "5204 Traning Loss: tensor(0.0360)\n",
            "5205 Traning Loss: tensor(0.0360)\n",
            "5206 Traning Loss: tensor(0.0360)\n",
            "5207 Traning Loss: tensor(0.0360)\n",
            "5208 Traning Loss: tensor(0.0360)\n",
            "5209 Traning Loss: tensor(0.0360)\n",
            "5210 Traning Loss: tensor(0.0360)\n",
            "5211 Traning Loss: tensor(0.0360)\n",
            "5212 Traning Loss: tensor(0.0360)\n",
            "5213 Traning Loss: tensor(0.0360)\n",
            "5214 Traning Loss: tensor(0.0360)\n",
            "5215 Traning Loss: tensor(0.0360)\n",
            "5216 Traning Loss: tensor(0.0360)\n",
            "5217 Traning Loss: tensor(0.0359)\n",
            "5218 Traning Loss: tensor(0.0359)\n",
            "5219 Traning Loss: tensor(0.0359)\n",
            "5220 Traning Loss: tensor(0.0359)\n",
            "5221 Traning Loss: tensor(0.0359)\n",
            "5222 Traning Loss: tensor(0.0359)\n",
            "5223 Traning Loss: tensor(0.0359)\n",
            "5224 Traning Loss: tensor(0.0359)\n",
            "5225 Traning Loss: tensor(0.0359)\n",
            "5226 Traning Loss: tensor(0.0359)\n",
            "5227 Traning Loss: tensor(0.0359)\n",
            "5228 Traning Loss: tensor(0.0359)\n",
            "5229 Traning Loss: tensor(0.0359)\n",
            "5230 Traning Loss: tensor(0.0359)\n",
            "5231 Traning Loss: tensor(0.0359)\n",
            "5232 Traning Loss: tensor(0.0359)\n",
            "5233 Traning Loss: tensor(0.0359)\n",
            "5234 Traning Loss: tensor(0.0359)\n",
            "5235 Traning Loss: tensor(0.0359)\n",
            "5236 Traning Loss: tensor(0.0359)\n",
            "5237 Traning Loss: tensor(0.0359)\n",
            "5238 Traning Loss: tensor(0.0359)\n",
            "5239 Traning Loss: tensor(0.0359)\n",
            "5240 Traning Loss: tensor(0.0359)\n",
            "5241 Traning Loss: tensor(0.0359)\n",
            "5242 Traning Loss: tensor(0.0359)\n",
            "5243 Traning Loss: tensor(0.0359)\n",
            "5244 Traning Loss: tensor(0.0358)\n",
            "5245 Traning Loss: tensor(0.0358)\n",
            "5246 Traning Loss: tensor(0.0358)\n",
            "5247 Traning Loss: tensor(0.0358)\n",
            "5248 Traning Loss: tensor(0.0358)\n",
            "5249 Traning Loss: tensor(0.0358)\n",
            "5250 Traning Loss: tensor(0.0358)\n",
            "5251 Traning Loss: tensor(0.0358)\n",
            "5252 Traning Loss: tensor(0.0358)\n",
            "5253 Traning Loss: tensor(0.0358)\n",
            "5254 Traning Loss: tensor(0.0358)\n",
            "5255 Traning Loss: tensor(0.0358)\n",
            "5256 Traning Loss: tensor(0.0358)\n",
            "5257 Traning Loss: tensor(0.0358)\n",
            "5258 Traning Loss: tensor(0.0358)\n",
            "5259 Traning Loss: tensor(0.0358)\n",
            "5260 Traning Loss: tensor(0.0358)\n",
            "5261 Traning Loss: tensor(0.0358)\n",
            "5262 Traning Loss: tensor(0.0358)\n",
            "5263 Traning Loss: tensor(0.0358)\n",
            "5264 Traning Loss: tensor(0.0358)\n",
            "5265 Traning Loss: tensor(0.0358)\n",
            "5266 Traning Loss: tensor(0.0358)\n",
            "5267 Traning Loss: tensor(0.0358)\n",
            "5268 Traning Loss: tensor(0.0358)\n",
            "5269 Traning Loss: tensor(0.0358)\n",
            "5270 Traning Loss: tensor(0.0357)\n",
            "5271 Traning Loss: tensor(0.0357)\n",
            "5272 Traning Loss: tensor(0.0357)\n",
            "5273 Traning Loss: tensor(0.0357)\n",
            "5274 Traning Loss: tensor(0.0357)\n",
            "5275 Traning Loss: tensor(0.0357)\n",
            "5276 Traning Loss: tensor(0.0357)\n",
            "5277 Traning Loss: tensor(0.0357)\n",
            "5278 Traning Loss: tensor(0.0357)\n",
            "5279 Traning Loss: tensor(0.0357)\n",
            "5280 Traning Loss: tensor(0.0357)\n",
            "5281 Traning Loss: tensor(0.0357)\n",
            "5282 Traning Loss: tensor(0.0357)\n",
            "5283 Traning Loss: tensor(0.0357)\n",
            "5284 Traning Loss: tensor(0.0357)\n",
            "5285 Traning Loss: tensor(0.0357)\n",
            "5286 Traning Loss: tensor(0.0357)\n",
            "5287 Traning Loss: tensor(0.0357)\n",
            "5288 Traning Loss: tensor(0.0357)\n",
            "5289 Traning Loss: tensor(0.0357)\n",
            "5290 Traning Loss: tensor(0.0357)\n",
            "5291 Traning Loss: tensor(0.0357)\n",
            "5292 Traning Loss: tensor(0.0357)\n",
            "5293 Traning Loss: tensor(0.0357)\n",
            "5294 Traning Loss: tensor(0.0357)\n",
            "5295 Traning Loss: tensor(0.0357)\n",
            "5296 Traning Loss: tensor(0.0357)\n",
            "5297 Traning Loss: tensor(0.0356)\n",
            "5298 Traning Loss: tensor(0.0356)\n",
            "5299 Traning Loss: tensor(0.0356)\n",
            "5300 Traning Loss: tensor(0.0356)\n",
            "5301 Traning Loss: tensor(0.0356)\n",
            "5302 Traning Loss: tensor(0.0356)\n",
            "5303 Traning Loss: tensor(0.0356)\n",
            "5304 Traning Loss: tensor(0.0356)\n",
            "5305 Traning Loss: tensor(0.0356)\n",
            "5306 Traning Loss: tensor(0.0356)\n",
            "5307 Traning Loss: tensor(0.0356)\n",
            "5308 Traning Loss: tensor(0.0356)\n",
            "5309 Traning Loss: tensor(0.0356)\n",
            "5310 Traning Loss: tensor(0.0356)\n",
            "5311 Traning Loss: tensor(0.0356)\n",
            "5312 Traning Loss: tensor(0.0356)\n",
            "5313 Traning Loss: tensor(0.0356)\n",
            "5314 Traning Loss: tensor(0.0356)\n",
            "5315 Traning Loss: tensor(0.0356)\n",
            "5316 Traning Loss: tensor(0.0356)\n",
            "5317 Traning Loss: tensor(0.0356)\n",
            "5318 Traning Loss: tensor(0.0356)\n",
            "5319 Traning Loss: tensor(0.0356)\n",
            "5320 Traning Loss: tensor(0.0356)\n",
            "5321 Traning Loss: tensor(0.0356)\n",
            "5322 Traning Loss: tensor(0.0356)\n",
            "5323 Traning Loss: tensor(0.0356)\n",
            "5324 Traning Loss: tensor(0.0355)\n",
            "5325 Traning Loss: tensor(0.0355)\n",
            "5326 Traning Loss: tensor(0.0355)\n",
            "5327 Traning Loss: tensor(0.0355)\n",
            "5328 Traning Loss: tensor(0.0355)\n",
            "5329 Traning Loss: tensor(0.0355)\n",
            "5330 Traning Loss: tensor(0.0355)\n",
            "5331 Traning Loss: tensor(0.0355)\n",
            "5332 Traning Loss: tensor(0.0355)\n",
            "5333 Traning Loss: tensor(0.0355)\n",
            "5334 Traning Loss: tensor(0.0355)\n",
            "5335 Traning Loss: tensor(0.0355)\n",
            "5336 Traning Loss: tensor(0.0355)\n",
            "5337 Traning Loss: tensor(0.0355)\n",
            "5338 Traning Loss: tensor(0.0355)\n",
            "5339 Traning Loss: tensor(0.0355)\n",
            "5340 Traning Loss: tensor(0.0355)\n",
            "5341 Traning Loss: tensor(0.0355)\n",
            "5342 Traning Loss: tensor(0.0355)\n",
            "5343 Traning Loss: tensor(0.0355)\n",
            "5344 Traning Loss: tensor(0.0355)\n",
            "5345 Traning Loss: tensor(0.0355)\n",
            "5346 Traning Loss: tensor(0.0355)\n",
            "5347 Traning Loss: tensor(0.0355)\n",
            "5348 Traning Loss: tensor(0.0355)\n",
            "5349 Traning Loss: tensor(0.0355)\n",
            "5350 Traning Loss: tensor(0.0355)\n",
            "5351 Traning Loss: tensor(0.0354)\n",
            "5352 Traning Loss: tensor(0.0354)\n",
            "5353 Traning Loss: tensor(0.0354)\n",
            "5354 Traning Loss: tensor(0.0354)\n",
            "5355 Traning Loss: tensor(0.0354)\n",
            "5356 Traning Loss: tensor(0.0354)\n",
            "5357 Traning Loss: tensor(0.0354)\n",
            "5358 Traning Loss: tensor(0.0354)\n",
            "5359 Traning Loss: tensor(0.0354)\n",
            "5360 Traning Loss: tensor(0.0354)\n",
            "5361 Traning Loss: tensor(0.0354)\n",
            "5362 Traning Loss: tensor(0.0354)\n",
            "5363 Traning Loss: tensor(0.0354)\n",
            "5364 Traning Loss: tensor(0.0354)\n",
            "5365 Traning Loss: tensor(0.0354)\n",
            "5366 Traning Loss: tensor(0.0354)\n",
            "5367 Traning Loss: tensor(0.0354)\n",
            "5368 Traning Loss: tensor(0.0354)\n",
            "5369 Traning Loss: tensor(0.0354)\n",
            "5370 Traning Loss: tensor(0.0354)\n",
            "5371 Traning Loss: tensor(0.0354)\n",
            "5372 Traning Loss: tensor(0.0354)\n",
            "5373 Traning Loss: tensor(0.0354)\n",
            "5374 Traning Loss: tensor(0.0354)\n",
            "5375 Traning Loss: tensor(0.0354)\n",
            "5376 Traning Loss: tensor(0.0354)\n",
            "5377 Traning Loss: tensor(0.0354)\n",
            "5378 Traning Loss: tensor(0.0354)\n",
            "5379 Traning Loss: tensor(0.0353)\n",
            "5380 Traning Loss: tensor(0.0353)\n",
            "5381 Traning Loss: tensor(0.0353)\n",
            "5382 Traning Loss: tensor(0.0353)\n",
            "5383 Traning Loss: tensor(0.0353)\n",
            "5384 Traning Loss: tensor(0.0353)\n",
            "5385 Traning Loss: tensor(0.0353)\n",
            "5386 Traning Loss: tensor(0.0353)\n",
            "5387 Traning Loss: tensor(0.0353)\n",
            "5388 Traning Loss: tensor(0.0353)\n",
            "5389 Traning Loss: tensor(0.0353)\n",
            "5390 Traning Loss: tensor(0.0353)\n",
            "5391 Traning Loss: tensor(0.0353)\n",
            "5392 Traning Loss: tensor(0.0353)\n",
            "5393 Traning Loss: tensor(0.0353)\n",
            "5394 Traning Loss: tensor(0.0353)\n",
            "5395 Traning Loss: tensor(0.0353)\n",
            "5396 Traning Loss: tensor(0.0353)\n",
            "5397 Traning Loss: tensor(0.0353)\n",
            "5398 Traning Loss: tensor(0.0353)\n",
            "5399 Traning Loss: tensor(0.0353)\n",
            "5400 Traning Loss: tensor(0.0353)\n",
            "5401 Traning Loss: tensor(0.0353)\n",
            "5402 Traning Loss: tensor(0.0353)\n",
            "5403 Traning Loss: tensor(0.0353)\n",
            "5404 Traning Loss: tensor(0.0353)\n",
            "5405 Traning Loss: tensor(0.0353)\n",
            "5406 Traning Loss: tensor(0.0353)\n",
            "5407 Traning Loss: tensor(0.0352)\n",
            "5408 Traning Loss: tensor(0.0352)\n",
            "5409 Traning Loss: tensor(0.0352)\n",
            "5410 Traning Loss: tensor(0.0352)\n",
            "5411 Traning Loss: tensor(0.0352)\n",
            "5412 Traning Loss: tensor(0.0352)\n",
            "5413 Traning Loss: tensor(0.0352)\n",
            "5414 Traning Loss: tensor(0.0352)\n",
            "5415 Traning Loss: tensor(0.0352)\n",
            "5416 Traning Loss: tensor(0.0352)\n",
            "5417 Traning Loss: tensor(0.0352)\n",
            "5418 Traning Loss: tensor(0.0352)\n",
            "5419 Traning Loss: tensor(0.0352)\n",
            "5420 Traning Loss: tensor(0.0352)\n",
            "5421 Traning Loss: tensor(0.0352)\n",
            "5422 Traning Loss: tensor(0.0352)\n",
            "5423 Traning Loss: tensor(0.0352)\n",
            "5424 Traning Loss: tensor(0.0352)\n",
            "5425 Traning Loss: tensor(0.0352)\n",
            "5426 Traning Loss: tensor(0.0352)\n",
            "5427 Traning Loss: tensor(0.0352)\n",
            "5428 Traning Loss: tensor(0.0352)\n",
            "5429 Traning Loss: tensor(0.0352)\n",
            "5430 Traning Loss: tensor(0.0352)\n",
            "5431 Traning Loss: tensor(0.0352)\n",
            "5432 Traning Loss: tensor(0.0352)\n",
            "5433 Traning Loss: tensor(0.0352)\n",
            "5434 Traning Loss: tensor(0.0352)\n",
            "5435 Traning Loss: tensor(0.0351)\n",
            "5436 Traning Loss: tensor(0.0351)\n",
            "5437 Traning Loss: tensor(0.0351)\n",
            "5438 Traning Loss: tensor(0.0351)\n",
            "5439 Traning Loss: tensor(0.0351)\n",
            "5440 Traning Loss: tensor(0.0351)\n",
            "5441 Traning Loss: tensor(0.0351)\n",
            "5442 Traning Loss: tensor(0.0351)\n",
            "5443 Traning Loss: tensor(0.0351)\n",
            "5444 Traning Loss: tensor(0.0351)\n",
            "5445 Traning Loss: tensor(0.0351)\n",
            "5446 Traning Loss: tensor(0.0351)\n",
            "5447 Traning Loss: tensor(0.0351)\n",
            "5448 Traning Loss: tensor(0.0351)\n",
            "5449 Traning Loss: tensor(0.0351)\n",
            "5450 Traning Loss: tensor(0.0351)\n",
            "5451 Traning Loss: tensor(0.0351)\n",
            "5452 Traning Loss: tensor(0.0351)\n",
            "5453 Traning Loss: tensor(0.0351)\n",
            "5454 Traning Loss: tensor(0.0351)\n",
            "5455 Traning Loss: tensor(0.0351)\n",
            "5456 Traning Loss: tensor(0.0351)\n",
            "5457 Traning Loss: tensor(0.0351)\n",
            "5458 Traning Loss: tensor(0.0351)\n",
            "5459 Traning Loss: tensor(0.0351)\n",
            "5460 Traning Loss: tensor(0.0351)\n",
            "5461 Traning Loss: tensor(0.0351)\n",
            "5462 Traning Loss: tensor(0.0351)\n",
            "5463 Traning Loss: tensor(0.0351)\n",
            "5464 Traning Loss: tensor(0.0350)\n",
            "5465 Traning Loss: tensor(0.0350)\n",
            "5466 Traning Loss: tensor(0.0350)\n",
            "5467 Traning Loss: tensor(0.0350)\n",
            "5468 Traning Loss: tensor(0.0350)\n",
            "5469 Traning Loss: tensor(0.0350)\n",
            "5470 Traning Loss: tensor(0.0350)\n",
            "5471 Traning Loss: tensor(0.0350)\n",
            "5472 Traning Loss: tensor(0.0350)\n",
            "5473 Traning Loss: tensor(0.0350)\n",
            "5474 Traning Loss: tensor(0.0350)\n",
            "5475 Traning Loss: tensor(0.0350)\n",
            "5476 Traning Loss: tensor(0.0350)\n",
            "5477 Traning Loss: tensor(0.0350)\n",
            "5478 Traning Loss: tensor(0.0350)\n",
            "5479 Traning Loss: tensor(0.0350)\n",
            "5480 Traning Loss: tensor(0.0350)\n",
            "5481 Traning Loss: tensor(0.0350)\n",
            "5482 Traning Loss: tensor(0.0350)\n",
            "5483 Traning Loss: tensor(0.0350)\n",
            "5484 Traning Loss: tensor(0.0350)\n",
            "5485 Traning Loss: tensor(0.0350)\n",
            "5486 Traning Loss: tensor(0.0350)\n",
            "5487 Traning Loss: tensor(0.0350)\n",
            "5488 Traning Loss: tensor(0.0350)\n",
            "5489 Traning Loss: tensor(0.0350)\n",
            "5490 Traning Loss: tensor(0.0350)\n",
            "5491 Traning Loss: tensor(0.0350)\n",
            "5492 Traning Loss: tensor(0.0350)\n",
            "5493 Traning Loss: tensor(0.0349)\n",
            "5494 Traning Loss: tensor(0.0349)\n",
            "5495 Traning Loss: tensor(0.0349)\n",
            "5496 Traning Loss: tensor(0.0349)\n",
            "5497 Traning Loss: tensor(0.0349)\n",
            "5498 Traning Loss: tensor(0.0349)\n",
            "5499 Traning Loss: tensor(0.0349)\n",
            "5500 Traning Loss: tensor(0.0349)\n",
            "5501 Traning Loss: tensor(0.0349)\n",
            "5502 Traning Loss: tensor(0.0349)\n",
            "5503 Traning Loss: tensor(0.0349)\n",
            "5504 Traning Loss: tensor(0.0349)\n",
            "5505 Traning Loss: tensor(0.0349)\n",
            "5506 Traning Loss: tensor(0.0349)\n",
            "5507 Traning Loss: tensor(0.0349)\n",
            "5508 Traning Loss: tensor(0.0349)\n",
            "5509 Traning Loss: tensor(0.0349)\n",
            "5510 Traning Loss: tensor(0.0349)\n",
            "5511 Traning Loss: tensor(0.0349)\n",
            "5512 Traning Loss: tensor(0.0349)\n",
            "5513 Traning Loss: tensor(0.0349)\n",
            "5514 Traning Loss: tensor(0.0349)\n",
            "5515 Traning Loss: tensor(0.0349)\n",
            "5516 Traning Loss: tensor(0.0349)\n",
            "5517 Traning Loss: tensor(0.0349)\n",
            "5518 Traning Loss: tensor(0.0349)\n",
            "5519 Traning Loss: tensor(0.0349)\n",
            "5520 Traning Loss: tensor(0.0349)\n",
            "5521 Traning Loss: tensor(0.0349)\n",
            "5522 Traning Loss: tensor(0.0348)\n",
            "5523 Traning Loss: tensor(0.0348)\n",
            "5524 Traning Loss: tensor(0.0348)\n",
            "5525 Traning Loss: tensor(0.0348)\n",
            "5526 Traning Loss: tensor(0.0348)\n",
            "5527 Traning Loss: tensor(0.0348)\n",
            "5528 Traning Loss: tensor(0.0348)\n",
            "5529 Traning Loss: tensor(0.0348)\n",
            "5530 Traning Loss: tensor(0.0348)\n",
            "5531 Traning Loss: tensor(0.0348)\n",
            "5532 Traning Loss: tensor(0.0348)\n",
            "5533 Traning Loss: tensor(0.0348)\n",
            "5534 Traning Loss: tensor(0.0348)\n",
            "5535 Traning Loss: tensor(0.0348)\n",
            "5536 Traning Loss: tensor(0.0348)\n",
            "5537 Traning Loss: tensor(0.0348)\n",
            "5538 Traning Loss: tensor(0.0348)\n",
            "5539 Traning Loss: tensor(0.0348)\n",
            "5540 Traning Loss: tensor(0.0348)\n",
            "5541 Traning Loss: tensor(0.0348)\n",
            "5542 Traning Loss: tensor(0.0348)\n",
            "5543 Traning Loss: tensor(0.0348)\n",
            "5544 Traning Loss: tensor(0.0348)\n",
            "5545 Traning Loss: tensor(0.0348)\n",
            "5546 Traning Loss: tensor(0.0348)\n",
            "5547 Traning Loss: tensor(0.0348)\n",
            "5548 Traning Loss: tensor(0.0348)\n",
            "5549 Traning Loss: tensor(0.0348)\n",
            "5550 Traning Loss: tensor(0.0348)\n",
            "5551 Traning Loss: tensor(0.0348)\n",
            "5552 Traning Loss: tensor(0.0347)\n",
            "5553 Traning Loss: tensor(0.0347)\n",
            "5554 Traning Loss: tensor(0.0347)\n",
            "5555 Traning Loss: tensor(0.0347)\n",
            "5556 Traning Loss: tensor(0.0347)\n",
            "5557 Traning Loss: tensor(0.0347)\n",
            "5558 Traning Loss: tensor(0.0347)\n",
            "5559 Traning Loss: tensor(0.0347)\n",
            "5560 Traning Loss: tensor(0.0347)\n",
            "5561 Traning Loss: tensor(0.0347)\n",
            "5562 Traning Loss: tensor(0.0347)\n",
            "5563 Traning Loss: tensor(0.0347)\n",
            "5564 Traning Loss: tensor(0.0347)\n",
            "5565 Traning Loss: tensor(0.0347)\n",
            "5566 Traning Loss: tensor(0.0347)\n",
            "5567 Traning Loss: tensor(0.0347)\n",
            "5568 Traning Loss: tensor(0.0347)\n",
            "5569 Traning Loss: tensor(0.0347)\n",
            "5570 Traning Loss: tensor(0.0347)\n",
            "5571 Traning Loss: tensor(0.0347)\n",
            "5572 Traning Loss: tensor(0.0347)\n",
            "5573 Traning Loss: tensor(0.0347)\n",
            "5574 Traning Loss: tensor(0.0347)\n",
            "5575 Traning Loss: tensor(0.0347)\n",
            "5576 Traning Loss: tensor(0.0347)\n",
            "5577 Traning Loss: tensor(0.0347)\n",
            "5578 Traning Loss: tensor(0.0347)\n",
            "5579 Traning Loss: tensor(0.0347)\n",
            "5580 Traning Loss: tensor(0.0347)\n",
            "5581 Traning Loss: tensor(0.0347)\n",
            "5582 Traning Loss: tensor(0.0346)\n",
            "5583 Traning Loss: tensor(0.0346)\n",
            "5584 Traning Loss: tensor(0.0346)\n",
            "5585 Traning Loss: tensor(0.0346)\n",
            "5586 Traning Loss: tensor(0.0346)\n",
            "5587 Traning Loss: tensor(0.0346)\n",
            "5588 Traning Loss: tensor(0.0346)\n",
            "5589 Traning Loss: tensor(0.0346)\n",
            "5590 Traning Loss: tensor(0.0346)\n",
            "5591 Traning Loss: tensor(0.0346)\n",
            "5592 Traning Loss: tensor(0.0346)\n",
            "5593 Traning Loss: tensor(0.0346)\n",
            "5594 Traning Loss: tensor(0.0346)\n",
            "5595 Traning Loss: tensor(0.0346)\n",
            "5596 Traning Loss: tensor(0.0346)\n",
            "5597 Traning Loss: tensor(0.0346)\n",
            "5598 Traning Loss: tensor(0.0346)\n",
            "5599 Traning Loss: tensor(0.0346)\n",
            "5600 Traning Loss: tensor(0.0346)\n",
            "5601 Traning Loss: tensor(0.0346)\n",
            "5602 Traning Loss: tensor(0.0346)\n",
            "5603 Traning Loss: tensor(0.0346)\n",
            "5604 Traning Loss: tensor(0.0346)\n",
            "5605 Traning Loss: tensor(0.0346)\n",
            "5606 Traning Loss: tensor(0.0346)\n",
            "5607 Traning Loss: tensor(0.0346)\n",
            "5608 Traning Loss: tensor(0.0346)\n",
            "5609 Traning Loss: tensor(0.0346)\n",
            "5610 Traning Loss: tensor(0.0346)\n",
            "5611 Traning Loss: tensor(0.0346)\n",
            "5612 Traning Loss: tensor(0.0345)\n",
            "5613 Traning Loss: tensor(0.0345)\n",
            "5614 Traning Loss: tensor(0.0345)\n",
            "5615 Traning Loss: tensor(0.0345)\n",
            "5616 Traning Loss: tensor(0.0345)\n",
            "5617 Traning Loss: tensor(0.0345)\n",
            "5618 Traning Loss: tensor(0.0345)\n",
            "5619 Traning Loss: tensor(0.0345)\n",
            "5620 Traning Loss: tensor(0.0345)\n",
            "5621 Traning Loss: tensor(0.0345)\n",
            "5622 Traning Loss: tensor(0.0345)\n",
            "5623 Traning Loss: tensor(0.0345)\n",
            "5624 Traning Loss: tensor(0.0345)\n",
            "5625 Traning Loss: tensor(0.0345)\n",
            "5626 Traning Loss: tensor(0.0345)\n",
            "5627 Traning Loss: tensor(0.0345)\n",
            "5628 Traning Loss: tensor(0.0345)\n",
            "5629 Traning Loss: tensor(0.0345)\n",
            "5630 Traning Loss: tensor(0.0345)\n",
            "5631 Traning Loss: tensor(0.0345)\n",
            "5632 Traning Loss: tensor(0.0345)\n",
            "5633 Traning Loss: tensor(0.0345)\n",
            "5634 Traning Loss: tensor(0.0345)\n",
            "5635 Traning Loss: tensor(0.0345)\n",
            "5636 Traning Loss: tensor(0.0345)\n",
            "5637 Traning Loss: tensor(0.0345)\n",
            "5638 Traning Loss: tensor(0.0345)\n",
            "5639 Traning Loss: tensor(0.0345)\n",
            "5640 Traning Loss: tensor(0.0345)\n",
            "5641 Traning Loss: tensor(0.0345)\n",
            "5642 Traning Loss: tensor(0.0344)\n",
            "5643 Traning Loss: tensor(0.0344)\n",
            "5644 Traning Loss: tensor(0.0344)\n",
            "5645 Traning Loss: tensor(0.0344)\n",
            "5646 Traning Loss: tensor(0.0344)\n",
            "5647 Traning Loss: tensor(0.0344)\n",
            "5648 Traning Loss: tensor(0.0344)\n",
            "5649 Traning Loss: tensor(0.0344)\n",
            "5650 Traning Loss: tensor(0.0344)\n",
            "5651 Traning Loss: tensor(0.0344)\n",
            "5652 Traning Loss: tensor(0.0344)\n",
            "5653 Traning Loss: tensor(0.0344)\n",
            "5654 Traning Loss: tensor(0.0344)\n",
            "5655 Traning Loss: tensor(0.0344)\n",
            "5656 Traning Loss: tensor(0.0344)\n",
            "5657 Traning Loss: tensor(0.0344)\n",
            "5658 Traning Loss: tensor(0.0344)\n",
            "5659 Traning Loss: tensor(0.0344)\n",
            "5660 Traning Loss: tensor(0.0344)\n",
            "5661 Traning Loss: tensor(0.0344)\n",
            "5662 Traning Loss: tensor(0.0344)\n",
            "5663 Traning Loss: tensor(0.0344)\n",
            "5664 Traning Loss: tensor(0.0344)\n",
            "5665 Traning Loss: tensor(0.0344)\n",
            "5666 Traning Loss: tensor(0.0344)\n",
            "5667 Traning Loss: tensor(0.0344)\n",
            "5668 Traning Loss: tensor(0.0344)\n",
            "5669 Traning Loss: tensor(0.0344)\n",
            "5670 Traning Loss: tensor(0.0344)\n",
            "5671 Traning Loss: tensor(0.0344)\n",
            "5672 Traning Loss: tensor(0.0344)\n",
            "5673 Traning Loss: tensor(0.0343)\n",
            "5674 Traning Loss: tensor(0.0343)\n",
            "5675 Traning Loss: tensor(0.0343)\n",
            "5676 Traning Loss: tensor(0.0343)\n",
            "5677 Traning Loss: tensor(0.0343)\n",
            "5678 Traning Loss: tensor(0.0343)\n",
            "5679 Traning Loss: tensor(0.0343)\n",
            "5680 Traning Loss: tensor(0.0343)\n",
            "5681 Traning Loss: tensor(0.0343)\n",
            "5682 Traning Loss: tensor(0.0343)\n",
            "5683 Traning Loss: tensor(0.0343)\n",
            "5684 Traning Loss: tensor(0.0343)\n",
            "5685 Traning Loss: tensor(0.0343)\n",
            "5686 Traning Loss: tensor(0.0343)\n",
            "5687 Traning Loss: tensor(0.0343)\n",
            "5688 Traning Loss: tensor(0.0343)\n",
            "5689 Traning Loss: tensor(0.0343)\n",
            "5690 Traning Loss: tensor(0.0343)\n",
            "5691 Traning Loss: tensor(0.0343)\n",
            "5692 Traning Loss: tensor(0.0343)\n",
            "5693 Traning Loss: tensor(0.0343)\n",
            "5694 Traning Loss: tensor(0.0343)\n",
            "5695 Traning Loss: tensor(0.0343)\n",
            "5696 Traning Loss: tensor(0.0343)\n",
            "5697 Traning Loss: tensor(0.0343)\n",
            "5698 Traning Loss: tensor(0.0343)\n",
            "5699 Traning Loss: tensor(0.0343)\n",
            "5700 Traning Loss: tensor(0.0343)\n",
            "5701 Traning Loss: tensor(0.0343)\n",
            "5702 Traning Loss: tensor(0.0343)\n",
            "5703 Traning Loss: tensor(0.0343)\n",
            "5704 Traning Loss: tensor(0.0343)\n",
            "5705 Traning Loss: tensor(0.0342)\n",
            "5706 Traning Loss: tensor(0.0342)\n",
            "5707 Traning Loss: tensor(0.0342)\n",
            "5708 Traning Loss: tensor(0.0342)\n",
            "5709 Traning Loss: tensor(0.0342)\n",
            "5710 Traning Loss: tensor(0.0342)\n",
            "5711 Traning Loss: tensor(0.0342)\n",
            "5712 Traning Loss: tensor(0.0342)\n",
            "5713 Traning Loss: tensor(0.0342)\n",
            "5714 Traning Loss: tensor(0.0342)\n",
            "5715 Traning Loss: tensor(0.0342)\n",
            "5716 Traning Loss: tensor(0.0342)\n",
            "5717 Traning Loss: tensor(0.0342)\n",
            "5718 Traning Loss: tensor(0.0342)\n",
            "5719 Traning Loss: tensor(0.0342)\n",
            "5720 Traning Loss: tensor(0.0342)\n",
            "5721 Traning Loss: tensor(0.0342)\n",
            "5722 Traning Loss: tensor(0.0342)\n",
            "5723 Traning Loss: tensor(0.0342)\n",
            "5724 Traning Loss: tensor(0.0342)\n",
            "5725 Traning Loss: tensor(0.0342)\n",
            "5726 Traning Loss: tensor(0.0342)\n",
            "5727 Traning Loss: tensor(0.0342)\n",
            "5728 Traning Loss: tensor(0.0342)\n",
            "5729 Traning Loss: tensor(0.0342)\n",
            "5730 Traning Loss: tensor(0.0342)\n",
            "5731 Traning Loss: tensor(0.0342)\n",
            "5732 Traning Loss: tensor(0.0342)\n",
            "5733 Traning Loss: tensor(0.0342)\n",
            "5734 Traning Loss: tensor(0.0342)\n",
            "5735 Traning Loss: tensor(0.0342)\n",
            "5736 Traning Loss: tensor(0.0342)\n",
            "5737 Traning Loss: tensor(0.0341)\n",
            "5738 Traning Loss: tensor(0.0341)\n",
            "5739 Traning Loss: tensor(0.0341)\n",
            "5740 Traning Loss: tensor(0.0341)\n",
            "5741 Traning Loss: tensor(0.0341)\n",
            "5742 Traning Loss: tensor(0.0341)\n",
            "5743 Traning Loss: tensor(0.0341)\n",
            "5744 Traning Loss: tensor(0.0341)\n",
            "5745 Traning Loss: tensor(0.0341)\n",
            "5746 Traning Loss: tensor(0.0341)\n",
            "5747 Traning Loss: tensor(0.0341)\n",
            "5748 Traning Loss: tensor(0.0341)\n",
            "5749 Traning Loss: tensor(0.0341)\n",
            "5750 Traning Loss: tensor(0.0341)\n",
            "5751 Traning Loss: tensor(0.0341)\n",
            "5752 Traning Loss: tensor(0.0341)\n",
            "5753 Traning Loss: tensor(0.0341)\n",
            "5754 Traning Loss: tensor(0.0341)\n",
            "5755 Traning Loss: tensor(0.0341)\n",
            "5756 Traning Loss: tensor(0.0341)\n",
            "5757 Traning Loss: tensor(0.0341)\n",
            "5758 Traning Loss: tensor(0.0341)\n",
            "5759 Traning Loss: tensor(0.0341)\n",
            "5760 Traning Loss: tensor(0.0341)\n",
            "5761 Traning Loss: tensor(0.0341)\n",
            "5762 Traning Loss: tensor(0.0341)\n",
            "5763 Traning Loss: tensor(0.0341)\n",
            "5764 Traning Loss: tensor(0.0341)\n",
            "5765 Traning Loss: tensor(0.0341)\n",
            "5766 Traning Loss: tensor(0.0341)\n",
            "5767 Traning Loss: tensor(0.0341)\n",
            "5768 Traning Loss: tensor(0.0341)\n",
            "5769 Traning Loss: tensor(0.0340)\n",
            "5770 Traning Loss: tensor(0.0340)\n",
            "5771 Traning Loss: tensor(0.0340)\n",
            "5772 Traning Loss: tensor(0.0340)\n",
            "5773 Traning Loss: tensor(0.0340)\n",
            "5774 Traning Loss: tensor(0.0340)\n",
            "5775 Traning Loss: tensor(0.0340)\n",
            "5776 Traning Loss: tensor(0.0340)\n",
            "5777 Traning Loss: tensor(0.0340)\n",
            "5778 Traning Loss: tensor(0.0340)\n",
            "5779 Traning Loss: tensor(0.0340)\n",
            "5780 Traning Loss: tensor(0.0340)\n",
            "5781 Traning Loss: tensor(0.0340)\n",
            "5782 Traning Loss: tensor(0.0340)\n",
            "5783 Traning Loss: tensor(0.0340)\n",
            "5784 Traning Loss: tensor(0.0340)\n",
            "5785 Traning Loss: tensor(0.0340)\n",
            "5786 Traning Loss: tensor(0.0340)\n",
            "5787 Traning Loss: tensor(0.0340)\n",
            "5788 Traning Loss: tensor(0.0340)\n",
            "5789 Traning Loss: tensor(0.0340)\n",
            "5790 Traning Loss: tensor(0.0340)\n",
            "5791 Traning Loss: tensor(0.0340)\n",
            "5792 Traning Loss: tensor(0.0340)\n",
            "5793 Traning Loss: tensor(0.0340)\n",
            "5794 Traning Loss: tensor(0.0340)\n",
            "5795 Traning Loss: tensor(0.0340)\n",
            "5796 Traning Loss: tensor(0.0340)\n",
            "5797 Traning Loss: tensor(0.0340)\n",
            "5798 Traning Loss: tensor(0.0340)\n",
            "5799 Traning Loss: tensor(0.0340)\n",
            "5800 Traning Loss: tensor(0.0340)\n",
            "5801 Traning Loss: tensor(0.0339)\n",
            "5802 Traning Loss: tensor(0.0339)\n",
            "5803 Traning Loss: tensor(0.0339)\n",
            "5804 Traning Loss: tensor(0.0339)\n",
            "5805 Traning Loss: tensor(0.0339)\n",
            "5806 Traning Loss: tensor(0.0339)\n",
            "5807 Traning Loss: tensor(0.0339)\n",
            "5808 Traning Loss: tensor(0.0339)\n",
            "5809 Traning Loss: tensor(0.0339)\n",
            "5810 Traning Loss: tensor(0.0339)\n",
            "5811 Traning Loss: tensor(0.0339)\n",
            "5812 Traning Loss: tensor(0.0339)\n",
            "5813 Traning Loss: tensor(0.0339)\n",
            "5814 Traning Loss: tensor(0.0339)\n",
            "5815 Traning Loss: tensor(0.0339)\n",
            "5816 Traning Loss: tensor(0.0339)\n",
            "5817 Traning Loss: tensor(0.0339)\n",
            "5818 Traning Loss: tensor(0.0339)\n",
            "5819 Traning Loss: tensor(0.0339)\n",
            "5820 Traning Loss: tensor(0.0339)\n",
            "5821 Traning Loss: tensor(0.0339)\n",
            "5822 Traning Loss: tensor(0.0339)\n",
            "5823 Traning Loss: tensor(0.0339)\n",
            "5824 Traning Loss: tensor(0.0339)\n",
            "5825 Traning Loss: tensor(0.0339)\n",
            "5826 Traning Loss: tensor(0.0339)\n",
            "5827 Traning Loss: tensor(0.0339)\n",
            "5828 Traning Loss: tensor(0.0339)\n",
            "5829 Traning Loss: tensor(0.0339)\n",
            "5830 Traning Loss: tensor(0.0339)\n",
            "5831 Traning Loss: tensor(0.0339)\n",
            "5832 Traning Loss: tensor(0.0339)\n",
            "5833 Traning Loss: tensor(0.0339)\n",
            "5834 Traning Loss: tensor(0.0338)\n",
            "5835 Traning Loss: tensor(0.0338)\n",
            "5836 Traning Loss: tensor(0.0338)\n",
            "5837 Traning Loss: tensor(0.0338)\n",
            "5838 Traning Loss: tensor(0.0338)\n",
            "5839 Traning Loss: tensor(0.0338)\n",
            "5840 Traning Loss: tensor(0.0338)\n",
            "5841 Traning Loss: tensor(0.0338)\n",
            "5842 Traning Loss: tensor(0.0338)\n",
            "5843 Traning Loss: tensor(0.0338)\n",
            "5844 Traning Loss: tensor(0.0338)\n",
            "5845 Traning Loss: tensor(0.0338)\n",
            "5846 Traning Loss: tensor(0.0338)\n",
            "5847 Traning Loss: tensor(0.0338)\n",
            "5848 Traning Loss: tensor(0.0338)\n",
            "5849 Traning Loss: tensor(0.0338)\n",
            "5850 Traning Loss: tensor(0.0338)\n",
            "5851 Traning Loss: tensor(0.0338)\n",
            "5852 Traning Loss: tensor(0.0338)\n",
            "5853 Traning Loss: tensor(0.0338)\n",
            "5854 Traning Loss: tensor(0.0338)\n",
            "5855 Traning Loss: tensor(0.0338)\n",
            "5856 Traning Loss: tensor(0.0338)\n",
            "5857 Traning Loss: tensor(0.0338)\n",
            "5858 Traning Loss: tensor(0.0338)\n",
            "5859 Traning Loss: tensor(0.0338)\n",
            "5860 Traning Loss: tensor(0.0338)\n",
            "5861 Traning Loss: tensor(0.0338)\n",
            "5862 Traning Loss: tensor(0.0338)\n",
            "5863 Traning Loss: tensor(0.0338)\n",
            "5864 Traning Loss: tensor(0.0338)\n",
            "5865 Traning Loss: tensor(0.0338)\n",
            "5866 Traning Loss: tensor(0.0338)\n",
            "5867 Traning Loss: tensor(0.0337)\n",
            "5868 Traning Loss: tensor(0.0337)\n",
            "5869 Traning Loss: tensor(0.0337)\n",
            "5870 Traning Loss: tensor(0.0337)\n",
            "5871 Traning Loss: tensor(0.0337)\n",
            "5872 Traning Loss: tensor(0.0337)\n",
            "5873 Traning Loss: tensor(0.0337)\n",
            "5874 Traning Loss: tensor(0.0337)\n",
            "5875 Traning Loss: tensor(0.0337)\n",
            "5876 Traning Loss: tensor(0.0337)\n",
            "5877 Traning Loss: tensor(0.0337)\n",
            "5878 Traning Loss: tensor(0.0337)\n",
            "5879 Traning Loss: tensor(0.0337)\n",
            "5880 Traning Loss: tensor(0.0337)\n",
            "5881 Traning Loss: tensor(0.0337)\n",
            "5882 Traning Loss: tensor(0.0337)\n",
            "5883 Traning Loss: tensor(0.0337)\n",
            "5884 Traning Loss: tensor(0.0337)\n",
            "5885 Traning Loss: tensor(0.0337)\n",
            "5886 Traning Loss: tensor(0.0337)\n",
            "5887 Traning Loss: tensor(0.0337)\n",
            "5888 Traning Loss: tensor(0.0337)\n",
            "5889 Traning Loss: tensor(0.0337)\n",
            "5890 Traning Loss: tensor(0.0337)\n",
            "5891 Traning Loss: tensor(0.0337)\n",
            "5892 Traning Loss: tensor(0.0337)\n",
            "5893 Traning Loss: tensor(0.0337)\n",
            "5894 Traning Loss: tensor(0.0337)\n",
            "5895 Traning Loss: tensor(0.0337)\n",
            "5896 Traning Loss: tensor(0.0337)\n",
            "5897 Traning Loss: tensor(0.0337)\n",
            "5898 Traning Loss: tensor(0.0337)\n",
            "5899 Traning Loss: tensor(0.0337)\n",
            "5900 Traning Loss: tensor(0.0337)\n",
            "5901 Traning Loss: tensor(0.0336)\n",
            "5902 Traning Loss: tensor(0.0336)\n",
            "5903 Traning Loss: tensor(0.0336)\n",
            "5904 Traning Loss: tensor(0.0336)\n",
            "5905 Traning Loss: tensor(0.0336)\n",
            "5906 Traning Loss: tensor(0.0336)\n",
            "5907 Traning Loss: tensor(0.0336)\n",
            "5908 Traning Loss: tensor(0.0336)\n",
            "5909 Traning Loss: tensor(0.0336)\n",
            "5910 Traning Loss: tensor(0.0336)\n",
            "5911 Traning Loss: tensor(0.0336)\n",
            "5912 Traning Loss: tensor(0.0336)\n",
            "5913 Traning Loss: tensor(0.0336)\n",
            "5914 Traning Loss: tensor(0.0336)\n",
            "5915 Traning Loss: tensor(0.0336)\n",
            "5916 Traning Loss: tensor(0.0336)\n",
            "5917 Traning Loss: tensor(0.0336)\n",
            "5918 Traning Loss: tensor(0.0336)\n",
            "5919 Traning Loss: tensor(0.0336)\n",
            "5920 Traning Loss: tensor(0.0336)\n",
            "5921 Traning Loss: tensor(0.0336)\n",
            "5922 Traning Loss: tensor(0.0336)\n",
            "5923 Traning Loss: tensor(0.0336)\n",
            "5924 Traning Loss: tensor(0.0336)\n",
            "5925 Traning Loss: tensor(0.0336)\n",
            "5926 Traning Loss: tensor(0.0336)\n",
            "5927 Traning Loss: tensor(0.0336)\n",
            "5928 Traning Loss: tensor(0.0336)\n",
            "5929 Traning Loss: tensor(0.0336)\n",
            "5930 Traning Loss: tensor(0.0336)\n",
            "5931 Traning Loss: tensor(0.0336)\n",
            "5932 Traning Loss: tensor(0.0336)\n",
            "5933 Traning Loss: tensor(0.0336)\n",
            "5934 Traning Loss: tensor(0.0336)\n",
            "5935 Traning Loss: tensor(0.0335)\n",
            "5936 Traning Loss: tensor(0.0335)\n",
            "5937 Traning Loss: tensor(0.0335)\n",
            "5938 Traning Loss: tensor(0.0335)\n",
            "5939 Traning Loss: tensor(0.0335)\n",
            "5940 Traning Loss: tensor(0.0335)\n",
            "5941 Traning Loss: tensor(0.0335)\n",
            "5942 Traning Loss: tensor(0.0335)\n",
            "5943 Traning Loss: tensor(0.0335)\n",
            "5944 Traning Loss: tensor(0.0335)\n",
            "5945 Traning Loss: tensor(0.0335)\n",
            "5946 Traning Loss: tensor(0.0335)\n",
            "5947 Traning Loss: tensor(0.0335)\n",
            "5948 Traning Loss: tensor(0.0335)\n",
            "5949 Traning Loss: tensor(0.0335)\n",
            "5950 Traning Loss: tensor(0.0335)\n",
            "5951 Traning Loss: tensor(0.0335)\n",
            "5952 Traning Loss: tensor(0.0335)\n",
            "5953 Traning Loss: tensor(0.0335)\n",
            "5954 Traning Loss: tensor(0.0335)\n",
            "5955 Traning Loss: tensor(0.0335)\n",
            "5956 Traning Loss: tensor(0.0335)\n",
            "5957 Traning Loss: tensor(0.0335)\n",
            "5958 Traning Loss: tensor(0.0335)\n",
            "5959 Traning Loss: tensor(0.0335)\n",
            "5960 Traning Loss: tensor(0.0335)\n",
            "5961 Traning Loss: tensor(0.0335)\n",
            "5962 Traning Loss: tensor(0.0335)\n",
            "5963 Traning Loss: tensor(0.0335)\n",
            "5964 Traning Loss: tensor(0.0335)\n",
            "5965 Traning Loss: tensor(0.0335)\n",
            "5966 Traning Loss: tensor(0.0335)\n",
            "5967 Traning Loss: tensor(0.0335)\n",
            "5968 Traning Loss: tensor(0.0335)\n",
            "5969 Traning Loss: tensor(0.0335)\n",
            "5970 Traning Loss: tensor(0.0334)\n",
            "5971 Traning Loss: tensor(0.0334)\n",
            "5972 Traning Loss: tensor(0.0334)\n",
            "5973 Traning Loss: tensor(0.0334)\n",
            "5974 Traning Loss: tensor(0.0334)\n",
            "5975 Traning Loss: tensor(0.0334)\n",
            "5976 Traning Loss: tensor(0.0334)\n",
            "5977 Traning Loss: tensor(0.0334)\n",
            "5978 Traning Loss: tensor(0.0334)\n",
            "5979 Traning Loss: tensor(0.0334)\n",
            "5980 Traning Loss: tensor(0.0334)\n",
            "5981 Traning Loss: tensor(0.0334)\n",
            "5982 Traning Loss: tensor(0.0334)\n",
            "5983 Traning Loss: tensor(0.0334)\n",
            "5984 Traning Loss: tensor(0.0334)\n",
            "5985 Traning Loss: tensor(0.0334)\n",
            "5986 Traning Loss: tensor(0.0334)\n",
            "5987 Traning Loss: tensor(0.0334)\n",
            "5988 Traning Loss: tensor(0.0334)\n",
            "5989 Traning Loss: tensor(0.0334)\n",
            "5990 Traning Loss: tensor(0.0334)\n",
            "5991 Traning Loss: tensor(0.0334)\n",
            "5992 Traning Loss: tensor(0.0334)\n",
            "5993 Traning Loss: tensor(0.0334)\n",
            "5994 Traning Loss: tensor(0.0334)\n",
            "5995 Traning Loss: tensor(0.0334)\n",
            "5996 Traning Loss: tensor(0.0334)\n",
            "5997 Traning Loss: tensor(0.0334)\n",
            "5998 Traning Loss: tensor(0.0334)\n",
            "5999 Traning Loss: tensor(0.0334)\n",
            "6000 Traning Loss: tensor(0.0334)\n",
            "6001 Traning Loss: tensor(0.0334)\n",
            "6002 Traning Loss: tensor(0.0334)\n",
            "6003 Traning Loss: tensor(0.0334)\n",
            "6004 Traning Loss: tensor(0.0334)\n",
            "6005 Traning Loss: tensor(0.0333)\n",
            "6006 Traning Loss: tensor(0.0333)\n",
            "6007 Traning Loss: tensor(0.0333)\n",
            "6008 Traning Loss: tensor(0.0333)\n",
            "6009 Traning Loss: tensor(0.0333)\n",
            "6010 Traning Loss: tensor(0.0333)\n",
            "6011 Traning Loss: tensor(0.0333)\n",
            "6012 Traning Loss: tensor(0.0333)\n",
            "6013 Traning Loss: tensor(0.0333)\n",
            "6014 Traning Loss: tensor(0.0333)\n",
            "6015 Traning Loss: tensor(0.0333)\n",
            "6016 Traning Loss: tensor(0.0333)\n",
            "6017 Traning Loss: tensor(0.0333)\n",
            "6018 Traning Loss: tensor(0.0333)\n",
            "6019 Traning Loss: tensor(0.0333)\n",
            "6020 Traning Loss: tensor(0.0333)\n",
            "6021 Traning Loss: tensor(0.0333)\n",
            "6022 Traning Loss: tensor(0.0333)\n",
            "6023 Traning Loss: tensor(0.0333)\n",
            "6024 Traning Loss: tensor(0.0333)\n",
            "6025 Traning Loss: tensor(0.0333)\n",
            "6026 Traning Loss: tensor(0.0333)\n",
            "6027 Traning Loss: tensor(0.0333)\n",
            "6028 Traning Loss: tensor(0.0333)\n",
            "6029 Traning Loss: tensor(0.0333)\n",
            "6030 Traning Loss: tensor(0.0333)\n",
            "6031 Traning Loss: tensor(0.0333)\n",
            "6032 Traning Loss: tensor(0.0333)\n",
            "6033 Traning Loss: tensor(0.0333)\n",
            "6034 Traning Loss: tensor(0.0333)\n",
            "6035 Traning Loss: tensor(0.0333)\n",
            "6036 Traning Loss: tensor(0.0333)\n",
            "6037 Traning Loss: tensor(0.0333)\n",
            "6038 Traning Loss: tensor(0.0333)\n",
            "6039 Traning Loss: tensor(0.0333)\n",
            "6040 Traning Loss: tensor(0.0332)\n",
            "6041 Traning Loss: tensor(0.0332)\n",
            "6042 Traning Loss: tensor(0.0332)\n",
            "6043 Traning Loss: tensor(0.0332)\n",
            "6044 Traning Loss: tensor(0.0332)\n",
            "6045 Traning Loss: tensor(0.0332)\n",
            "6046 Traning Loss: tensor(0.0332)\n",
            "6047 Traning Loss: tensor(0.0332)\n",
            "6048 Traning Loss: tensor(0.0332)\n",
            "6049 Traning Loss: tensor(0.0332)\n",
            "6050 Traning Loss: tensor(0.0332)\n",
            "6051 Traning Loss: tensor(0.0332)\n",
            "6052 Traning Loss: tensor(0.0332)\n",
            "6053 Traning Loss: tensor(0.0332)\n",
            "6054 Traning Loss: tensor(0.0332)\n",
            "6055 Traning Loss: tensor(0.0332)\n",
            "6056 Traning Loss: tensor(0.0332)\n",
            "6057 Traning Loss: tensor(0.0332)\n",
            "6058 Traning Loss: tensor(0.0332)\n",
            "6059 Traning Loss: tensor(0.0332)\n",
            "6060 Traning Loss: tensor(0.0332)\n",
            "6061 Traning Loss: tensor(0.0332)\n",
            "6062 Traning Loss: tensor(0.0332)\n",
            "6063 Traning Loss: tensor(0.0332)\n",
            "6064 Traning Loss: tensor(0.0332)\n",
            "6065 Traning Loss: tensor(0.0332)\n",
            "6066 Traning Loss: tensor(0.0332)\n",
            "6067 Traning Loss: tensor(0.0332)\n",
            "6068 Traning Loss: tensor(0.0332)\n",
            "6069 Traning Loss: tensor(0.0332)\n",
            "6070 Traning Loss: tensor(0.0332)\n",
            "6071 Traning Loss: tensor(0.0332)\n",
            "6072 Traning Loss: tensor(0.0332)\n",
            "6073 Traning Loss: tensor(0.0332)\n",
            "6074 Traning Loss: tensor(0.0332)\n",
            "6075 Traning Loss: tensor(0.0332)\n",
            "6076 Traning Loss: tensor(0.0331)\n",
            "6077 Traning Loss: tensor(0.0331)\n",
            "6078 Traning Loss: tensor(0.0331)\n",
            "6079 Traning Loss: tensor(0.0331)\n",
            "6080 Traning Loss: tensor(0.0331)\n",
            "6081 Traning Loss: tensor(0.0331)\n",
            "6082 Traning Loss: tensor(0.0331)\n",
            "6083 Traning Loss: tensor(0.0331)\n",
            "6084 Traning Loss: tensor(0.0331)\n",
            "6085 Traning Loss: tensor(0.0331)\n",
            "6086 Traning Loss: tensor(0.0331)\n",
            "6087 Traning Loss: tensor(0.0331)\n",
            "6088 Traning Loss: tensor(0.0331)\n",
            "6089 Traning Loss: tensor(0.0331)\n",
            "6090 Traning Loss: tensor(0.0331)\n",
            "6091 Traning Loss: tensor(0.0331)\n",
            "6092 Traning Loss: tensor(0.0331)\n",
            "6093 Traning Loss: tensor(0.0331)\n",
            "6094 Traning Loss: tensor(0.0331)\n",
            "6095 Traning Loss: tensor(0.0331)\n",
            "6096 Traning Loss: tensor(0.0331)\n",
            "6097 Traning Loss: tensor(0.0331)\n",
            "6098 Traning Loss: tensor(0.0331)\n",
            "6099 Traning Loss: tensor(0.0331)\n",
            "6100 Traning Loss: tensor(0.0331)\n",
            "6101 Traning Loss: tensor(0.0331)\n",
            "6102 Traning Loss: tensor(0.0331)\n",
            "6103 Traning Loss: tensor(0.0331)\n",
            "6104 Traning Loss: tensor(0.0331)\n",
            "6105 Traning Loss: tensor(0.0331)\n",
            "6106 Traning Loss: tensor(0.0331)\n",
            "6107 Traning Loss: tensor(0.0331)\n",
            "6108 Traning Loss: tensor(0.0331)\n",
            "6109 Traning Loss: tensor(0.0331)\n",
            "6110 Traning Loss: tensor(0.0331)\n",
            "6111 Traning Loss: tensor(0.0331)\n",
            "6112 Traning Loss: tensor(0.0330)\n",
            "6113 Traning Loss: tensor(0.0330)\n",
            "6114 Traning Loss: tensor(0.0330)\n",
            "6115 Traning Loss: tensor(0.0330)\n",
            "6116 Traning Loss: tensor(0.0330)\n",
            "6117 Traning Loss: tensor(0.0330)\n",
            "6118 Traning Loss: tensor(0.0330)\n",
            "6119 Traning Loss: tensor(0.0330)\n",
            "6120 Traning Loss: tensor(0.0330)\n",
            "6121 Traning Loss: tensor(0.0330)\n",
            "6122 Traning Loss: tensor(0.0330)\n",
            "6123 Traning Loss: tensor(0.0330)\n",
            "6124 Traning Loss: tensor(0.0330)\n",
            "6125 Traning Loss: tensor(0.0330)\n",
            "6126 Traning Loss: tensor(0.0330)\n",
            "6127 Traning Loss: tensor(0.0330)\n",
            "6128 Traning Loss: tensor(0.0330)\n",
            "6129 Traning Loss: tensor(0.0330)\n",
            "6130 Traning Loss: tensor(0.0330)\n",
            "6131 Traning Loss: tensor(0.0330)\n",
            "6132 Traning Loss: tensor(0.0330)\n",
            "6133 Traning Loss: tensor(0.0330)\n",
            "6134 Traning Loss: tensor(0.0330)\n",
            "6135 Traning Loss: tensor(0.0330)\n",
            "6136 Traning Loss: tensor(0.0330)\n",
            "6137 Traning Loss: tensor(0.0330)\n",
            "6138 Traning Loss: tensor(0.0330)\n",
            "6139 Traning Loss: tensor(0.0330)\n",
            "6140 Traning Loss: tensor(0.0330)\n",
            "6141 Traning Loss: tensor(0.0330)\n",
            "6142 Traning Loss: tensor(0.0330)\n",
            "6143 Traning Loss: tensor(0.0330)\n",
            "6144 Traning Loss: tensor(0.0330)\n",
            "6145 Traning Loss: tensor(0.0330)\n",
            "6146 Traning Loss: tensor(0.0330)\n",
            "6147 Traning Loss: tensor(0.0330)\n",
            "6148 Traning Loss: tensor(0.0330)\n",
            "6149 Traning Loss: tensor(0.0329)\n",
            "6150 Traning Loss: tensor(0.0329)\n",
            "6151 Traning Loss: tensor(0.0329)\n",
            "6152 Traning Loss: tensor(0.0329)\n",
            "6153 Traning Loss: tensor(0.0329)\n",
            "6154 Traning Loss: tensor(0.0329)\n",
            "6155 Traning Loss: tensor(0.0329)\n",
            "6156 Traning Loss: tensor(0.0329)\n",
            "6157 Traning Loss: tensor(0.0329)\n",
            "6158 Traning Loss: tensor(0.0329)\n",
            "6159 Traning Loss: tensor(0.0329)\n",
            "6160 Traning Loss: tensor(0.0329)\n",
            "6161 Traning Loss: tensor(0.0329)\n",
            "6162 Traning Loss: tensor(0.0329)\n",
            "6163 Traning Loss: tensor(0.0329)\n",
            "6164 Traning Loss: tensor(0.0329)\n",
            "6165 Traning Loss: tensor(0.0329)\n",
            "6166 Traning Loss: tensor(0.0329)\n",
            "6167 Traning Loss: tensor(0.0329)\n",
            "6168 Traning Loss: tensor(0.0329)\n",
            "6169 Traning Loss: tensor(0.0329)\n",
            "6170 Traning Loss: tensor(0.0329)\n",
            "6171 Traning Loss: tensor(0.0329)\n",
            "6172 Traning Loss: tensor(0.0329)\n",
            "6173 Traning Loss: tensor(0.0329)\n",
            "6174 Traning Loss: tensor(0.0329)\n",
            "6175 Traning Loss: tensor(0.0329)\n",
            "6176 Traning Loss: tensor(0.0329)\n",
            "6177 Traning Loss: tensor(0.0329)\n",
            "6178 Traning Loss: tensor(0.0329)\n",
            "6179 Traning Loss: tensor(0.0329)\n",
            "6180 Traning Loss: tensor(0.0329)\n",
            "6181 Traning Loss: tensor(0.0329)\n",
            "6182 Traning Loss: tensor(0.0329)\n",
            "6183 Traning Loss: tensor(0.0329)\n",
            "6184 Traning Loss: tensor(0.0329)\n",
            "6185 Traning Loss: tensor(0.0329)\n",
            "6186 Traning Loss: tensor(0.0328)\n",
            "6187 Traning Loss: tensor(0.0328)\n",
            "6188 Traning Loss: tensor(0.0328)\n",
            "6189 Traning Loss: tensor(0.0328)\n",
            "6190 Traning Loss: tensor(0.0328)\n",
            "6191 Traning Loss: tensor(0.0328)\n",
            "6192 Traning Loss: tensor(0.0328)\n",
            "6193 Traning Loss: tensor(0.0328)\n",
            "6194 Traning Loss: tensor(0.0328)\n",
            "6195 Traning Loss: tensor(0.0328)\n",
            "6196 Traning Loss: tensor(0.0328)\n",
            "6197 Traning Loss: tensor(0.0328)\n",
            "6198 Traning Loss: tensor(0.0328)\n",
            "6199 Traning Loss: tensor(0.0328)\n",
            "6200 Traning Loss: tensor(0.0328)\n",
            "6201 Traning Loss: tensor(0.0328)\n",
            "6202 Traning Loss: tensor(0.0328)\n",
            "6203 Traning Loss: tensor(0.0328)\n",
            "6204 Traning Loss: tensor(0.0328)\n",
            "6205 Traning Loss: tensor(0.0328)\n",
            "6206 Traning Loss: tensor(0.0328)\n",
            "6207 Traning Loss: tensor(0.0328)\n",
            "6208 Traning Loss: tensor(0.0328)\n",
            "6209 Traning Loss: tensor(0.0328)\n",
            "6210 Traning Loss: tensor(0.0328)\n",
            "6211 Traning Loss: tensor(0.0328)\n",
            "6212 Traning Loss: tensor(0.0328)\n",
            "6213 Traning Loss: tensor(0.0328)\n",
            "6214 Traning Loss: tensor(0.0328)\n",
            "6215 Traning Loss: tensor(0.0328)\n",
            "6216 Traning Loss: tensor(0.0328)\n",
            "6217 Traning Loss: tensor(0.0328)\n",
            "6218 Traning Loss: tensor(0.0328)\n",
            "6219 Traning Loss: tensor(0.0328)\n",
            "6220 Traning Loss: tensor(0.0328)\n",
            "6221 Traning Loss: tensor(0.0328)\n",
            "6222 Traning Loss: tensor(0.0328)\n",
            "6223 Traning Loss: tensor(0.0328)\n",
            "6224 Traning Loss: tensor(0.0327)\n",
            "6225 Traning Loss: tensor(0.0327)\n",
            "6226 Traning Loss: tensor(0.0327)\n",
            "6227 Traning Loss: tensor(0.0327)\n",
            "6228 Traning Loss: tensor(0.0327)\n",
            "6229 Traning Loss: tensor(0.0327)\n",
            "6230 Traning Loss: tensor(0.0327)\n",
            "6231 Traning Loss: tensor(0.0327)\n",
            "6232 Traning Loss: tensor(0.0327)\n",
            "6233 Traning Loss: tensor(0.0327)\n",
            "6234 Traning Loss: tensor(0.0327)\n",
            "6235 Traning Loss: tensor(0.0327)\n",
            "6236 Traning Loss: tensor(0.0327)\n",
            "6237 Traning Loss: tensor(0.0327)\n",
            "6238 Traning Loss: tensor(0.0327)\n",
            "6239 Traning Loss: tensor(0.0327)\n",
            "6240 Traning Loss: tensor(0.0327)\n",
            "6241 Traning Loss: tensor(0.0327)\n",
            "6242 Traning Loss: tensor(0.0327)\n",
            "6243 Traning Loss: tensor(0.0327)\n",
            "6244 Traning Loss: tensor(0.0327)\n",
            "6245 Traning Loss: tensor(0.0327)\n",
            "6246 Traning Loss: tensor(0.0327)\n",
            "6247 Traning Loss: tensor(0.0327)\n",
            "6248 Traning Loss: tensor(0.0327)\n",
            "6249 Traning Loss: tensor(0.0327)\n",
            "6250 Traning Loss: tensor(0.0327)\n",
            "6251 Traning Loss: tensor(0.0327)\n",
            "6252 Traning Loss: tensor(0.0327)\n",
            "6253 Traning Loss: tensor(0.0327)\n",
            "6254 Traning Loss: tensor(0.0327)\n",
            "6255 Traning Loss: tensor(0.0327)\n",
            "6256 Traning Loss: tensor(0.0327)\n",
            "6257 Traning Loss: tensor(0.0327)\n",
            "6258 Traning Loss: tensor(0.0327)\n",
            "6259 Traning Loss: tensor(0.0327)\n",
            "6260 Traning Loss: tensor(0.0327)\n",
            "6261 Traning Loss: tensor(0.0327)\n",
            "6262 Traning Loss: tensor(0.0326)\n",
            "6263 Traning Loss: tensor(0.0326)\n",
            "6264 Traning Loss: tensor(0.0326)\n",
            "6265 Traning Loss: tensor(0.0326)\n",
            "6266 Traning Loss: tensor(0.0326)\n",
            "6267 Traning Loss: tensor(0.0326)\n",
            "6268 Traning Loss: tensor(0.0326)\n",
            "6269 Traning Loss: tensor(0.0326)\n",
            "6270 Traning Loss: tensor(0.0326)\n",
            "6271 Traning Loss: tensor(0.0326)\n",
            "6272 Traning Loss: tensor(0.0326)\n",
            "6273 Traning Loss: tensor(0.0326)\n",
            "6274 Traning Loss: tensor(0.0326)\n",
            "6275 Traning Loss: tensor(0.0326)\n",
            "6276 Traning Loss: tensor(0.0326)\n",
            "6277 Traning Loss: tensor(0.0326)\n",
            "6278 Traning Loss: tensor(0.0326)\n",
            "6279 Traning Loss: tensor(0.0326)\n",
            "6280 Traning Loss: tensor(0.0326)\n",
            "6281 Traning Loss: tensor(0.0326)\n",
            "6282 Traning Loss: tensor(0.0326)\n",
            "6283 Traning Loss: tensor(0.0326)\n",
            "6284 Traning Loss: tensor(0.0326)\n",
            "6285 Traning Loss: tensor(0.0326)\n",
            "6286 Traning Loss: tensor(0.0326)\n",
            "6287 Traning Loss: tensor(0.0326)\n",
            "6288 Traning Loss: tensor(0.0326)\n",
            "6289 Traning Loss: tensor(0.0326)\n",
            "6290 Traning Loss: tensor(0.0326)\n",
            "6291 Traning Loss: tensor(0.0326)\n",
            "6292 Traning Loss: tensor(0.0326)\n",
            "6293 Traning Loss: tensor(0.0326)\n",
            "6294 Traning Loss: tensor(0.0326)\n",
            "6295 Traning Loss: tensor(0.0326)\n",
            "6296 Traning Loss: tensor(0.0326)\n",
            "6297 Traning Loss: tensor(0.0326)\n",
            "6298 Traning Loss: tensor(0.0326)\n",
            "6299 Traning Loss: tensor(0.0326)\n",
            "6300 Traning Loss: tensor(0.0326)\n",
            "6301 Traning Loss: tensor(0.0325)\n",
            "6302 Traning Loss: tensor(0.0325)\n",
            "6303 Traning Loss: tensor(0.0325)\n",
            "6304 Traning Loss: tensor(0.0325)\n",
            "6305 Traning Loss: tensor(0.0325)\n",
            "6306 Traning Loss: tensor(0.0325)\n",
            "6307 Traning Loss: tensor(0.0325)\n",
            "6308 Traning Loss: tensor(0.0325)\n",
            "6309 Traning Loss: tensor(0.0325)\n",
            "6310 Traning Loss: tensor(0.0325)\n",
            "6311 Traning Loss: tensor(0.0325)\n",
            "6312 Traning Loss: tensor(0.0325)\n",
            "6313 Traning Loss: tensor(0.0325)\n",
            "6314 Traning Loss: tensor(0.0325)\n",
            "6315 Traning Loss: tensor(0.0325)\n",
            "6316 Traning Loss: tensor(0.0325)\n",
            "6317 Traning Loss: tensor(0.0325)\n",
            "6318 Traning Loss: tensor(0.0325)\n",
            "6319 Traning Loss: tensor(0.0325)\n",
            "6320 Traning Loss: tensor(0.0325)\n",
            "6321 Traning Loss: tensor(0.0325)\n",
            "6322 Traning Loss: tensor(0.0325)\n",
            "6323 Traning Loss: tensor(0.0325)\n",
            "6324 Traning Loss: tensor(0.0325)\n",
            "6325 Traning Loss: tensor(0.0325)\n",
            "6326 Traning Loss: tensor(0.0325)\n",
            "6327 Traning Loss: tensor(0.0325)\n",
            "6328 Traning Loss: tensor(0.0325)\n",
            "6329 Traning Loss: tensor(0.0325)\n",
            "6330 Traning Loss: tensor(0.0325)\n",
            "6331 Traning Loss: tensor(0.0325)\n",
            "6332 Traning Loss: tensor(0.0325)\n",
            "6333 Traning Loss: tensor(0.0325)\n",
            "6334 Traning Loss: tensor(0.0325)\n",
            "6335 Traning Loss: tensor(0.0325)\n",
            "6336 Traning Loss: tensor(0.0325)\n",
            "6337 Traning Loss: tensor(0.0325)\n",
            "6338 Traning Loss: tensor(0.0325)\n",
            "6339 Traning Loss: tensor(0.0325)\n",
            "6340 Traning Loss: tensor(0.0324)\n",
            "6341 Traning Loss: tensor(0.0324)\n",
            "6342 Traning Loss: tensor(0.0324)\n",
            "6343 Traning Loss: tensor(0.0324)\n",
            "6344 Traning Loss: tensor(0.0324)\n",
            "6345 Traning Loss: tensor(0.0324)\n",
            "6346 Traning Loss: tensor(0.0324)\n",
            "6347 Traning Loss: tensor(0.0324)\n",
            "6348 Traning Loss: tensor(0.0324)\n",
            "6349 Traning Loss: tensor(0.0324)\n",
            "6350 Traning Loss: tensor(0.0324)\n",
            "6351 Traning Loss: tensor(0.0324)\n",
            "6352 Traning Loss: tensor(0.0324)\n",
            "6353 Traning Loss: tensor(0.0324)\n",
            "6354 Traning Loss: tensor(0.0324)\n",
            "6355 Traning Loss: tensor(0.0324)\n",
            "6356 Traning Loss: tensor(0.0324)\n",
            "6357 Traning Loss: tensor(0.0324)\n",
            "6358 Traning Loss: tensor(0.0324)\n",
            "6359 Traning Loss: tensor(0.0324)\n",
            "6360 Traning Loss: tensor(0.0324)\n",
            "6361 Traning Loss: tensor(0.0324)\n",
            "6362 Traning Loss: tensor(0.0324)\n",
            "6363 Traning Loss: tensor(0.0324)\n",
            "6364 Traning Loss: tensor(0.0324)\n",
            "6365 Traning Loss: tensor(0.0324)\n",
            "6366 Traning Loss: tensor(0.0324)\n",
            "6367 Traning Loss: tensor(0.0324)\n",
            "6368 Traning Loss: tensor(0.0324)\n",
            "6369 Traning Loss: tensor(0.0324)\n",
            "6370 Traning Loss: tensor(0.0324)\n",
            "6371 Traning Loss: tensor(0.0324)\n",
            "6372 Traning Loss: tensor(0.0324)\n",
            "6373 Traning Loss: tensor(0.0324)\n",
            "6374 Traning Loss: tensor(0.0324)\n",
            "6375 Traning Loss: tensor(0.0324)\n",
            "6376 Traning Loss: tensor(0.0324)\n",
            "6377 Traning Loss: tensor(0.0324)\n",
            "6378 Traning Loss: tensor(0.0324)\n",
            "6379 Traning Loss: tensor(0.0324)\n",
            "6380 Traning Loss: tensor(0.0323)\n",
            "6381 Traning Loss: tensor(0.0323)\n",
            "6382 Traning Loss: tensor(0.0323)\n",
            "6383 Traning Loss: tensor(0.0323)\n",
            "6384 Traning Loss: tensor(0.0323)\n",
            "6385 Traning Loss: tensor(0.0323)\n",
            "6386 Traning Loss: tensor(0.0323)\n",
            "6387 Traning Loss: tensor(0.0323)\n",
            "6388 Traning Loss: tensor(0.0323)\n",
            "6389 Traning Loss: tensor(0.0323)\n",
            "6390 Traning Loss: tensor(0.0323)\n",
            "6391 Traning Loss: tensor(0.0323)\n",
            "6392 Traning Loss: tensor(0.0323)\n",
            "6393 Traning Loss: tensor(0.0323)\n",
            "6394 Traning Loss: tensor(0.0323)\n",
            "6395 Traning Loss: tensor(0.0323)\n",
            "6396 Traning Loss: tensor(0.0323)\n",
            "6397 Traning Loss: tensor(0.0323)\n",
            "6398 Traning Loss: tensor(0.0323)\n",
            "6399 Traning Loss: tensor(0.0323)\n",
            "6400 Traning Loss: tensor(0.0323)\n",
            "6401 Traning Loss: tensor(0.0323)\n",
            "6402 Traning Loss: tensor(0.0323)\n",
            "6403 Traning Loss: tensor(0.0323)\n",
            "6404 Traning Loss: tensor(0.0323)\n",
            "6405 Traning Loss: tensor(0.0323)\n",
            "6406 Traning Loss: tensor(0.0323)\n",
            "6407 Traning Loss: tensor(0.0323)\n",
            "6408 Traning Loss: tensor(0.0323)\n",
            "6409 Traning Loss: tensor(0.0323)\n",
            "6410 Traning Loss: tensor(0.0323)\n",
            "6411 Traning Loss: tensor(0.0323)\n",
            "6412 Traning Loss: tensor(0.0323)\n",
            "6413 Traning Loss: tensor(0.0323)\n",
            "6414 Traning Loss: tensor(0.0323)\n",
            "6415 Traning Loss: tensor(0.0323)\n",
            "6416 Traning Loss: tensor(0.0323)\n",
            "6417 Traning Loss: tensor(0.0323)\n",
            "6418 Traning Loss: tensor(0.0323)\n",
            "6419 Traning Loss: tensor(0.0323)\n",
            "6420 Traning Loss: tensor(0.0323)\n",
            "6421 Traning Loss: tensor(0.0322)\n",
            "6422 Traning Loss: tensor(0.0322)\n",
            "6423 Traning Loss: tensor(0.0322)\n",
            "6424 Traning Loss: tensor(0.0322)\n",
            "6425 Traning Loss: tensor(0.0322)\n",
            "6426 Traning Loss: tensor(0.0322)\n",
            "6427 Traning Loss: tensor(0.0322)\n",
            "6428 Traning Loss: tensor(0.0322)\n",
            "6429 Traning Loss: tensor(0.0322)\n",
            "6430 Traning Loss: tensor(0.0322)\n",
            "6431 Traning Loss: tensor(0.0322)\n",
            "6432 Traning Loss: tensor(0.0322)\n",
            "6433 Traning Loss: tensor(0.0322)\n",
            "6434 Traning Loss: tensor(0.0322)\n",
            "6435 Traning Loss: tensor(0.0322)\n",
            "6436 Traning Loss: tensor(0.0322)\n",
            "6437 Traning Loss: tensor(0.0322)\n",
            "6438 Traning Loss: tensor(0.0322)\n",
            "6439 Traning Loss: tensor(0.0322)\n",
            "6440 Traning Loss: tensor(0.0322)\n",
            "6441 Traning Loss: tensor(0.0322)\n",
            "6442 Traning Loss: tensor(0.0322)\n",
            "6443 Traning Loss: tensor(0.0322)\n",
            "6444 Traning Loss: tensor(0.0322)\n",
            "6445 Traning Loss: tensor(0.0322)\n",
            "6446 Traning Loss: tensor(0.0322)\n",
            "6447 Traning Loss: tensor(0.0322)\n",
            "6448 Traning Loss: tensor(0.0322)\n",
            "6449 Traning Loss: tensor(0.0322)\n",
            "6450 Traning Loss: tensor(0.0322)\n",
            "6451 Traning Loss: tensor(0.0322)\n",
            "6452 Traning Loss: tensor(0.0322)\n",
            "6453 Traning Loss: tensor(0.0322)\n",
            "6454 Traning Loss: tensor(0.0322)\n",
            "6455 Traning Loss: tensor(0.0322)\n",
            "6456 Traning Loss: tensor(0.0322)\n",
            "6457 Traning Loss: tensor(0.0322)\n",
            "6458 Traning Loss: tensor(0.0322)\n",
            "6459 Traning Loss: tensor(0.0322)\n",
            "6460 Traning Loss: tensor(0.0322)\n",
            "6461 Traning Loss: tensor(0.0321)\n",
            "6462 Traning Loss: tensor(0.0321)\n",
            "6463 Traning Loss: tensor(0.0321)\n",
            "6464 Traning Loss: tensor(0.0321)\n",
            "6465 Traning Loss: tensor(0.0321)\n",
            "6466 Traning Loss: tensor(0.0321)\n",
            "6467 Traning Loss: tensor(0.0321)\n",
            "6468 Traning Loss: tensor(0.0321)\n",
            "6469 Traning Loss: tensor(0.0321)\n",
            "6470 Traning Loss: tensor(0.0321)\n",
            "6471 Traning Loss: tensor(0.0321)\n",
            "6472 Traning Loss: tensor(0.0321)\n",
            "6473 Traning Loss: tensor(0.0321)\n",
            "6474 Traning Loss: tensor(0.0321)\n",
            "6475 Traning Loss: tensor(0.0321)\n",
            "6476 Traning Loss: tensor(0.0321)\n",
            "6477 Traning Loss: tensor(0.0321)\n",
            "6478 Traning Loss: tensor(0.0321)\n",
            "6479 Traning Loss: tensor(0.0321)\n",
            "6480 Traning Loss: tensor(0.0321)\n",
            "6481 Traning Loss: tensor(0.0321)\n",
            "6482 Traning Loss: tensor(0.0321)\n",
            "6483 Traning Loss: tensor(0.0321)\n",
            "6484 Traning Loss: tensor(0.0321)\n",
            "6485 Traning Loss: tensor(0.0321)\n",
            "6486 Traning Loss: tensor(0.0321)\n",
            "6487 Traning Loss: tensor(0.0321)\n",
            "6488 Traning Loss: tensor(0.0321)\n",
            "6489 Traning Loss: tensor(0.0321)\n",
            "6490 Traning Loss: tensor(0.0321)\n",
            "6491 Traning Loss: tensor(0.0321)\n",
            "6492 Traning Loss: tensor(0.0321)\n",
            "6493 Traning Loss: tensor(0.0321)\n",
            "6494 Traning Loss: tensor(0.0321)\n",
            "6495 Traning Loss: tensor(0.0321)\n",
            "6496 Traning Loss: tensor(0.0321)\n",
            "6497 Traning Loss: tensor(0.0321)\n",
            "6498 Traning Loss: tensor(0.0321)\n",
            "6499 Traning Loss: tensor(0.0321)\n",
            "6500 Traning Loss: tensor(0.0321)\n",
            "6501 Traning Loss: tensor(0.0321)\n",
            "6502 Traning Loss: tensor(0.0321)\n",
            "6503 Traning Loss: tensor(0.0320)\n",
            "6504 Traning Loss: tensor(0.0320)\n",
            "6505 Traning Loss: tensor(0.0320)\n",
            "6506 Traning Loss: tensor(0.0320)\n",
            "6507 Traning Loss: tensor(0.0320)\n",
            "6508 Traning Loss: tensor(0.0320)\n",
            "6509 Traning Loss: tensor(0.0320)\n",
            "6510 Traning Loss: tensor(0.0320)\n",
            "6511 Traning Loss: tensor(0.0320)\n",
            "6512 Traning Loss: tensor(0.0320)\n",
            "6513 Traning Loss: tensor(0.0320)\n",
            "6514 Traning Loss: tensor(0.0320)\n",
            "6515 Traning Loss: tensor(0.0320)\n",
            "6516 Traning Loss: tensor(0.0320)\n",
            "6517 Traning Loss: tensor(0.0320)\n",
            "6518 Traning Loss: tensor(0.0320)\n",
            "6519 Traning Loss: tensor(0.0320)\n",
            "6520 Traning Loss: tensor(0.0320)\n",
            "6521 Traning Loss: tensor(0.0320)\n",
            "6522 Traning Loss: tensor(0.0320)\n",
            "6523 Traning Loss: tensor(0.0320)\n",
            "6524 Traning Loss: tensor(0.0320)\n",
            "6525 Traning Loss: tensor(0.0320)\n",
            "6526 Traning Loss: tensor(0.0320)\n",
            "6527 Traning Loss: tensor(0.0320)\n",
            "6528 Traning Loss: tensor(0.0320)\n",
            "6529 Traning Loss: tensor(0.0320)\n",
            "6530 Traning Loss: tensor(0.0320)\n",
            "6531 Traning Loss: tensor(0.0320)\n",
            "6532 Traning Loss: tensor(0.0320)\n",
            "6533 Traning Loss: tensor(0.0320)\n",
            "6534 Traning Loss: tensor(0.0320)\n",
            "6535 Traning Loss: tensor(0.0320)\n",
            "6536 Traning Loss: tensor(0.0320)\n",
            "6537 Traning Loss: tensor(0.0320)\n",
            "6538 Traning Loss: tensor(0.0320)\n",
            "6539 Traning Loss: tensor(0.0320)\n",
            "6540 Traning Loss: tensor(0.0320)\n",
            "6541 Traning Loss: tensor(0.0320)\n",
            "6542 Traning Loss: tensor(0.0320)\n",
            "6543 Traning Loss: tensor(0.0320)\n",
            "6544 Traning Loss: tensor(0.0320)\n",
            "6545 Traning Loss: tensor(0.0319)\n",
            "6546 Traning Loss: tensor(0.0319)\n",
            "6547 Traning Loss: tensor(0.0319)\n",
            "6548 Traning Loss: tensor(0.0319)\n",
            "6549 Traning Loss: tensor(0.0319)\n",
            "6550 Traning Loss: tensor(0.0319)\n",
            "6551 Traning Loss: tensor(0.0319)\n",
            "6552 Traning Loss: tensor(0.0319)\n",
            "6553 Traning Loss: tensor(0.0319)\n",
            "6554 Traning Loss: tensor(0.0319)\n",
            "6555 Traning Loss: tensor(0.0319)\n",
            "6556 Traning Loss: tensor(0.0319)\n",
            "6557 Traning Loss: tensor(0.0319)\n",
            "6558 Traning Loss: tensor(0.0319)\n",
            "6559 Traning Loss: tensor(0.0319)\n",
            "6560 Traning Loss: tensor(0.0319)\n",
            "6561 Traning Loss: tensor(0.0319)\n",
            "6562 Traning Loss: tensor(0.0319)\n",
            "6563 Traning Loss: tensor(0.0319)\n",
            "6564 Traning Loss: tensor(0.0319)\n",
            "6565 Traning Loss: tensor(0.0319)\n",
            "6566 Traning Loss: tensor(0.0319)\n",
            "6567 Traning Loss: tensor(0.0319)\n",
            "6568 Traning Loss: tensor(0.0319)\n",
            "6569 Traning Loss: tensor(0.0319)\n",
            "6570 Traning Loss: tensor(0.0319)\n",
            "6571 Traning Loss: tensor(0.0319)\n",
            "6572 Traning Loss: tensor(0.0319)\n",
            "6573 Traning Loss: tensor(0.0319)\n",
            "6574 Traning Loss: tensor(0.0319)\n",
            "6575 Traning Loss: tensor(0.0319)\n",
            "6576 Traning Loss: tensor(0.0319)\n",
            "6577 Traning Loss: tensor(0.0319)\n",
            "6578 Traning Loss: tensor(0.0319)\n",
            "6579 Traning Loss: tensor(0.0319)\n",
            "6580 Traning Loss: tensor(0.0319)\n",
            "6581 Traning Loss: tensor(0.0319)\n",
            "6582 Traning Loss: tensor(0.0319)\n",
            "6583 Traning Loss: tensor(0.0319)\n",
            "6584 Traning Loss: tensor(0.0319)\n",
            "6585 Traning Loss: tensor(0.0319)\n",
            "6586 Traning Loss: tensor(0.0319)\n",
            "6587 Traning Loss: tensor(0.0319)\n",
            "6588 Traning Loss: tensor(0.0318)\n",
            "6589 Traning Loss: tensor(0.0318)\n",
            "6590 Traning Loss: tensor(0.0318)\n",
            "6591 Traning Loss: tensor(0.0318)\n",
            "6592 Traning Loss: tensor(0.0318)\n",
            "6593 Traning Loss: tensor(0.0318)\n",
            "6594 Traning Loss: tensor(0.0318)\n",
            "6595 Traning Loss: tensor(0.0318)\n",
            "6596 Traning Loss: tensor(0.0318)\n",
            "6597 Traning Loss: tensor(0.0318)\n",
            "6598 Traning Loss: tensor(0.0318)\n",
            "6599 Traning Loss: tensor(0.0318)\n",
            "6600 Traning Loss: tensor(0.0318)\n",
            "6601 Traning Loss: tensor(0.0318)\n",
            "6602 Traning Loss: tensor(0.0318)\n",
            "6603 Traning Loss: tensor(0.0318)\n",
            "6604 Traning Loss: tensor(0.0318)\n",
            "6605 Traning Loss: tensor(0.0318)\n",
            "6606 Traning Loss: tensor(0.0318)\n",
            "6607 Traning Loss: tensor(0.0318)\n",
            "6608 Traning Loss: tensor(0.0318)\n",
            "6609 Traning Loss: tensor(0.0318)\n",
            "6610 Traning Loss: tensor(0.0318)\n",
            "6611 Traning Loss: tensor(0.0318)\n",
            "6612 Traning Loss: tensor(0.0318)\n",
            "6613 Traning Loss: tensor(0.0318)\n",
            "6614 Traning Loss: tensor(0.0318)\n",
            "6615 Traning Loss: tensor(0.0318)\n",
            "6616 Traning Loss: tensor(0.0318)\n",
            "6617 Traning Loss: tensor(0.0318)\n",
            "6618 Traning Loss: tensor(0.0318)\n",
            "6619 Traning Loss: tensor(0.0318)\n",
            "6620 Traning Loss: tensor(0.0318)\n",
            "6621 Traning Loss: tensor(0.0318)\n",
            "6622 Traning Loss: tensor(0.0318)\n",
            "6623 Traning Loss: tensor(0.0318)\n",
            "6624 Traning Loss: tensor(0.0318)\n",
            "6625 Traning Loss: tensor(0.0318)\n",
            "6626 Traning Loss: tensor(0.0318)\n",
            "6627 Traning Loss: tensor(0.0318)\n",
            "6628 Traning Loss: tensor(0.0318)\n",
            "6629 Traning Loss: tensor(0.0318)\n",
            "6630 Traning Loss: tensor(0.0318)\n",
            "6631 Traning Loss: tensor(0.0317)\n",
            "6632 Traning Loss: tensor(0.0317)\n",
            "6633 Traning Loss: tensor(0.0317)\n",
            "6634 Traning Loss: tensor(0.0317)\n",
            "6635 Traning Loss: tensor(0.0317)\n",
            "6636 Traning Loss: tensor(0.0317)\n",
            "6637 Traning Loss: tensor(0.0317)\n",
            "6638 Traning Loss: tensor(0.0317)\n",
            "6639 Traning Loss: tensor(0.0317)\n",
            "6640 Traning Loss: tensor(0.0317)\n",
            "6641 Traning Loss: tensor(0.0317)\n",
            "6642 Traning Loss: tensor(0.0317)\n",
            "6643 Traning Loss: tensor(0.0317)\n",
            "6644 Traning Loss: tensor(0.0317)\n",
            "6645 Traning Loss: tensor(0.0317)\n",
            "6646 Traning Loss: tensor(0.0317)\n",
            "6647 Traning Loss: tensor(0.0317)\n",
            "6648 Traning Loss: tensor(0.0317)\n",
            "6649 Traning Loss: tensor(0.0317)\n",
            "6650 Traning Loss: tensor(0.0317)\n",
            "6651 Traning Loss: tensor(0.0317)\n",
            "6652 Traning Loss: tensor(0.0317)\n",
            "6653 Traning Loss: tensor(0.0317)\n",
            "6654 Traning Loss: tensor(0.0317)\n",
            "6655 Traning Loss: tensor(0.0317)\n",
            "6656 Traning Loss: tensor(0.0317)\n",
            "6657 Traning Loss: tensor(0.0317)\n",
            "6658 Traning Loss: tensor(0.0317)\n",
            "6659 Traning Loss: tensor(0.0317)\n",
            "6660 Traning Loss: tensor(0.0317)\n",
            "6661 Traning Loss: tensor(0.0317)\n",
            "6662 Traning Loss: tensor(0.0317)\n",
            "6663 Traning Loss: tensor(0.0317)\n",
            "6664 Traning Loss: tensor(0.0317)\n",
            "6665 Traning Loss: tensor(0.0317)\n",
            "6666 Traning Loss: tensor(0.0317)\n",
            "6667 Traning Loss: tensor(0.0317)\n",
            "6668 Traning Loss: tensor(0.0317)\n",
            "6669 Traning Loss: tensor(0.0317)\n",
            "6670 Traning Loss: tensor(0.0317)\n",
            "6671 Traning Loss: tensor(0.0317)\n",
            "6672 Traning Loss: tensor(0.0317)\n",
            "6673 Traning Loss: tensor(0.0317)\n",
            "6674 Traning Loss: tensor(0.0317)\n",
            "6675 Traning Loss: tensor(0.0316)\n",
            "6676 Traning Loss: tensor(0.0316)\n",
            "6677 Traning Loss: tensor(0.0316)\n",
            "6678 Traning Loss: tensor(0.0316)\n",
            "6679 Traning Loss: tensor(0.0316)\n",
            "6680 Traning Loss: tensor(0.0316)\n",
            "6681 Traning Loss: tensor(0.0316)\n",
            "6682 Traning Loss: tensor(0.0316)\n",
            "6683 Traning Loss: tensor(0.0316)\n",
            "6684 Traning Loss: tensor(0.0316)\n",
            "6685 Traning Loss: tensor(0.0316)\n",
            "6686 Traning Loss: tensor(0.0316)\n",
            "6687 Traning Loss: tensor(0.0316)\n",
            "6688 Traning Loss: tensor(0.0316)\n",
            "6689 Traning Loss: tensor(0.0316)\n",
            "6690 Traning Loss: tensor(0.0316)\n",
            "6691 Traning Loss: tensor(0.0316)\n",
            "6692 Traning Loss: tensor(0.0316)\n",
            "6693 Traning Loss: tensor(0.0316)\n",
            "6694 Traning Loss: tensor(0.0316)\n",
            "6695 Traning Loss: tensor(0.0316)\n",
            "6696 Traning Loss: tensor(0.0316)\n",
            "6697 Traning Loss: tensor(0.0316)\n",
            "6698 Traning Loss: tensor(0.0316)\n",
            "6699 Traning Loss: tensor(0.0316)\n",
            "6700 Traning Loss: tensor(0.0316)\n",
            "6701 Traning Loss: tensor(0.0316)\n",
            "6702 Traning Loss: tensor(0.0316)\n",
            "6703 Traning Loss: tensor(0.0316)\n",
            "6704 Traning Loss: tensor(0.0316)\n",
            "6705 Traning Loss: tensor(0.0316)\n",
            "6706 Traning Loss: tensor(0.0316)\n",
            "6707 Traning Loss: tensor(0.0316)\n",
            "6708 Traning Loss: tensor(0.0316)\n",
            "6709 Traning Loss: tensor(0.0316)\n",
            "6710 Traning Loss: tensor(0.0316)\n",
            "6711 Traning Loss: tensor(0.0316)\n",
            "6712 Traning Loss: tensor(0.0316)\n",
            "6713 Traning Loss: tensor(0.0316)\n",
            "6714 Traning Loss: tensor(0.0316)\n",
            "6715 Traning Loss: tensor(0.0316)\n",
            "6716 Traning Loss: tensor(0.0316)\n",
            "6717 Traning Loss: tensor(0.0316)\n",
            "6718 Traning Loss: tensor(0.0316)\n",
            "6719 Traning Loss: tensor(0.0315)\n",
            "6720 Traning Loss: tensor(0.0315)\n",
            "6721 Traning Loss: tensor(0.0315)\n",
            "6722 Traning Loss: tensor(0.0315)\n",
            "6723 Traning Loss: tensor(0.0315)\n",
            "6724 Traning Loss: tensor(0.0315)\n",
            "6725 Traning Loss: tensor(0.0315)\n",
            "6726 Traning Loss: tensor(0.0315)\n",
            "6727 Traning Loss: tensor(0.0315)\n",
            "6728 Traning Loss: tensor(0.0315)\n",
            "6729 Traning Loss: tensor(0.0315)\n",
            "6730 Traning Loss: tensor(0.0315)\n",
            "6731 Traning Loss: tensor(0.0315)\n",
            "6732 Traning Loss: tensor(0.0315)\n",
            "6733 Traning Loss: tensor(0.0315)\n",
            "6734 Traning Loss: tensor(0.0315)\n",
            "6735 Traning Loss: tensor(0.0315)\n",
            "6736 Traning Loss: tensor(0.0315)\n",
            "6737 Traning Loss: tensor(0.0315)\n",
            "6738 Traning Loss: tensor(0.0315)\n",
            "6739 Traning Loss: tensor(0.0315)\n",
            "6740 Traning Loss: tensor(0.0315)\n",
            "6741 Traning Loss: tensor(0.0315)\n",
            "6742 Traning Loss: tensor(0.0315)\n",
            "6743 Traning Loss: tensor(0.0315)\n",
            "6744 Traning Loss: tensor(0.0315)\n",
            "6745 Traning Loss: tensor(0.0315)\n",
            "6746 Traning Loss: tensor(0.0315)\n",
            "6747 Traning Loss: tensor(0.0315)\n",
            "6748 Traning Loss: tensor(0.0315)\n",
            "6749 Traning Loss: tensor(0.0315)\n",
            "6750 Traning Loss: tensor(0.0315)\n",
            "6751 Traning Loss: tensor(0.0315)\n",
            "6752 Traning Loss: tensor(0.0315)\n",
            "6753 Traning Loss: tensor(0.0315)\n",
            "6754 Traning Loss: tensor(0.0315)\n",
            "6755 Traning Loss: tensor(0.0315)\n",
            "6756 Traning Loss: tensor(0.0315)\n",
            "6757 Traning Loss: tensor(0.0315)\n",
            "6758 Traning Loss: tensor(0.0315)\n",
            "6759 Traning Loss: tensor(0.0315)\n",
            "6760 Traning Loss: tensor(0.0315)\n",
            "6761 Traning Loss: tensor(0.0315)\n",
            "6762 Traning Loss: tensor(0.0315)\n",
            "6763 Traning Loss: tensor(0.0315)\n",
            "6764 Traning Loss: tensor(0.0314)\n",
            "6765 Traning Loss: tensor(0.0314)\n",
            "6766 Traning Loss: tensor(0.0314)\n",
            "6767 Traning Loss: tensor(0.0314)\n",
            "6768 Traning Loss: tensor(0.0314)\n",
            "6769 Traning Loss: tensor(0.0314)\n",
            "6770 Traning Loss: tensor(0.0314)\n",
            "6771 Traning Loss: tensor(0.0314)\n",
            "6772 Traning Loss: tensor(0.0314)\n",
            "6773 Traning Loss: tensor(0.0314)\n",
            "6774 Traning Loss: tensor(0.0314)\n",
            "6775 Traning Loss: tensor(0.0314)\n",
            "6776 Traning Loss: tensor(0.0314)\n",
            "6777 Traning Loss: tensor(0.0314)\n",
            "6778 Traning Loss: tensor(0.0314)\n",
            "6779 Traning Loss: tensor(0.0314)\n",
            "6780 Traning Loss: tensor(0.0314)\n",
            "6781 Traning Loss: tensor(0.0314)\n",
            "6782 Traning Loss: tensor(0.0314)\n",
            "6783 Traning Loss: tensor(0.0314)\n",
            "6784 Traning Loss: tensor(0.0314)\n",
            "6785 Traning Loss: tensor(0.0314)\n",
            "6786 Traning Loss: tensor(0.0314)\n",
            "6787 Traning Loss: tensor(0.0314)\n",
            "6788 Traning Loss: tensor(0.0314)\n",
            "6789 Traning Loss: tensor(0.0314)\n",
            "6790 Traning Loss: tensor(0.0314)\n",
            "6791 Traning Loss: tensor(0.0314)\n",
            "6792 Traning Loss: tensor(0.0314)\n",
            "6793 Traning Loss: tensor(0.0314)\n",
            "6794 Traning Loss: tensor(0.0314)\n",
            "6795 Traning Loss: tensor(0.0314)\n",
            "6796 Traning Loss: tensor(0.0314)\n",
            "6797 Traning Loss: tensor(0.0314)\n",
            "6798 Traning Loss: tensor(0.0314)\n",
            "6799 Traning Loss: tensor(0.0314)\n",
            "6800 Traning Loss: tensor(0.0314)\n",
            "6801 Traning Loss: tensor(0.0314)\n",
            "6802 Traning Loss: tensor(0.0314)\n",
            "6803 Traning Loss: tensor(0.0314)\n",
            "6804 Traning Loss: tensor(0.0314)\n",
            "6805 Traning Loss: tensor(0.0314)\n",
            "6806 Traning Loss: tensor(0.0314)\n",
            "6807 Traning Loss: tensor(0.0314)\n",
            "6808 Traning Loss: tensor(0.0314)\n",
            "6809 Traning Loss: tensor(0.0314)\n",
            "6810 Traning Loss: tensor(0.0313)\n",
            "6811 Traning Loss: tensor(0.0313)\n",
            "6812 Traning Loss: tensor(0.0313)\n",
            "6813 Traning Loss: tensor(0.0313)\n",
            "6814 Traning Loss: tensor(0.0313)\n",
            "6815 Traning Loss: tensor(0.0313)\n",
            "6816 Traning Loss: tensor(0.0313)\n",
            "6817 Traning Loss: tensor(0.0313)\n",
            "6818 Traning Loss: tensor(0.0313)\n",
            "6819 Traning Loss: tensor(0.0313)\n",
            "6820 Traning Loss: tensor(0.0313)\n",
            "6821 Traning Loss: tensor(0.0313)\n",
            "6822 Traning Loss: tensor(0.0313)\n",
            "6823 Traning Loss: tensor(0.0313)\n",
            "6824 Traning Loss: tensor(0.0313)\n",
            "6825 Traning Loss: tensor(0.0313)\n",
            "6826 Traning Loss: tensor(0.0313)\n",
            "6827 Traning Loss: tensor(0.0313)\n",
            "6828 Traning Loss: tensor(0.0313)\n",
            "6829 Traning Loss: tensor(0.0313)\n",
            "6830 Traning Loss: tensor(0.0313)\n",
            "6831 Traning Loss: tensor(0.0313)\n",
            "6832 Traning Loss: tensor(0.0313)\n",
            "6833 Traning Loss: tensor(0.0313)\n",
            "6834 Traning Loss: tensor(0.0313)\n",
            "6835 Traning Loss: tensor(0.0313)\n",
            "6836 Traning Loss: tensor(0.0313)\n",
            "6837 Traning Loss: tensor(0.0313)\n",
            "6838 Traning Loss: tensor(0.0313)\n",
            "6839 Traning Loss: tensor(0.0313)\n",
            "6840 Traning Loss: tensor(0.0313)\n",
            "6841 Traning Loss: tensor(0.0313)\n",
            "6842 Traning Loss: tensor(0.0313)\n",
            "6843 Traning Loss: tensor(0.0313)\n",
            "6844 Traning Loss: tensor(0.0313)\n",
            "6845 Traning Loss: tensor(0.0313)\n",
            "6846 Traning Loss: tensor(0.0313)\n",
            "6847 Traning Loss: tensor(0.0313)\n",
            "6848 Traning Loss: tensor(0.0313)\n",
            "6849 Traning Loss: tensor(0.0313)\n",
            "6850 Traning Loss: tensor(0.0313)\n",
            "6851 Traning Loss: tensor(0.0313)\n",
            "6852 Traning Loss: tensor(0.0313)\n",
            "6853 Traning Loss: tensor(0.0313)\n",
            "6854 Traning Loss: tensor(0.0313)\n",
            "6855 Traning Loss: tensor(0.0313)\n",
            "6856 Traning Loss: tensor(0.0312)\n",
            "6857 Traning Loss: tensor(0.0312)\n",
            "6858 Traning Loss: tensor(0.0312)\n",
            "6859 Traning Loss: tensor(0.0312)\n",
            "6860 Traning Loss: tensor(0.0312)\n",
            "6861 Traning Loss: tensor(0.0312)\n",
            "6862 Traning Loss: tensor(0.0312)\n",
            "6863 Traning Loss: tensor(0.0312)\n",
            "6864 Traning Loss: tensor(0.0312)\n",
            "6865 Traning Loss: tensor(0.0312)\n",
            "6866 Traning Loss: tensor(0.0312)\n",
            "6867 Traning Loss: tensor(0.0312)\n",
            "6868 Traning Loss: tensor(0.0312)\n",
            "6869 Traning Loss: tensor(0.0312)\n",
            "6870 Traning Loss: tensor(0.0312)\n",
            "6871 Traning Loss: tensor(0.0312)\n",
            "6872 Traning Loss: tensor(0.0312)\n",
            "6873 Traning Loss: tensor(0.0312)\n",
            "6874 Traning Loss: tensor(0.0312)\n",
            "6875 Traning Loss: tensor(0.0312)\n",
            "6876 Traning Loss: tensor(0.0312)\n",
            "6877 Traning Loss: tensor(0.0312)\n",
            "6878 Traning Loss: tensor(0.0312)\n",
            "6879 Traning Loss: tensor(0.0312)\n",
            "6880 Traning Loss: tensor(0.0312)\n",
            "6881 Traning Loss: tensor(0.0312)\n",
            "6882 Traning Loss: tensor(0.0312)\n",
            "6883 Traning Loss: tensor(0.0312)\n",
            "6884 Traning Loss: tensor(0.0312)\n",
            "6885 Traning Loss: tensor(0.0312)\n",
            "6886 Traning Loss: tensor(0.0312)\n",
            "6887 Traning Loss: tensor(0.0312)\n",
            "6888 Traning Loss: tensor(0.0312)\n",
            "6889 Traning Loss: tensor(0.0312)\n",
            "6890 Traning Loss: tensor(0.0312)\n",
            "6891 Traning Loss: tensor(0.0312)\n",
            "6892 Traning Loss: tensor(0.0312)\n",
            "6893 Traning Loss: tensor(0.0312)\n",
            "6894 Traning Loss: tensor(0.0312)\n",
            "6895 Traning Loss: tensor(0.0312)\n",
            "6896 Traning Loss: tensor(0.0312)\n",
            "6897 Traning Loss: tensor(0.0312)\n",
            "6898 Traning Loss: tensor(0.0312)\n",
            "6899 Traning Loss: tensor(0.0312)\n",
            "6900 Traning Loss: tensor(0.0312)\n",
            "6901 Traning Loss: tensor(0.0312)\n",
            "6902 Traning Loss: tensor(0.0312)\n",
            "6903 Traning Loss: tensor(0.0311)\n",
            "6904 Traning Loss: tensor(0.0311)\n",
            "6905 Traning Loss: tensor(0.0311)\n",
            "6906 Traning Loss: tensor(0.0311)\n",
            "6907 Traning Loss: tensor(0.0311)\n",
            "6908 Traning Loss: tensor(0.0311)\n",
            "6909 Traning Loss: tensor(0.0311)\n",
            "6910 Traning Loss: tensor(0.0311)\n",
            "6911 Traning Loss: tensor(0.0311)\n",
            "6912 Traning Loss: tensor(0.0311)\n",
            "6913 Traning Loss: tensor(0.0311)\n",
            "6914 Traning Loss: tensor(0.0311)\n",
            "6915 Traning Loss: tensor(0.0311)\n",
            "6916 Traning Loss: tensor(0.0311)\n",
            "6917 Traning Loss: tensor(0.0311)\n",
            "6918 Traning Loss: tensor(0.0311)\n",
            "6919 Traning Loss: tensor(0.0311)\n",
            "6920 Traning Loss: tensor(0.0311)\n",
            "6921 Traning Loss: tensor(0.0311)\n",
            "6922 Traning Loss: tensor(0.0311)\n",
            "6923 Traning Loss: tensor(0.0311)\n",
            "6924 Traning Loss: tensor(0.0311)\n",
            "6925 Traning Loss: tensor(0.0311)\n",
            "6926 Traning Loss: tensor(0.0311)\n",
            "6927 Traning Loss: tensor(0.0311)\n",
            "6928 Traning Loss: tensor(0.0311)\n",
            "6929 Traning Loss: tensor(0.0311)\n",
            "6930 Traning Loss: tensor(0.0311)\n",
            "6931 Traning Loss: tensor(0.0311)\n",
            "6932 Traning Loss: tensor(0.0311)\n",
            "6933 Traning Loss: tensor(0.0311)\n",
            "6934 Traning Loss: tensor(0.0311)\n",
            "6935 Traning Loss: tensor(0.0311)\n",
            "6936 Traning Loss: tensor(0.0311)\n",
            "6937 Traning Loss: tensor(0.0311)\n",
            "6938 Traning Loss: tensor(0.0311)\n",
            "6939 Traning Loss: tensor(0.0311)\n",
            "6940 Traning Loss: tensor(0.0311)\n",
            "6941 Traning Loss: tensor(0.0311)\n",
            "6942 Traning Loss: tensor(0.0311)\n",
            "6943 Traning Loss: tensor(0.0311)\n",
            "6944 Traning Loss: tensor(0.0311)\n",
            "6945 Traning Loss: tensor(0.0311)\n",
            "6946 Traning Loss: tensor(0.0311)\n",
            "6947 Traning Loss: tensor(0.0311)\n",
            "6948 Traning Loss: tensor(0.0311)\n",
            "6949 Traning Loss: tensor(0.0311)\n",
            "6950 Traning Loss: tensor(0.0311)\n",
            "6951 Traning Loss: tensor(0.0310)\n",
            "6952 Traning Loss: tensor(0.0310)\n",
            "6953 Traning Loss: tensor(0.0310)\n",
            "6954 Traning Loss: tensor(0.0310)\n",
            "6955 Traning Loss: tensor(0.0310)\n",
            "6956 Traning Loss: tensor(0.0310)\n",
            "6957 Traning Loss: tensor(0.0310)\n",
            "6958 Traning Loss: tensor(0.0310)\n",
            "6959 Traning Loss: tensor(0.0310)\n",
            "6960 Traning Loss: tensor(0.0310)\n",
            "6961 Traning Loss: tensor(0.0310)\n",
            "6962 Traning Loss: tensor(0.0310)\n",
            "6963 Traning Loss: tensor(0.0310)\n",
            "6964 Traning Loss: tensor(0.0310)\n",
            "6965 Traning Loss: tensor(0.0310)\n",
            "6966 Traning Loss: tensor(0.0310)\n",
            "6967 Traning Loss: tensor(0.0310)\n",
            "6968 Traning Loss: tensor(0.0310)\n",
            "6969 Traning Loss: tensor(0.0310)\n",
            "6970 Traning Loss: tensor(0.0310)\n",
            "6971 Traning Loss: tensor(0.0310)\n",
            "6972 Traning Loss: tensor(0.0310)\n",
            "6973 Traning Loss: tensor(0.0310)\n",
            "6974 Traning Loss: tensor(0.0310)\n",
            "6975 Traning Loss: tensor(0.0310)\n",
            "6976 Traning Loss: tensor(0.0310)\n",
            "6977 Traning Loss: tensor(0.0310)\n",
            "6978 Traning Loss: tensor(0.0310)\n",
            "6979 Traning Loss: tensor(0.0310)\n",
            "6980 Traning Loss: tensor(0.0310)\n",
            "6981 Traning Loss: tensor(0.0310)\n",
            "6982 Traning Loss: tensor(0.0310)\n",
            "6983 Traning Loss: tensor(0.0310)\n",
            "6984 Traning Loss: tensor(0.0310)\n",
            "6985 Traning Loss: tensor(0.0310)\n",
            "6986 Traning Loss: tensor(0.0310)\n",
            "6987 Traning Loss: tensor(0.0310)\n",
            "6988 Traning Loss: tensor(0.0310)\n",
            "6989 Traning Loss: tensor(0.0310)\n",
            "6990 Traning Loss: tensor(0.0310)\n",
            "6991 Traning Loss: tensor(0.0310)\n",
            "6992 Traning Loss: tensor(0.0310)\n",
            "6993 Traning Loss: tensor(0.0310)\n",
            "6994 Traning Loss: tensor(0.0310)\n",
            "6995 Traning Loss: tensor(0.0310)\n",
            "6996 Traning Loss: tensor(0.0310)\n",
            "6997 Traning Loss: tensor(0.0310)\n",
            "6998 Traning Loss: tensor(0.0310)\n",
            "6999 Traning Loss: tensor(0.0309)\n",
            "7000 Traning Loss: tensor(0.0309)\n",
            "7001 Traning Loss: tensor(0.0309)\n",
            "7002 Traning Loss: tensor(0.0309)\n",
            "7003 Traning Loss: tensor(0.0309)\n",
            "7004 Traning Loss: tensor(0.0309)\n",
            "7005 Traning Loss: tensor(0.0309)\n",
            "7006 Traning Loss: tensor(0.0309)\n",
            "7007 Traning Loss: tensor(0.0309)\n",
            "7008 Traning Loss: tensor(0.0309)\n",
            "7009 Traning Loss: tensor(0.0309)\n",
            "7010 Traning Loss: tensor(0.0309)\n",
            "7011 Traning Loss: tensor(0.0309)\n",
            "7012 Traning Loss: tensor(0.0309)\n",
            "7013 Traning Loss: tensor(0.0309)\n",
            "7014 Traning Loss: tensor(0.0309)\n",
            "7015 Traning Loss: tensor(0.0309)\n",
            "7016 Traning Loss: tensor(0.0309)\n",
            "7017 Traning Loss: tensor(0.0309)\n",
            "7018 Traning Loss: tensor(0.0309)\n",
            "7019 Traning Loss: tensor(0.0309)\n",
            "7020 Traning Loss: tensor(0.0309)\n",
            "7021 Traning Loss: tensor(0.0309)\n",
            "7022 Traning Loss: tensor(0.0309)\n",
            "7023 Traning Loss: tensor(0.0309)\n",
            "7024 Traning Loss: tensor(0.0309)\n",
            "7025 Traning Loss: tensor(0.0309)\n",
            "7026 Traning Loss: tensor(0.0309)\n",
            "7027 Traning Loss: tensor(0.0309)\n",
            "7028 Traning Loss: tensor(0.0309)\n",
            "7029 Traning Loss: tensor(0.0309)\n",
            "7030 Traning Loss: tensor(0.0309)\n",
            "7031 Traning Loss: tensor(0.0309)\n",
            "7032 Traning Loss: tensor(0.0309)\n",
            "7033 Traning Loss: tensor(0.0309)\n",
            "7034 Traning Loss: tensor(0.0309)\n",
            "7035 Traning Loss: tensor(0.0309)\n",
            "7036 Traning Loss: tensor(0.0309)\n",
            "7037 Traning Loss: tensor(0.0309)\n",
            "7038 Traning Loss: tensor(0.0309)\n",
            "7039 Traning Loss: tensor(0.0309)\n",
            "7040 Traning Loss: tensor(0.0309)\n",
            "7041 Traning Loss: tensor(0.0309)\n",
            "7042 Traning Loss: tensor(0.0309)\n",
            "7043 Traning Loss: tensor(0.0309)\n",
            "7044 Traning Loss: tensor(0.0309)\n",
            "7045 Traning Loss: tensor(0.0309)\n",
            "7046 Traning Loss: tensor(0.0309)\n",
            "7047 Traning Loss: tensor(0.0309)\n",
            "7048 Traning Loss: tensor(0.0308)\n",
            "7049 Traning Loss: tensor(0.0308)\n",
            "7050 Traning Loss: tensor(0.0308)\n",
            "7051 Traning Loss: tensor(0.0308)\n",
            "7052 Traning Loss: tensor(0.0308)\n",
            "7053 Traning Loss: tensor(0.0308)\n",
            "7054 Traning Loss: tensor(0.0308)\n",
            "7055 Traning Loss: tensor(0.0308)\n",
            "7056 Traning Loss: tensor(0.0308)\n",
            "7057 Traning Loss: tensor(0.0308)\n",
            "7058 Traning Loss: tensor(0.0308)\n",
            "7059 Traning Loss: tensor(0.0308)\n",
            "7060 Traning Loss: tensor(0.0308)\n",
            "7061 Traning Loss: tensor(0.0308)\n",
            "7062 Traning Loss: tensor(0.0308)\n",
            "7063 Traning Loss: tensor(0.0308)\n",
            "7064 Traning Loss: tensor(0.0308)\n",
            "7065 Traning Loss: tensor(0.0308)\n",
            "7066 Traning Loss: tensor(0.0308)\n",
            "7067 Traning Loss: tensor(0.0308)\n",
            "7068 Traning Loss: tensor(0.0308)\n",
            "7069 Traning Loss: tensor(0.0308)\n",
            "7070 Traning Loss: tensor(0.0308)\n",
            "7071 Traning Loss: tensor(0.0308)\n",
            "7072 Traning Loss: tensor(0.0308)\n",
            "7073 Traning Loss: tensor(0.0308)\n",
            "7074 Traning Loss: tensor(0.0308)\n",
            "7075 Traning Loss: tensor(0.0308)\n",
            "7076 Traning Loss: tensor(0.0308)\n",
            "7077 Traning Loss: tensor(0.0308)\n",
            "7078 Traning Loss: tensor(0.0308)\n",
            "7079 Traning Loss: tensor(0.0308)\n",
            "7080 Traning Loss: tensor(0.0308)\n",
            "7081 Traning Loss: tensor(0.0308)\n",
            "7082 Traning Loss: tensor(0.0308)\n",
            "7083 Traning Loss: tensor(0.0308)\n",
            "7084 Traning Loss: tensor(0.0308)\n",
            "7085 Traning Loss: tensor(0.0308)\n",
            "7086 Traning Loss: tensor(0.0308)\n",
            "7087 Traning Loss: tensor(0.0308)\n",
            "7088 Traning Loss: tensor(0.0308)\n",
            "7089 Traning Loss: tensor(0.0308)\n",
            "7090 Traning Loss: tensor(0.0308)\n",
            "7091 Traning Loss: tensor(0.0308)\n",
            "7092 Traning Loss: tensor(0.0308)\n",
            "7093 Traning Loss: tensor(0.0308)\n",
            "7094 Traning Loss: tensor(0.0308)\n",
            "7095 Traning Loss: tensor(0.0308)\n",
            "7096 Traning Loss: tensor(0.0308)\n",
            "7097 Traning Loss: tensor(0.0308)\n",
            "7098 Traning Loss: tensor(0.0307)\n",
            "7099 Traning Loss: tensor(0.0307)\n",
            "7100 Traning Loss: tensor(0.0307)\n",
            "7101 Traning Loss: tensor(0.0307)\n",
            "7102 Traning Loss: tensor(0.0307)\n",
            "7103 Traning Loss: tensor(0.0307)\n",
            "7104 Traning Loss: tensor(0.0307)\n",
            "7105 Traning Loss: tensor(0.0307)\n",
            "7106 Traning Loss: tensor(0.0307)\n",
            "7107 Traning Loss: tensor(0.0307)\n",
            "7108 Traning Loss: tensor(0.0307)\n",
            "7109 Traning Loss: tensor(0.0307)\n",
            "7110 Traning Loss: tensor(0.0307)\n",
            "7111 Traning Loss: tensor(0.0307)\n",
            "7112 Traning Loss: tensor(0.0307)\n",
            "7113 Traning Loss: tensor(0.0307)\n",
            "7114 Traning Loss: tensor(0.0307)\n",
            "7115 Traning Loss: tensor(0.0307)\n",
            "7116 Traning Loss: tensor(0.0307)\n",
            "7117 Traning Loss: tensor(0.0307)\n",
            "7118 Traning Loss: tensor(0.0307)\n",
            "7119 Traning Loss: tensor(0.0307)\n",
            "7120 Traning Loss: tensor(0.0307)\n",
            "7121 Traning Loss: tensor(0.0307)\n",
            "7122 Traning Loss: tensor(0.0307)\n",
            "7123 Traning Loss: tensor(0.0307)\n",
            "7124 Traning Loss: tensor(0.0307)\n",
            "7125 Traning Loss: tensor(0.0307)\n",
            "7126 Traning Loss: tensor(0.0307)\n",
            "7127 Traning Loss: tensor(0.0307)\n",
            "7128 Traning Loss: tensor(0.0307)\n",
            "7129 Traning Loss: tensor(0.0307)\n",
            "7130 Traning Loss: tensor(0.0307)\n",
            "7131 Traning Loss: tensor(0.0307)\n",
            "7132 Traning Loss: tensor(0.0307)\n",
            "7133 Traning Loss: tensor(0.0307)\n",
            "7134 Traning Loss: tensor(0.0307)\n",
            "7135 Traning Loss: tensor(0.0307)\n",
            "7136 Traning Loss: tensor(0.0307)\n",
            "7137 Traning Loss: tensor(0.0307)\n",
            "7138 Traning Loss: tensor(0.0307)\n",
            "7139 Traning Loss: tensor(0.0307)\n",
            "7140 Traning Loss: tensor(0.0307)\n",
            "7141 Traning Loss: tensor(0.0307)\n",
            "7142 Traning Loss: tensor(0.0307)\n",
            "7143 Traning Loss: tensor(0.0307)\n",
            "7144 Traning Loss: tensor(0.0307)\n",
            "7145 Traning Loss: tensor(0.0307)\n",
            "7146 Traning Loss: tensor(0.0307)\n",
            "7147 Traning Loss: tensor(0.0307)\n",
            "7148 Traning Loss: tensor(0.0306)\n",
            "7149 Traning Loss: tensor(0.0306)\n",
            "7150 Traning Loss: tensor(0.0306)\n",
            "7151 Traning Loss: tensor(0.0306)\n",
            "7152 Traning Loss: tensor(0.0306)\n",
            "7153 Traning Loss: tensor(0.0306)\n",
            "7154 Traning Loss: tensor(0.0306)\n",
            "7155 Traning Loss: tensor(0.0306)\n",
            "7156 Traning Loss: tensor(0.0306)\n",
            "7157 Traning Loss: tensor(0.0306)\n",
            "7158 Traning Loss: tensor(0.0306)\n",
            "7159 Traning Loss: tensor(0.0306)\n",
            "7160 Traning Loss: tensor(0.0306)\n",
            "7161 Traning Loss: tensor(0.0306)\n",
            "7162 Traning Loss: tensor(0.0306)\n",
            "7163 Traning Loss: tensor(0.0306)\n",
            "7164 Traning Loss: tensor(0.0306)\n",
            "7165 Traning Loss: tensor(0.0306)\n",
            "7166 Traning Loss: tensor(0.0306)\n",
            "7167 Traning Loss: tensor(0.0306)\n",
            "7168 Traning Loss: tensor(0.0306)\n",
            "7169 Traning Loss: tensor(0.0306)\n",
            "7170 Traning Loss: tensor(0.0306)\n",
            "7171 Traning Loss: tensor(0.0306)\n",
            "7172 Traning Loss: tensor(0.0306)\n",
            "7173 Traning Loss: tensor(0.0306)\n",
            "7174 Traning Loss: tensor(0.0306)\n",
            "7175 Traning Loss: tensor(0.0306)\n",
            "7176 Traning Loss: tensor(0.0306)\n",
            "7177 Traning Loss: tensor(0.0306)\n",
            "7178 Traning Loss: tensor(0.0306)\n",
            "7179 Traning Loss: tensor(0.0306)\n",
            "7180 Traning Loss: tensor(0.0306)\n",
            "7181 Traning Loss: tensor(0.0306)\n",
            "7182 Traning Loss: tensor(0.0306)\n",
            "7183 Traning Loss: tensor(0.0306)\n",
            "7184 Traning Loss: tensor(0.0306)\n",
            "7185 Traning Loss: tensor(0.0306)\n",
            "7186 Traning Loss: tensor(0.0306)\n",
            "7187 Traning Loss: tensor(0.0306)\n",
            "7188 Traning Loss: tensor(0.0306)\n",
            "7189 Traning Loss: tensor(0.0306)\n",
            "7190 Traning Loss: tensor(0.0306)\n",
            "7191 Traning Loss: tensor(0.0306)\n",
            "7192 Traning Loss: tensor(0.0306)\n",
            "7193 Traning Loss: tensor(0.0306)\n",
            "7194 Traning Loss: tensor(0.0306)\n",
            "7195 Traning Loss: tensor(0.0306)\n",
            "7196 Traning Loss: tensor(0.0306)\n",
            "7197 Traning Loss: tensor(0.0306)\n",
            "7198 Traning Loss: tensor(0.0306)\n",
            "7199 Traning Loss: tensor(0.0306)\n",
            "7200 Traning Loss: tensor(0.0305)\n",
            "7201 Traning Loss: tensor(0.0305)\n",
            "7202 Traning Loss: tensor(0.0305)\n",
            "7203 Traning Loss: tensor(0.0305)\n",
            "7204 Traning Loss: tensor(0.0305)\n",
            "7205 Traning Loss: tensor(0.0305)\n",
            "7206 Traning Loss: tensor(0.0305)\n",
            "7207 Traning Loss: tensor(0.0305)\n",
            "7208 Traning Loss: tensor(0.0305)\n",
            "7209 Traning Loss: tensor(0.0305)\n",
            "7210 Traning Loss: tensor(0.0305)\n",
            "7211 Traning Loss: tensor(0.0305)\n",
            "7212 Traning Loss: tensor(0.0305)\n",
            "7213 Traning Loss: tensor(0.0305)\n",
            "7214 Traning Loss: tensor(0.0305)\n",
            "7215 Traning Loss: tensor(0.0305)\n",
            "7216 Traning Loss: tensor(0.0305)\n",
            "7217 Traning Loss: tensor(0.0305)\n",
            "7218 Traning Loss: tensor(0.0305)\n",
            "7219 Traning Loss: tensor(0.0305)\n",
            "7220 Traning Loss: tensor(0.0305)\n",
            "7221 Traning Loss: tensor(0.0305)\n",
            "7222 Traning Loss: tensor(0.0305)\n",
            "7223 Traning Loss: tensor(0.0305)\n",
            "7224 Traning Loss: tensor(0.0305)\n",
            "7225 Traning Loss: tensor(0.0305)\n",
            "7226 Traning Loss: tensor(0.0305)\n",
            "7227 Traning Loss: tensor(0.0305)\n",
            "7228 Traning Loss: tensor(0.0305)\n",
            "7229 Traning Loss: tensor(0.0305)\n",
            "7230 Traning Loss: tensor(0.0305)\n",
            "7231 Traning Loss: tensor(0.0305)\n",
            "7232 Traning Loss: tensor(0.0305)\n",
            "7233 Traning Loss: tensor(0.0305)\n",
            "7234 Traning Loss: tensor(0.0305)\n",
            "7235 Traning Loss: tensor(0.0305)\n",
            "7236 Traning Loss: tensor(0.0305)\n",
            "7237 Traning Loss: tensor(0.0305)\n",
            "7238 Traning Loss: tensor(0.0305)\n",
            "7239 Traning Loss: tensor(0.0305)\n",
            "7240 Traning Loss: tensor(0.0305)\n",
            "7241 Traning Loss: tensor(0.0305)\n",
            "7242 Traning Loss: tensor(0.0305)\n",
            "7243 Traning Loss: tensor(0.0305)\n",
            "7244 Traning Loss: tensor(0.0305)\n",
            "7245 Traning Loss: tensor(0.0305)\n",
            "7246 Traning Loss: tensor(0.0305)\n",
            "7247 Traning Loss: tensor(0.0305)\n",
            "7248 Traning Loss: tensor(0.0305)\n",
            "7249 Traning Loss: tensor(0.0305)\n",
            "7250 Traning Loss: tensor(0.0305)\n",
            "7251 Traning Loss: tensor(0.0305)\n",
            "7252 Traning Loss: tensor(0.0304)\n",
            "7253 Traning Loss: tensor(0.0304)\n",
            "7254 Traning Loss: tensor(0.0304)\n",
            "7255 Traning Loss: tensor(0.0304)\n",
            "7256 Traning Loss: tensor(0.0304)\n",
            "7257 Traning Loss: tensor(0.0304)\n",
            "7258 Traning Loss: tensor(0.0304)\n",
            "7259 Traning Loss: tensor(0.0304)\n",
            "7260 Traning Loss: tensor(0.0304)\n",
            "7261 Traning Loss: tensor(0.0304)\n",
            "7262 Traning Loss: tensor(0.0304)\n",
            "7263 Traning Loss: tensor(0.0304)\n",
            "7264 Traning Loss: tensor(0.0304)\n",
            "7265 Traning Loss: tensor(0.0304)\n",
            "7266 Traning Loss: tensor(0.0304)\n",
            "7267 Traning Loss: tensor(0.0304)\n",
            "7268 Traning Loss: tensor(0.0304)\n",
            "7269 Traning Loss: tensor(0.0304)\n",
            "7270 Traning Loss: tensor(0.0304)\n",
            "7271 Traning Loss: tensor(0.0304)\n",
            "7272 Traning Loss: tensor(0.0304)\n",
            "7273 Traning Loss: tensor(0.0304)\n",
            "7274 Traning Loss: tensor(0.0304)\n",
            "7275 Traning Loss: tensor(0.0304)\n",
            "7276 Traning Loss: tensor(0.0304)\n",
            "7277 Traning Loss: tensor(0.0304)\n",
            "7278 Traning Loss: tensor(0.0304)\n",
            "7279 Traning Loss: tensor(0.0304)\n",
            "7280 Traning Loss: tensor(0.0304)\n",
            "7281 Traning Loss: tensor(0.0304)\n",
            "7282 Traning Loss: tensor(0.0304)\n",
            "7283 Traning Loss: tensor(0.0304)\n",
            "7284 Traning Loss: tensor(0.0304)\n",
            "7285 Traning Loss: tensor(0.0304)\n",
            "7286 Traning Loss: tensor(0.0304)\n",
            "7287 Traning Loss: tensor(0.0304)\n",
            "7288 Traning Loss: tensor(0.0304)\n",
            "7289 Traning Loss: tensor(0.0304)\n",
            "7290 Traning Loss: tensor(0.0304)\n",
            "7291 Traning Loss: tensor(0.0304)\n",
            "7292 Traning Loss: tensor(0.0304)\n",
            "7293 Traning Loss: tensor(0.0304)\n",
            "7294 Traning Loss: tensor(0.0304)\n",
            "7295 Traning Loss: tensor(0.0304)\n",
            "7296 Traning Loss: tensor(0.0304)\n",
            "7297 Traning Loss: tensor(0.0304)\n",
            "7298 Traning Loss: tensor(0.0304)\n",
            "7299 Traning Loss: tensor(0.0304)\n",
            "7300 Traning Loss: tensor(0.0304)\n",
            "7301 Traning Loss: tensor(0.0304)\n",
            "7302 Traning Loss: tensor(0.0304)\n",
            "7303 Traning Loss: tensor(0.0304)\n",
            "7304 Traning Loss: tensor(0.0303)\n",
            "7305 Traning Loss: tensor(0.0303)\n",
            "7306 Traning Loss: tensor(0.0303)\n",
            "7307 Traning Loss: tensor(0.0303)\n",
            "7308 Traning Loss: tensor(0.0303)\n",
            "7309 Traning Loss: tensor(0.0303)\n",
            "7310 Traning Loss: tensor(0.0303)\n",
            "7311 Traning Loss: tensor(0.0303)\n",
            "7312 Traning Loss: tensor(0.0303)\n",
            "7313 Traning Loss: tensor(0.0303)\n",
            "7314 Traning Loss: tensor(0.0303)\n",
            "7315 Traning Loss: tensor(0.0303)\n",
            "7316 Traning Loss: tensor(0.0303)\n",
            "7317 Traning Loss: tensor(0.0303)\n",
            "7318 Traning Loss: tensor(0.0303)\n",
            "7319 Traning Loss: tensor(0.0303)\n",
            "7320 Traning Loss: tensor(0.0303)\n",
            "7321 Traning Loss: tensor(0.0303)\n",
            "7322 Traning Loss: tensor(0.0303)\n",
            "7323 Traning Loss: tensor(0.0303)\n",
            "7324 Traning Loss: tensor(0.0303)\n",
            "7325 Traning Loss: tensor(0.0303)\n",
            "7326 Traning Loss: tensor(0.0303)\n",
            "7327 Traning Loss: tensor(0.0303)\n",
            "7328 Traning Loss: tensor(0.0303)\n",
            "7329 Traning Loss: tensor(0.0303)\n",
            "7330 Traning Loss: tensor(0.0303)\n",
            "7331 Traning Loss: tensor(0.0303)\n",
            "7332 Traning Loss: tensor(0.0303)\n",
            "7333 Traning Loss: tensor(0.0303)\n",
            "7334 Traning Loss: tensor(0.0303)\n",
            "7335 Traning Loss: tensor(0.0303)\n",
            "7336 Traning Loss: tensor(0.0303)\n",
            "7337 Traning Loss: tensor(0.0303)\n",
            "7338 Traning Loss: tensor(0.0303)\n",
            "7339 Traning Loss: tensor(0.0303)\n",
            "7340 Traning Loss: tensor(0.0303)\n",
            "7341 Traning Loss: tensor(0.0303)\n",
            "7342 Traning Loss: tensor(0.0303)\n",
            "7343 Traning Loss: tensor(0.0303)\n",
            "7344 Traning Loss: tensor(0.0303)\n",
            "7345 Traning Loss: tensor(0.0303)\n",
            "7346 Traning Loss: tensor(0.0303)\n",
            "7347 Traning Loss: tensor(0.0303)\n",
            "7348 Traning Loss: tensor(0.0303)\n",
            "7349 Traning Loss: tensor(0.0303)\n",
            "7350 Traning Loss: tensor(0.0303)\n",
            "7351 Traning Loss: tensor(0.0303)\n",
            "7352 Traning Loss: tensor(0.0303)\n",
            "7353 Traning Loss: tensor(0.0303)\n",
            "7354 Traning Loss: tensor(0.0303)\n",
            "7355 Traning Loss: tensor(0.0303)\n",
            "7356 Traning Loss: tensor(0.0303)\n",
            "7357 Traning Loss: tensor(0.0303)\n",
            "7358 Traning Loss: tensor(0.0302)\n",
            "7359 Traning Loss: tensor(0.0302)\n",
            "7360 Traning Loss: tensor(0.0302)\n",
            "7361 Traning Loss: tensor(0.0302)\n",
            "7362 Traning Loss: tensor(0.0302)\n",
            "7363 Traning Loss: tensor(0.0302)\n",
            "7364 Traning Loss: tensor(0.0302)\n",
            "7365 Traning Loss: tensor(0.0302)\n",
            "7366 Traning Loss: tensor(0.0302)\n",
            "7367 Traning Loss: tensor(0.0302)\n",
            "7368 Traning Loss: tensor(0.0302)\n",
            "7369 Traning Loss: tensor(0.0302)\n",
            "7370 Traning Loss: tensor(0.0302)\n",
            "7371 Traning Loss: tensor(0.0302)\n",
            "7372 Traning Loss: tensor(0.0302)\n",
            "7373 Traning Loss: tensor(0.0302)\n",
            "7374 Traning Loss: tensor(0.0302)\n",
            "7375 Traning Loss: tensor(0.0302)\n",
            "7376 Traning Loss: tensor(0.0302)\n",
            "7377 Traning Loss: tensor(0.0302)\n",
            "7378 Traning Loss: tensor(0.0302)\n",
            "7379 Traning Loss: tensor(0.0302)\n",
            "7380 Traning Loss: tensor(0.0302)\n",
            "7381 Traning Loss: tensor(0.0302)\n",
            "7382 Traning Loss: tensor(0.0302)\n",
            "7383 Traning Loss: tensor(0.0302)\n",
            "7384 Traning Loss: tensor(0.0302)\n",
            "7385 Traning Loss: tensor(0.0302)\n",
            "7386 Traning Loss: tensor(0.0302)\n",
            "7387 Traning Loss: tensor(0.0302)\n",
            "7388 Traning Loss: tensor(0.0302)\n",
            "7389 Traning Loss: tensor(0.0302)\n",
            "7390 Traning Loss: tensor(0.0302)\n",
            "7391 Traning Loss: tensor(0.0302)\n",
            "7392 Traning Loss: tensor(0.0302)\n",
            "7393 Traning Loss: tensor(0.0302)\n",
            "7394 Traning Loss: tensor(0.0302)\n",
            "7395 Traning Loss: tensor(0.0302)\n",
            "7396 Traning Loss: tensor(0.0302)\n",
            "7397 Traning Loss: tensor(0.0302)\n",
            "7398 Traning Loss: tensor(0.0302)\n",
            "7399 Traning Loss: tensor(0.0302)\n",
            "7400 Traning Loss: tensor(0.0302)\n",
            "7401 Traning Loss: tensor(0.0302)\n",
            "7402 Traning Loss: tensor(0.0302)\n",
            "7403 Traning Loss: tensor(0.0302)\n",
            "7404 Traning Loss: tensor(0.0302)\n",
            "7405 Traning Loss: tensor(0.0302)\n",
            "7406 Traning Loss: tensor(0.0302)\n",
            "7407 Traning Loss: tensor(0.0302)\n",
            "7408 Traning Loss: tensor(0.0302)\n",
            "7409 Traning Loss: tensor(0.0302)\n",
            "7410 Traning Loss: tensor(0.0302)\n",
            "7411 Traning Loss: tensor(0.0302)\n",
            "7412 Traning Loss: tensor(0.0301)\n",
            "7413 Traning Loss: tensor(0.0301)\n",
            "7414 Traning Loss: tensor(0.0301)\n",
            "7415 Traning Loss: tensor(0.0301)\n",
            "7416 Traning Loss: tensor(0.0301)\n",
            "7417 Traning Loss: tensor(0.0301)\n",
            "7418 Traning Loss: tensor(0.0301)\n",
            "7419 Traning Loss: tensor(0.0301)\n",
            "7420 Traning Loss: tensor(0.0301)\n",
            "7421 Traning Loss: tensor(0.0301)\n",
            "7422 Traning Loss: tensor(0.0301)\n",
            "7423 Traning Loss: tensor(0.0301)\n",
            "7424 Traning Loss: tensor(0.0301)\n",
            "7425 Traning Loss: tensor(0.0301)\n",
            "7426 Traning Loss: tensor(0.0301)\n",
            "7427 Traning Loss: tensor(0.0301)\n",
            "7428 Traning Loss: tensor(0.0301)\n",
            "7429 Traning Loss: tensor(0.0301)\n",
            "7430 Traning Loss: tensor(0.0301)\n",
            "7431 Traning Loss: tensor(0.0301)\n",
            "7432 Traning Loss: tensor(0.0301)\n",
            "7433 Traning Loss: tensor(0.0301)\n",
            "7434 Traning Loss: tensor(0.0301)\n",
            "7435 Traning Loss: tensor(0.0301)\n",
            "7436 Traning Loss: tensor(0.0301)\n",
            "7437 Traning Loss: tensor(0.0301)\n",
            "7438 Traning Loss: tensor(0.0301)\n",
            "7439 Traning Loss: tensor(0.0301)\n",
            "7440 Traning Loss: tensor(0.0301)\n",
            "7441 Traning Loss: tensor(0.0301)\n",
            "7442 Traning Loss: tensor(0.0301)\n",
            "7443 Traning Loss: tensor(0.0301)\n",
            "7444 Traning Loss: tensor(0.0301)\n",
            "7445 Traning Loss: tensor(0.0301)\n",
            "7446 Traning Loss: tensor(0.0301)\n",
            "7447 Traning Loss: tensor(0.0301)\n",
            "7448 Traning Loss: tensor(0.0301)\n",
            "7449 Traning Loss: tensor(0.0301)\n",
            "7450 Traning Loss: tensor(0.0301)\n",
            "7451 Traning Loss: tensor(0.0301)\n",
            "7452 Traning Loss: tensor(0.0301)\n",
            "7453 Traning Loss: tensor(0.0301)\n",
            "7454 Traning Loss: tensor(0.0301)\n",
            "7455 Traning Loss: tensor(0.0301)\n",
            "7456 Traning Loss: tensor(0.0301)\n",
            "7457 Traning Loss: tensor(0.0301)\n",
            "7458 Traning Loss: tensor(0.0301)\n",
            "7459 Traning Loss: tensor(0.0301)\n",
            "7460 Traning Loss: tensor(0.0301)\n",
            "7461 Traning Loss: tensor(0.0301)\n",
            "7462 Traning Loss: tensor(0.0301)\n",
            "7463 Traning Loss: tensor(0.0301)\n",
            "7464 Traning Loss: tensor(0.0301)\n",
            "7465 Traning Loss: tensor(0.0301)\n",
            "7466 Traning Loss: tensor(0.0301)\n",
            "7467 Traning Loss: tensor(0.0301)\n",
            "7468 Traning Loss: tensor(0.0300)\n",
            "7469 Traning Loss: tensor(0.0300)\n",
            "7470 Traning Loss: tensor(0.0300)\n",
            "7471 Traning Loss: tensor(0.0300)\n",
            "7472 Traning Loss: tensor(0.0300)\n",
            "7473 Traning Loss: tensor(0.0300)\n",
            "7474 Traning Loss: tensor(0.0300)\n",
            "7475 Traning Loss: tensor(0.0300)\n",
            "7476 Traning Loss: tensor(0.0300)\n",
            "7477 Traning Loss: tensor(0.0300)\n",
            "7478 Traning Loss: tensor(0.0300)\n",
            "7479 Traning Loss: tensor(0.0300)\n",
            "7480 Traning Loss: tensor(0.0300)\n",
            "7481 Traning Loss: tensor(0.0300)\n",
            "7482 Traning Loss: tensor(0.0300)\n",
            "7483 Traning Loss: tensor(0.0300)\n",
            "7484 Traning Loss: tensor(0.0300)\n",
            "7485 Traning Loss: tensor(0.0300)\n",
            "7486 Traning Loss: tensor(0.0300)\n",
            "7487 Traning Loss: tensor(0.0300)\n",
            "7488 Traning Loss: tensor(0.0300)\n",
            "7489 Traning Loss: tensor(0.0300)\n",
            "7490 Traning Loss: tensor(0.0300)\n",
            "7491 Traning Loss: tensor(0.0300)\n",
            "7492 Traning Loss: tensor(0.0300)\n",
            "7493 Traning Loss: tensor(0.0300)\n",
            "7494 Traning Loss: tensor(0.0300)\n",
            "7495 Traning Loss: tensor(0.0300)\n",
            "7496 Traning Loss: tensor(0.0300)\n",
            "7497 Traning Loss: tensor(0.0300)\n",
            "7498 Traning Loss: tensor(0.0300)\n",
            "7499 Traning Loss: tensor(0.0300)\n",
            "7500 Traning Loss: tensor(0.0300)\n",
            "7501 Traning Loss: tensor(0.0300)\n",
            "7502 Traning Loss: tensor(0.0300)\n",
            "7503 Traning Loss: tensor(0.0300)\n",
            "7504 Traning Loss: tensor(0.0300)\n",
            "7505 Traning Loss: tensor(0.0300)\n",
            "7506 Traning Loss: tensor(0.0300)\n",
            "7507 Traning Loss: tensor(0.0300)\n",
            "7508 Traning Loss: tensor(0.0300)\n",
            "7509 Traning Loss: tensor(0.0300)\n",
            "7510 Traning Loss: tensor(0.0300)\n",
            "7511 Traning Loss: tensor(0.0300)\n",
            "7512 Traning Loss: tensor(0.0300)\n",
            "7513 Traning Loss: tensor(0.0300)\n",
            "7514 Traning Loss: tensor(0.0300)\n",
            "7515 Traning Loss: tensor(0.0300)\n",
            "7516 Traning Loss: tensor(0.0300)\n",
            "7517 Traning Loss: tensor(0.0300)\n",
            "7518 Traning Loss: tensor(0.0300)\n",
            "7519 Traning Loss: tensor(0.0300)\n",
            "7520 Traning Loss: tensor(0.0300)\n",
            "7521 Traning Loss: tensor(0.0300)\n",
            "7522 Traning Loss: tensor(0.0300)\n",
            "7523 Traning Loss: tensor(0.0300)\n",
            "7524 Traning Loss: tensor(0.0299)\n",
            "7525 Traning Loss: tensor(0.0299)\n",
            "7526 Traning Loss: tensor(0.0299)\n",
            "7527 Traning Loss: tensor(0.0299)\n",
            "7528 Traning Loss: tensor(0.0299)\n",
            "7529 Traning Loss: tensor(0.0299)\n",
            "7530 Traning Loss: tensor(0.0299)\n",
            "7531 Traning Loss: tensor(0.0299)\n",
            "7532 Traning Loss: tensor(0.0299)\n",
            "7533 Traning Loss: tensor(0.0299)\n",
            "7534 Traning Loss: tensor(0.0299)\n",
            "7535 Traning Loss: tensor(0.0299)\n",
            "7536 Traning Loss: tensor(0.0299)\n",
            "7537 Traning Loss: tensor(0.0299)\n",
            "7538 Traning Loss: tensor(0.0299)\n",
            "7539 Traning Loss: tensor(0.0299)\n",
            "7540 Traning Loss: tensor(0.0299)\n",
            "7541 Traning Loss: tensor(0.0299)\n",
            "7542 Traning Loss: tensor(0.0299)\n",
            "7543 Traning Loss: tensor(0.0299)\n",
            "7544 Traning Loss: tensor(0.0299)\n",
            "7545 Traning Loss: tensor(0.0299)\n",
            "7546 Traning Loss: tensor(0.0299)\n",
            "7547 Traning Loss: tensor(0.0299)\n",
            "7548 Traning Loss: tensor(0.0299)\n",
            "7549 Traning Loss: tensor(0.0299)\n",
            "7550 Traning Loss: tensor(0.0299)\n",
            "7551 Traning Loss: tensor(0.0299)\n",
            "7552 Traning Loss: tensor(0.0299)\n",
            "7553 Traning Loss: tensor(0.0299)\n",
            "7554 Traning Loss: tensor(0.0299)\n",
            "7555 Traning Loss: tensor(0.0299)\n",
            "7556 Traning Loss: tensor(0.0299)\n",
            "7557 Traning Loss: tensor(0.0299)\n",
            "7558 Traning Loss: tensor(0.0299)\n",
            "7559 Traning Loss: tensor(0.0299)\n",
            "7560 Traning Loss: tensor(0.0299)\n",
            "7561 Traning Loss: tensor(0.0299)\n",
            "7562 Traning Loss: tensor(0.0299)\n",
            "7563 Traning Loss: tensor(0.0299)\n",
            "7564 Traning Loss: tensor(0.0299)\n",
            "7565 Traning Loss: tensor(0.0299)\n",
            "7566 Traning Loss: tensor(0.0299)\n",
            "7567 Traning Loss: tensor(0.0299)\n",
            "7568 Traning Loss: tensor(0.0299)\n",
            "7569 Traning Loss: tensor(0.0299)\n",
            "7570 Traning Loss: tensor(0.0299)\n",
            "7571 Traning Loss: tensor(0.0299)\n",
            "7572 Traning Loss: tensor(0.0299)\n",
            "7573 Traning Loss: tensor(0.0299)\n",
            "7574 Traning Loss: tensor(0.0299)\n",
            "7575 Traning Loss: tensor(0.0299)\n",
            "7576 Traning Loss: tensor(0.0299)\n",
            "7577 Traning Loss: tensor(0.0299)\n",
            "7578 Traning Loss: tensor(0.0299)\n",
            "7579 Traning Loss: tensor(0.0299)\n",
            "7580 Traning Loss: tensor(0.0298)\n",
            "7581 Traning Loss: tensor(0.0298)\n",
            "7582 Traning Loss: tensor(0.0298)\n",
            "7583 Traning Loss: tensor(0.0298)\n",
            "7584 Traning Loss: tensor(0.0298)\n",
            "7585 Traning Loss: tensor(0.0298)\n",
            "7586 Traning Loss: tensor(0.0298)\n",
            "7587 Traning Loss: tensor(0.0298)\n",
            "7588 Traning Loss: tensor(0.0298)\n",
            "7589 Traning Loss: tensor(0.0298)\n",
            "7590 Traning Loss: tensor(0.0298)\n",
            "7591 Traning Loss: tensor(0.0298)\n",
            "7592 Traning Loss: tensor(0.0298)\n",
            "7593 Traning Loss: tensor(0.0298)\n",
            "7594 Traning Loss: tensor(0.0298)\n",
            "7595 Traning Loss: tensor(0.0298)\n",
            "7596 Traning Loss: tensor(0.0298)\n",
            "7597 Traning Loss: tensor(0.0298)\n",
            "7598 Traning Loss: tensor(0.0298)\n",
            "7599 Traning Loss: tensor(0.0298)\n",
            "7600 Traning Loss: tensor(0.0298)\n",
            "7601 Traning Loss: tensor(0.0298)\n",
            "7602 Traning Loss: tensor(0.0298)\n",
            "7603 Traning Loss: tensor(0.0298)\n",
            "7604 Traning Loss: tensor(0.0298)\n",
            "7605 Traning Loss: tensor(0.0298)\n",
            "7606 Traning Loss: tensor(0.0298)\n",
            "7607 Traning Loss: tensor(0.0298)\n",
            "7608 Traning Loss: tensor(0.0298)\n",
            "7609 Traning Loss: tensor(0.0298)\n",
            "7610 Traning Loss: tensor(0.0298)\n",
            "7611 Traning Loss: tensor(0.0298)\n",
            "7612 Traning Loss: tensor(0.0298)\n",
            "7613 Traning Loss: tensor(0.0298)\n",
            "7614 Traning Loss: tensor(0.0298)\n",
            "7615 Traning Loss: tensor(0.0298)\n",
            "7616 Traning Loss: tensor(0.0298)\n",
            "7617 Traning Loss: tensor(0.0298)\n",
            "7618 Traning Loss: tensor(0.0298)\n",
            "7619 Traning Loss: tensor(0.0298)\n",
            "7620 Traning Loss: tensor(0.0298)\n",
            "7621 Traning Loss: tensor(0.0298)\n",
            "7622 Traning Loss: tensor(0.0298)\n",
            "7623 Traning Loss: tensor(0.0298)\n",
            "7624 Traning Loss: tensor(0.0298)\n",
            "7625 Traning Loss: tensor(0.0298)\n",
            "7626 Traning Loss: tensor(0.0298)\n",
            "7627 Traning Loss: tensor(0.0298)\n",
            "7628 Traning Loss: tensor(0.0298)\n",
            "7629 Traning Loss: tensor(0.0298)\n",
            "7630 Traning Loss: tensor(0.0298)\n",
            "7631 Traning Loss: tensor(0.0298)\n",
            "7632 Traning Loss: tensor(0.0298)\n",
            "7633 Traning Loss: tensor(0.0298)\n",
            "7634 Traning Loss: tensor(0.0298)\n",
            "7635 Traning Loss: tensor(0.0298)\n",
            "7636 Traning Loss: tensor(0.0298)\n",
            "7637 Traning Loss: tensor(0.0298)\n",
            "7638 Traning Loss: tensor(0.0297)\n",
            "7639 Traning Loss: tensor(0.0297)\n",
            "7640 Traning Loss: tensor(0.0297)\n",
            "7641 Traning Loss: tensor(0.0297)\n",
            "7642 Traning Loss: tensor(0.0297)\n",
            "7643 Traning Loss: tensor(0.0297)\n",
            "7644 Traning Loss: tensor(0.0297)\n",
            "7645 Traning Loss: tensor(0.0297)\n",
            "7646 Traning Loss: tensor(0.0297)\n",
            "7647 Traning Loss: tensor(0.0297)\n",
            "7648 Traning Loss: tensor(0.0297)\n",
            "7649 Traning Loss: tensor(0.0297)\n",
            "7650 Traning Loss: tensor(0.0297)\n",
            "7651 Traning Loss: tensor(0.0297)\n",
            "7652 Traning Loss: tensor(0.0297)\n",
            "7653 Traning Loss: tensor(0.0297)\n",
            "7654 Traning Loss: tensor(0.0297)\n",
            "7655 Traning Loss: tensor(0.0297)\n",
            "7656 Traning Loss: tensor(0.0297)\n",
            "7657 Traning Loss: tensor(0.0297)\n",
            "7658 Traning Loss: tensor(0.0297)\n",
            "7659 Traning Loss: tensor(0.0297)\n",
            "7660 Traning Loss: tensor(0.0297)\n",
            "7661 Traning Loss: tensor(0.0297)\n",
            "7662 Traning Loss: tensor(0.0297)\n",
            "7663 Traning Loss: tensor(0.0297)\n",
            "7664 Traning Loss: tensor(0.0297)\n",
            "7665 Traning Loss: tensor(0.0297)\n",
            "7666 Traning Loss: tensor(0.0297)\n",
            "7667 Traning Loss: tensor(0.0297)\n",
            "7668 Traning Loss: tensor(0.0297)\n",
            "7669 Traning Loss: tensor(0.0297)\n",
            "7670 Traning Loss: tensor(0.0297)\n",
            "7671 Traning Loss: tensor(0.0297)\n",
            "7672 Traning Loss: tensor(0.0297)\n",
            "7673 Traning Loss: tensor(0.0297)\n",
            "7674 Traning Loss: tensor(0.0297)\n",
            "7675 Traning Loss: tensor(0.0297)\n",
            "7676 Traning Loss: tensor(0.0297)\n",
            "7677 Traning Loss: tensor(0.0297)\n",
            "7678 Traning Loss: tensor(0.0297)\n",
            "7679 Traning Loss: tensor(0.0297)\n",
            "7680 Traning Loss: tensor(0.0297)\n",
            "7681 Traning Loss: tensor(0.0297)\n",
            "7682 Traning Loss: tensor(0.0297)\n",
            "7683 Traning Loss: tensor(0.0297)\n",
            "7684 Traning Loss: tensor(0.0297)\n",
            "7685 Traning Loss: tensor(0.0297)\n",
            "7686 Traning Loss: tensor(0.0297)\n",
            "7687 Traning Loss: tensor(0.0297)\n",
            "7688 Traning Loss: tensor(0.0297)\n",
            "7689 Traning Loss: tensor(0.0297)\n",
            "7690 Traning Loss: tensor(0.0297)\n",
            "7691 Traning Loss: tensor(0.0297)\n",
            "7692 Traning Loss: tensor(0.0297)\n",
            "7693 Traning Loss: tensor(0.0297)\n",
            "7694 Traning Loss: tensor(0.0297)\n",
            "7695 Traning Loss: tensor(0.0297)\n",
            "7696 Traning Loss: tensor(0.0297)\n",
            "7697 Traning Loss: tensor(0.0296)\n",
            "7698 Traning Loss: tensor(0.0296)\n",
            "7699 Traning Loss: tensor(0.0296)\n",
            "7700 Traning Loss: tensor(0.0296)\n",
            "7701 Traning Loss: tensor(0.0296)\n",
            "7702 Traning Loss: tensor(0.0296)\n",
            "7703 Traning Loss: tensor(0.0296)\n",
            "7704 Traning Loss: tensor(0.0296)\n",
            "7705 Traning Loss: tensor(0.0296)\n",
            "7706 Traning Loss: tensor(0.0296)\n",
            "7707 Traning Loss: tensor(0.0296)\n",
            "7708 Traning Loss: tensor(0.0296)\n",
            "7709 Traning Loss: tensor(0.0296)\n",
            "7710 Traning Loss: tensor(0.0296)\n",
            "7711 Traning Loss: tensor(0.0296)\n",
            "7712 Traning Loss: tensor(0.0296)\n",
            "7713 Traning Loss: tensor(0.0296)\n",
            "7714 Traning Loss: tensor(0.0296)\n",
            "7715 Traning Loss: tensor(0.0296)\n",
            "7716 Traning Loss: tensor(0.0296)\n",
            "7717 Traning Loss: tensor(0.0296)\n",
            "7718 Traning Loss: tensor(0.0296)\n",
            "7719 Traning Loss: tensor(0.0296)\n",
            "7720 Traning Loss: tensor(0.0296)\n",
            "7721 Traning Loss: tensor(0.0296)\n",
            "7722 Traning Loss: tensor(0.0296)\n",
            "7723 Traning Loss: tensor(0.0296)\n",
            "7724 Traning Loss: tensor(0.0296)\n",
            "7725 Traning Loss: tensor(0.0296)\n",
            "7726 Traning Loss: tensor(0.0296)\n",
            "7727 Traning Loss: tensor(0.0296)\n",
            "7728 Traning Loss: tensor(0.0296)\n",
            "7729 Traning Loss: tensor(0.0296)\n",
            "7730 Traning Loss: tensor(0.0296)\n",
            "7731 Traning Loss: tensor(0.0296)\n",
            "7732 Traning Loss: tensor(0.0296)\n",
            "7733 Traning Loss: tensor(0.0296)\n",
            "7734 Traning Loss: tensor(0.0296)\n",
            "7735 Traning Loss: tensor(0.0296)\n",
            "7736 Traning Loss: tensor(0.0296)\n",
            "7737 Traning Loss: tensor(0.0296)\n",
            "7738 Traning Loss: tensor(0.0296)\n",
            "7739 Traning Loss: tensor(0.0296)\n",
            "7740 Traning Loss: tensor(0.0296)\n",
            "7741 Traning Loss: tensor(0.0296)\n",
            "7742 Traning Loss: tensor(0.0296)\n",
            "7743 Traning Loss: tensor(0.0296)\n",
            "7744 Traning Loss: tensor(0.0296)\n",
            "7745 Traning Loss: tensor(0.0296)\n",
            "7746 Traning Loss: tensor(0.0296)\n",
            "7747 Traning Loss: tensor(0.0296)\n",
            "7748 Traning Loss: tensor(0.0296)\n",
            "7749 Traning Loss: tensor(0.0296)\n",
            "7750 Traning Loss: tensor(0.0296)\n",
            "7751 Traning Loss: tensor(0.0296)\n",
            "7752 Traning Loss: tensor(0.0296)\n",
            "7753 Traning Loss: tensor(0.0296)\n",
            "7754 Traning Loss: tensor(0.0296)\n",
            "7755 Traning Loss: tensor(0.0296)\n",
            "7756 Traning Loss: tensor(0.0295)\n",
            "7757 Traning Loss: tensor(0.0295)\n",
            "7758 Traning Loss: tensor(0.0295)\n",
            "7759 Traning Loss: tensor(0.0295)\n",
            "7760 Traning Loss: tensor(0.0295)\n",
            "7761 Traning Loss: tensor(0.0295)\n",
            "7762 Traning Loss: tensor(0.0295)\n",
            "7763 Traning Loss: tensor(0.0295)\n",
            "7764 Traning Loss: tensor(0.0295)\n",
            "7765 Traning Loss: tensor(0.0295)\n",
            "7766 Traning Loss: tensor(0.0295)\n",
            "7767 Traning Loss: tensor(0.0295)\n",
            "7768 Traning Loss: tensor(0.0295)\n",
            "7769 Traning Loss: tensor(0.0295)\n",
            "7770 Traning Loss: tensor(0.0295)\n",
            "7771 Traning Loss: tensor(0.0295)\n",
            "7772 Traning Loss: tensor(0.0295)\n",
            "7773 Traning Loss: tensor(0.0295)\n",
            "7774 Traning Loss: tensor(0.0295)\n",
            "7775 Traning Loss: tensor(0.0295)\n",
            "7776 Traning Loss: tensor(0.0295)\n",
            "7777 Traning Loss: tensor(0.0295)\n",
            "7778 Traning Loss: tensor(0.0295)\n",
            "7779 Traning Loss: tensor(0.0295)\n",
            "7780 Traning Loss: tensor(0.0295)\n",
            "7781 Traning Loss: tensor(0.0295)\n",
            "7782 Traning Loss: tensor(0.0295)\n",
            "7783 Traning Loss: tensor(0.0295)\n",
            "7784 Traning Loss: tensor(0.0295)\n",
            "7785 Traning Loss: tensor(0.0295)\n",
            "7786 Traning Loss: tensor(0.0295)\n",
            "7787 Traning Loss: tensor(0.0295)\n",
            "7788 Traning Loss: tensor(0.0295)\n",
            "7789 Traning Loss: tensor(0.0295)\n",
            "7790 Traning Loss: tensor(0.0295)\n",
            "7791 Traning Loss: tensor(0.0295)\n",
            "7792 Traning Loss: tensor(0.0295)\n",
            "7793 Traning Loss: tensor(0.0295)\n",
            "7794 Traning Loss: tensor(0.0295)\n",
            "7795 Traning Loss: tensor(0.0295)\n",
            "7796 Traning Loss: tensor(0.0295)\n",
            "7797 Traning Loss: tensor(0.0295)\n",
            "7798 Traning Loss: tensor(0.0295)\n",
            "7799 Traning Loss: tensor(0.0295)\n",
            "7800 Traning Loss: tensor(0.0295)\n",
            "7801 Traning Loss: tensor(0.0295)\n",
            "7802 Traning Loss: tensor(0.0295)\n",
            "7803 Traning Loss: tensor(0.0295)\n",
            "7804 Traning Loss: tensor(0.0295)\n",
            "7805 Traning Loss: tensor(0.0295)\n",
            "7806 Traning Loss: tensor(0.0295)\n",
            "7807 Traning Loss: tensor(0.0295)\n",
            "7808 Traning Loss: tensor(0.0295)\n",
            "7809 Traning Loss: tensor(0.0295)\n",
            "7810 Traning Loss: tensor(0.0295)\n",
            "7811 Traning Loss: tensor(0.0295)\n",
            "7812 Traning Loss: tensor(0.0295)\n",
            "7813 Traning Loss: tensor(0.0295)\n",
            "7814 Traning Loss: tensor(0.0295)\n",
            "7815 Traning Loss: tensor(0.0295)\n",
            "7816 Traning Loss: tensor(0.0294)\n",
            "7817 Traning Loss: tensor(0.0294)\n",
            "7818 Traning Loss: tensor(0.0294)\n",
            "7819 Traning Loss: tensor(0.0294)\n",
            "7820 Traning Loss: tensor(0.0294)\n",
            "7821 Traning Loss: tensor(0.0294)\n",
            "7822 Traning Loss: tensor(0.0294)\n",
            "7823 Traning Loss: tensor(0.0294)\n",
            "7824 Traning Loss: tensor(0.0294)\n",
            "7825 Traning Loss: tensor(0.0294)\n",
            "7826 Traning Loss: tensor(0.0294)\n",
            "7827 Traning Loss: tensor(0.0294)\n",
            "7828 Traning Loss: tensor(0.0294)\n",
            "7829 Traning Loss: tensor(0.0294)\n",
            "7830 Traning Loss: tensor(0.0294)\n",
            "7831 Traning Loss: tensor(0.0294)\n",
            "7832 Traning Loss: tensor(0.0294)\n",
            "7833 Traning Loss: tensor(0.0294)\n",
            "7834 Traning Loss: tensor(0.0294)\n",
            "7835 Traning Loss: tensor(0.0294)\n",
            "7836 Traning Loss: tensor(0.0294)\n",
            "7837 Traning Loss: tensor(0.0294)\n",
            "7838 Traning Loss: tensor(0.0294)\n",
            "7839 Traning Loss: tensor(0.0294)\n",
            "7840 Traning Loss: tensor(0.0294)\n",
            "7841 Traning Loss: tensor(0.0294)\n",
            "7842 Traning Loss: tensor(0.0294)\n",
            "7843 Traning Loss: tensor(0.0294)\n",
            "7844 Traning Loss: tensor(0.0294)\n",
            "7845 Traning Loss: tensor(0.0294)\n",
            "7846 Traning Loss: tensor(0.0294)\n",
            "7847 Traning Loss: tensor(0.0294)\n",
            "7848 Traning Loss: tensor(0.0294)\n",
            "7849 Traning Loss: tensor(0.0294)\n",
            "7850 Traning Loss: tensor(0.0294)\n",
            "7851 Traning Loss: tensor(0.0294)\n",
            "7852 Traning Loss: tensor(0.0294)\n",
            "7853 Traning Loss: tensor(0.0294)\n",
            "7854 Traning Loss: tensor(0.0294)\n",
            "7855 Traning Loss: tensor(0.0294)\n",
            "7856 Traning Loss: tensor(0.0294)\n",
            "7857 Traning Loss: tensor(0.0294)\n",
            "7858 Traning Loss: tensor(0.0294)\n",
            "7859 Traning Loss: tensor(0.0294)\n",
            "7860 Traning Loss: tensor(0.0294)\n",
            "7861 Traning Loss: tensor(0.0294)\n",
            "7862 Traning Loss: tensor(0.0294)\n",
            "7863 Traning Loss: tensor(0.0294)\n",
            "7864 Traning Loss: tensor(0.0294)\n",
            "7865 Traning Loss: tensor(0.0294)\n",
            "7866 Traning Loss: tensor(0.0294)\n",
            "7867 Traning Loss: tensor(0.0294)\n",
            "7868 Traning Loss: tensor(0.0294)\n",
            "7869 Traning Loss: tensor(0.0294)\n",
            "7870 Traning Loss: tensor(0.0294)\n",
            "7871 Traning Loss: tensor(0.0294)\n",
            "7872 Traning Loss: tensor(0.0294)\n",
            "7873 Traning Loss: tensor(0.0294)\n",
            "7874 Traning Loss: tensor(0.0294)\n",
            "7875 Traning Loss: tensor(0.0294)\n",
            "7876 Traning Loss: tensor(0.0294)\n",
            "7877 Traning Loss: tensor(0.0294)\n",
            "7878 Traning Loss: tensor(0.0293)\n",
            "7879 Traning Loss: tensor(0.0293)\n",
            "7880 Traning Loss: tensor(0.0293)\n",
            "7881 Traning Loss: tensor(0.0293)\n",
            "7882 Traning Loss: tensor(0.0293)\n",
            "7883 Traning Loss: tensor(0.0293)\n",
            "7884 Traning Loss: tensor(0.0293)\n",
            "7885 Traning Loss: tensor(0.0293)\n",
            "7886 Traning Loss: tensor(0.0293)\n",
            "7887 Traning Loss: tensor(0.0293)\n",
            "7888 Traning Loss: tensor(0.0293)\n",
            "7889 Traning Loss: tensor(0.0293)\n",
            "7890 Traning Loss: tensor(0.0293)\n",
            "7891 Traning Loss: tensor(0.0293)\n",
            "7892 Traning Loss: tensor(0.0293)\n",
            "7893 Traning Loss: tensor(0.0293)\n",
            "7894 Traning Loss: tensor(0.0293)\n",
            "7895 Traning Loss: tensor(0.0293)\n",
            "7896 Traning Loss: tensor(0.0293)\n",
            "7897 Traning Loss: tensor(0.0293)\n",
            "7898 Traning Loss: tensor(0.0293)\n",
            "7899 Traning Loss: tensor(0.0293)\n",
            "7900 Traning Loss: tensor(0.0293)\n",
            "7901 Traning Loss: tensor(0.0293)\n",
            "7902 Traning Loss: tensor(0.0293)\n",
            "7903 Traning Loss: tensor(0.0293)\n",
            "7904 Traning Loss: tensor(0.0293)\n",
            "7905 Traning Loss: tensor(0.0293)\n",
            "7906 Traning Loss: tensor(0.0293)\n",
            "7907 Traning Loss: tensor(0.0293)\n",
            "7908 Traning Loss: tensor(0.0293)\n",
            "7909 Traning Loss: tensor(0.0293)\n",
            "7910 Traning Loss: tensor(0.0293)\n",
            "7911 Traning Loss: tensor(0.0293)\n",
            "7912 Traning Loss: tensor(0.0293)\n",
            "7913 Traning Loss: tensor(0.0293)\n",
            "7914 Traning Loss: tensor(0.0293)\n",
            "7915 Traning Loss: tensor(0.0293)\n",
            "7916 Traning Loss: tensor(0.0293)\n",
            "7917 Traning Loss: tensor(0.0293)\n",
            "7918 Traning Loss: tensor(0.0293)\n",
            "7919 Traning Loss: tensor(0.0293)\n",
            "7920 Traning Loss: tensor(0.0293)\n",
            "7921 Traning Loss: tensor(0.0293)\n",
            "7922 Traning Loss: tensor(0.0293)\n",
            "7923 Traning Loss: tensor(0.0293)\n",
            "7924 Traning Loss: tensor(0.0293)\n",
            "7925 Traning Loss: tensor(0.0293)\n",
            "7926 Traning Loss: tensor(0.0293)\n",
            "7927 Traning Loss: tensor(0.0293)\n",
            "7928 Traning Loss: tensor(0.0293)\n",
            "7929 Traning Loss: tensor(0.0293)\n",
            "7930 Traning Loss: tensor(0.0293)\n",
            "7931 Traning Loss: tensor(0.0293)\n",
            "7932 Traning Loss: tensor(0.0293)\n",
            "7933 Traning Loss: tensor(0.0293)\n",
            "7934 Traning Loss: tensor(0.0293)\n",
            "7935 Traning Loss: tensor(0.0293)\n",
            "7936 Traning Loss: tensor(0.0293)\n",
            "7937 Traning Loss: tensor(0.0293)\n",
            "7938 Traning Loss: tensor(0.0293)\n",
            "7939 Traning Loss: tensor(0.0293)\n",
            "7940 Traning Loss: tensor(0.0292)\n",
            "7941 Traning Loss: tensor(0.0292)\n",
            "7942 Traning Loss: tensor(0.0292)\n",
            "7943 Traning Loss: tensor(0.0292)\n",
            "7944 Traning Loss: tensor(0.0292)\n",
            "7945 Traning Loss: tensor(0.0292)\n",
            "7946 Traning Loss: tensor(0.0292)\n",
            "7947 Traning Loss: tensor(0.0292)\n",
            "7948 Traning Loss: tensor(0.0292)\n",
            "7949 Traning Loss: tensor(0.0292)\n",
            "7950 Traning Loss: tensor(0.0292)\n",
            "7951 Traning Loss: tensor(0.0292)\n",
            "7952 Traning Loss: tensor(0.0292)\n",
            "7953 Traning Loss: tensor(0.0292)\n",
            "7954 Traning Loss: tensor(0.0292)\n",
            "7955 Traning Loss: tensor(0.0292)\n",
            "7956 Traning Loss: tensor(0.0292)\n",
            "7957 Traning Loss: tensor(0.0292)\n",
            "7958 Traning Loss: tensor(0.0292)\n",
            "7959 Traning Loss: tensor(0.0292)\n",
            "7960 Traning Loss: tensor(0.0292)\n",
            "7961 Traning Loss: tensor(0.0292)\n",
            "7962 Traning Loss: tensor(0.0292)\n",
            "7963 Traning Loss: tensor(0.0292)\n",
            "7964 Traning Loss: tensor(0.0292)\n",
            "7965 Traning Loss: tensor(0.0292)\n",
            "7966 Traning Loss: tensor(0.0292)\n",
            "7967 Traning Loss: tensor(0.0292)\n",
            "7968 Traning Loss: tensor(0.0292)\n",
            "7969 Traning Loss: tensor(0.0292)\n",
            "7970 Traning Loss: tensor(0.0292)\n",
            "7971 Traning Loss: tensor(0.0292)\n",
            "7972 Traning Loss: tensor(0.0292)\n",
            "7973 Traning Loss: tensor(0.0292)\n",
            "7974 Traning Loss: tensor(0.0292)\n",
            "7975 Traning Loss: tensor(0.0292)\n",
            "7976 Traning Loss: tensor(0.0292)\n",
            "7977 Traning Loss: tensor(0.0292)\n",
            "7978 Traning Loss: tensor(0.0292)\n",
            "7979 Traning Loss: tensor(0.0292)\n",
            "7980 Traning Loss: tensor(0.0292)\n",
            "7981 Traning Loss: tensor(0.0292)\n",
            "7982 Traning Loss: tensor(0.0292)\n",
            "7983 Traning Loss: tensor(0.0292)\n",
            "7984 Traning Loss: tensor(0.0292)\n",
            "7985 Traning Loss: tensor(0.0292)\n",
            "7986 Traning Loss: tensor(0.0292)\n",
            "7987 Traning Loss: tensor(0.0292)\n",
            "7988 Traning Loss: tensor(0.0292)\n",
            "7989 Traning Loss: tensor(0.0292)\n",
            "7990 Traning Loss: tensor(0.0292)\n",
            "7991 Traning Loss: tensor(0.0292)\n",
            "7992 Traning Loss: tensor(0.0292)\n",
            "7993 Traning Loss: tensor(0.0292)\n",
            "7994 Traning Loss: tensor(0.0292)\n",
            "7995 Traning Loss: tensor(0.0292)\n",
            "7996 Traning Loss: tensor(0.0292)\n",
            "7997 Traning Loss: tensor(0.0292)\n",
            "7998 Traning Loss: tensor(0.0292)\n",
            "7999 Traning Loss: tensor(0.0292)\n",
            "8000 Traning Loss: tensor(0.0292)\n",
            "8001 Traning Loss: tensor(0.0292)\n",
            "8002 Traning Loss: tensor(0.0292)\n",
            "8003 Traning Loss: tensor(0.0291)\n",
            "8004 Traning Loss: tensor(0.0291)\n",
            "8005 Traning Loss: tensor(0.0291)\n",
            "8006 Traning Loss: tensor(0.0291)\n",
            "8007 Traning Loss: tensor(0.0291)\n",
            "8008 Traning Loss: tensor(0.0291)\n",
            "8009 Traning Loss: tensor(0.0291)\n",
            "8010 Traning Loss: tensor(0.0291)\n",
            "8011 Traning Loss: tensor(0.0291)\n",
            "8012 Traning Loss: tensor(0.0291)\n",
            "8013 Traning Loss: tensor(0.0291)\n",
            "8014 Traning Loss: tensor(0.0291)\n",
            "8015 Traning Loss: tensor(0.0291)\n",
            "8016 Traning Loss: tensor(0.0291)\n",
            "8017 Traning Loss: tensor(0.0291)\n",
            "8018 Traning Loss: tensor(0.0291)\n",
            "8019 Traning Loss: tensor(0.0291)\n",
            "8020 Traning Loss: tensor(0.0291)\n",
            "8021 Traning Loss: tensor(0.0291)\n",
            "8022 Traning Loss: tensor(0.0291)\n",
            "8023 Traning Loss: tensor(0.0291)\n",
            "8024 Traning Loss: tensor(0.0291)\n",
            "8025 Traning Loss: tensor(0.0291)\n",
            "8026 Traning Loss: tensor(0.0291)\n",
            "8027 Traning Loss: tensor(0.0291)\n",
            "8028 Traning Loss: tensor(0.0291)\n",
            "8029 Traning Loss: tensor(0.0291)\n",
            "8030 Traning Loss: tensor(0.0291)\n",
            "8031 Traning Loss: tensor(0.0291)\n",
            "8032 Traning Loss: tensor(0.0291)\n",
            "8033 Traning Loss: tensor(0.0291)\n",
            "8034 Traning Loss: tensor(0.0291)\n",
            "8035 Traning Loss: tensor(0.0291)\n",
            "8036 Traning Loss: tensor(0.0291)\n",
            "8037 Traning Loss: tensor(0.0291)\n",
            "8038 Traning Loss: tensor(0.0291)\n",
            "8039 Traning Loss: tensor(0.0291)\n",
            "8040 Traning Loss: tensor(0.0291)\n",
            "8041 Traning Loss: tensor(0.0291)\n",
            "8042 Traning Loss: tensor(0.0291)\n",
            "8043 Traning Loss: tensor(0.0291)\n",
            "8044 Traning Loss: tensor(0.0291)\n",
            "8045 Traning Loss: tensor(0.0291)\n",
            "8046 Traning Loss: tensor(0.0291)\n",
            "8047 Traning Loss: tensor(0.0291)\n",
            "8048 Traning Loss: tensor(0.0291)\n",
            "8049 Traning Loss: tensor(0.0291)\n",
            "8050 Traning Loss: tensor(0.0291)\n",
            "8051 Traning Loss: tensor(0.0291)\n",
            "8052 Traning Loss: tensor(0.0291)\n",
            "8053 Traning Loss: tensor(0.0291)\n",
            "8054 Traning Loss: tensor(0.0291)\n",
            "8055 Traning Loss: tensor(0.0291)\n",
            "8056 Traning Loss: tensor(0.0291)\n",
            "8057 Traning Loss: tensor(0.0291)\n",
            "8058 Traning Loss: tensor(0.0291)\n",
            "8059 Traning Loss: tensor(0.0291)\n",
            "8060 Traning Loss: tensor(0.0291)\n",
            "8061 Traning Loss: tensor(0.0291)\n",
            "8062 Traning Loss: tensor(0.0291)\n",
            "8063 Traning Loss: tensor(0.0291)\n",
            "8064 Traning Loss: tensor(0.0291)\n",
            "8065 Traning Loss: tensor(0.0291)\n",
            "8066 Traning Loss: tensor(0.0291)\n",
            "8067 Traning Loss: tensor(0.0290)\n",
            "8068 Traning Loss: tensor(0.0290)\n",
            "8069 Traning Loss: tensor(0.0290)\n",
            "8070 Traning Loss: tensor(0.0290)\n",
            "8071 Traning Loss: tensor(0.0290)\n",
            "8072 Traning Loss: tensor(0.0290)\n",
            "8073 Traning Loss: tensor(0.0290)\n",
            "8074 Traning Loss: tensor(0.0290)\n",
            "8075 Traning Loss: tensor(0.0290)\n",
            "8076 Traning Loss: tensor(0.0290)\n",
            "8077 Traning Loss: tensor(0.0290)\n",
            "8078 Traning Loss: tensor(0.0290)\n",
            "8079 Traning Loss: tensor(0.0290)\n",
            "8080 Traning Loss: tensor(0.0290)\n",
            "8081 Traning Loss: tensor(0.0290)\n",
            "8082 Traning Loss: tensor(0.0290)\n",
            "8083 Traning Loss: tensor(0.0290)\n",
            "8084 Traning Loss: tensor(0.0290)\n",
            "8085 Traning Loss: tensor(0.0290)\n",
            "8086 Traning Loss: tensor(0.0290)\n",
            "8087 Traning Loss: tensor(0.0290)\n",
            "8088 Traning Loss: tensor(0.0290)\n",
            "8089 Traning Loss: tensor(0.0290)\n",
            "8090 Traning Loss: tensor(0.0290)\n",
            "8091 Traning Loss: tensor(0.0290)\n",
            "8092 Traning Loss: tensor(0.0290)\n",
            "8093 Traning Loss: tensor(0.0290)\n",
            "8094 Traning Loss: tensor(0.0290)\n",
            "8095 Traning Loss: tensor(0.0290)\n",
            "8096 Traning Loss: tensor(0.0290)\n",
            "8097 Traning Loss: tensor(0.0290)\n",
            "8098 Traning Loss: tensor(0.0290)\n",
            "8099 Traning Loss: tensor(0.0290)\n",
            "8100 Traning Loss: tensor(0.0290)\n",
            "8101 Traning Loss: tensor(0.0290)\n",
            "8102 Traning Loss: tensor(0.0290)\n",
            "8103 Traning Loss: tensor(0.0290)\n",
            "8104 Traning Loss: tensor(0.0290)\n",
            "8105 Traning Loss: tensor(0.0290)\n",
            "8106 Traning Loss: tensor(0.0290)\n",
            "8107 Traning Loss: tensor(0.0290)\n",
            "8108 Traning Loss: tensor(0.0290)\n",
            "8109 Traning Loss: tensor(0.0290)\n",
            "8110 Traning Loss: tensor(0.0290)\n",
            "8111 Traning Loss: tensor(0.0290)\n",
            "8112 Traning Loss: tensor(0.0290)\n",
            "8113 Traning Loss: tensor(0.0290)\n",
            "8114 Traning Loss: tensor(0.0290)\n",
            "8115 Traning Loss: tensor(0.0290)\n",
            "8116 Traning Loss: tensor(0.0290)\n",
            "8117 Traning Loss: tensor(0.0290)\n",
            "8118 Traning Loss: tensor(0.0290)\n",
            "8119 Traning Loss: tensor(0.0290)\n",
            "8120 Traning Loss: tensor(0.0290)\n",
            "8121 Traning Loss: tensor(0.0290)\n",
            "8122 Traning Loss: tensor(0.0290)\n",
            "8123 Traning Loss: tensor(0.0290)\n",
            "8124 Traning Loss: tensor(0.0290)\n",
            "8125 Traning Loss: tensor(0.0290)\n",
            "8126 Traning Loss: tensor(0.0290)\n",
            "8127 Traning Loss: tensor(0.0290)\n",
            "8128 Traning Loss: tensor(0.0290)\n",
            "8129 Traning Loss: tensor(0.0290)\n",
            "8130 Traning Loss: tensor(0.0290)\n",
            "8131 Traning Loss: tensor(0.0290)\n",
            "8132 Traning Loss: tensor(0.0289)\n",
            "8133 Traning Loss: tensor(0.0289)\n",
            "8134 Traning Loss: tensor(0.0289)\n",
            "8135 Traning Loss: tensor(0.0289)\n",
            "8136 Traning Loss: tensor(0.0289)\n",
            "8137 Traning Loss: tensor(0.0289)\n",
            "8138 Traning Loss: tensor(0.0289)\n",
            "8139 Traning Loss: tensor(0.0289)\n",
            "8140 Traning Loss: tensor(0.0289)\n",
            "8141 Traning Loss: tensor(0.0289)\n",
            "8142 Traning Loss: tensor(0.0289)\n",
            "8143 Traning Loss: tensor(0.0289)\n",
            "8144 Traning Loss: tensor(0.0289)\n",
            "8145 Traning Loss: tensor(0.0289)\n",
            "8146 Traning Loss: tensor(0.0289)\n",
            "8147 Traning Loss: tensor(0.0289)\n",
            "8148 Traning Loss: tensor(0.0289)\n",
            "8149 Traning Loss: tensor(0.0289)\n",
            "8150 Traning Loss: tensor(0.0289)\n",
            "8151 Traning Loss: tensor(0.0289)\n",
            "8152 Traning Loss: tensor(0.0289)\n",
            "8153 Traning Loss: tensor(0.0289)\n",
            "8154 Traning Loss: tensor(0.0289)\n",
            "8155 Traning Loss: tensor(0.0289)\n",
            "8156 Traning Loss: tensor(0.0289)\n",
            "8157 Traning Loss: tensor(0.0289)\n",
            "8158 Traning Loss: tensor(0.0289)\n",
            "8159 Traning Loss: tensor(0.0289)\n",
            "8160 Traning Loss: tensor(0.0289)\n",
            "8161 Traning Loss: tensor(0.0289)\n",
            "8162 Traning Loss: tensor(0.0289)\n",
            "8163 Traning Loss: tensor(0.0289)\n",
            "8164 Traning Loss: tensor(0.0289)\n",
            "8165 Traning Loss: tensor(0.0289)\n",
            "8166 Traning Loss: tensor(0.0289)\n",
            "8167 Traning Loss: tensor(0.0289)\n",
            "8168 Traning Loss: tensor(0.0289)\n",
            "8169 Traning Loss: tensor(0.0289)\n",
            "8170 Traning Loss: tensor(0.0289)\n",
            "8171 Traning Loss: tensor(0.0289)\n",
            "8172 Traning Loss: tensor(0.0289)\n",
            "8173 Traning Loss: tensor(0.0289)\n",
            "8174 Traning Loss: tensor(0.0289)\n",
            "8175 Traning Loss: tensor(0.0289)\n",
            "8176 Traning Loss: tensor(0.0289)\n",
            "8177 Traning Loss: tensor(0.0289)\n",
            "8178 Traning Loss: tensor(0.0289)\n",
            "8179 Traning Loss: tensor(0.0289)\n",
            "8180 Traning Loss: tensor(0.0289)\n",
            "8181 Traning Loss: tensor(0.0289)\n",
            "8182 Traning Loss: tensor(0.0289)\n",
            "8183 Traning Loss: tensor(0.0289)\n",
            "8184 Traning Loss: tensor(0.0289)\n",
            "8185 Traning Loss: tensor(0.0289)\n",
            "8186 Traning Loss: tensor(0.0289)\n",
            "8187 Traning Loss: tensor(0.0289)\n",
            "8188 Traning Loss: tensor(0.0289)\n",
            "8189 Traning Loss: tensor(0.0289)\n",
            "8190 Traning Loss: tensor(0.0289)\n",
            "8191 Traning Loss: tensor(0.0289)\n",
            "8192 Traning Loss: tensor(0.0289)\n",
            "8193 Traning Loss: tensor(0.0289)\n",
            "8194 Traning Loss: tensor(0.0289)\n",
            "8195 Traning Loss: tensor(0.0289)\n",
            "8196 Traning Loss: tensor(0.0289)\n",
            "8197 Traning Loss: tensor(0.0289)\n",
            "8198 Traning Loss: tensor(0.0288)\n",
            "8199 Traning Loss: tensor(0.0288)\n",
            "8200 Traning Loss: tensor(0.0288)\n",
            "8201 Traning Loss: tensor(0.0288)\n",
            "8202 Traning Loss: tensor(0.0288)\n",
            "8203 Traning Loss: tensor(0.0288)\n",
            "8204 Traning Loss: tensor(0.0288)\n",
            "8205 Traning Loss: tensor(0.0288)\n",
            "8206 Traning Loss: tensor(0.0288)\n",
            "8207 Traning Loss: tensor(0.0288)\n",
            "8208 Traning Loss: tensor(0.0288)\n",
            "8209 Traning Loss: tensor(0.0288)\n",
            "8210 Traning Loss: tensor(0.0288)\n",
            "8211 Traning Loss: tensor(0.0288)\n",
            "8212 Traning Loss: tensor(0.0288)\n",
            "8213 Traning Loss: tensor(0.0288)\n",
            "8214 Traning Loss: tensor(0.0288)\n",
            "8215 Traning Loss: tensor(0.0288)\n",
            "8216 Traning Loss: tensor(0.0288)\n",
            "8217 Traning Loss: tensor(0.0288)\n",
            "8218 Traning Loss: tensor(0.0288)\n",
            "8219 Traning Loss: tensor(0.0288)\n",
            "8220 Traning Loss: tensor(0.0288)\n",
            "8221 Traning Loss: tensor(0.0288)\n",
            "8222 Traning Loss: tensor(0.0288)\n",
            "8223 Traning Loss: tensor(0.0288)\n",
            "8224 Traning Loss: tensor(0.0288)\n",
            "8225 Traning Loss: tensor(0.0288)\n",
            "8226 Traning Loss: tensor(0.0288)\n",
            "8227 Traning Loss: tensor(0.0288)\n",
            "8228 Traning Loss: tensor(0.0288)\n",
            "8229 Traning Loss: tensor(0.0288)\n",
            "8230 Traning Loss: tensor(0.0288)\n",
            "8231 Traning Loss: tensor(0.0288)\n",
            "8232 Traning Loss: tensor(0.0288)\n",
            "8233 Traning Loss: tensor(0.0288)\n",
            "8234 Traning Loss: tensor(0.0288)\n",
            "8235 Traning Loss: tensor(0.0288)\n",
            "8236 Traning Loss: tensor(0.0288)\n",
            "8237 Traning Loss: tensor(0.0288)\n",
            "8238 Traning Loss: tensor(0.0288)\n",
            "8239 Traning Loss: tensor(0.0288)\n",
            "8240 Traning Loss: tensor(0.0288)\n",
            "8241 Traning Loss: tensor(0.0288)\n",
            "8242 Traning Loss: tensor(0.0288)\n",
            "8243 Traning Loss: tensor(0.0288)\n",
            "8244 Traning Loss: tensor(0.0288)\n",
            "8245 Traning Loss: tensor(0.0288)\n",
            "8246 Traning Loss: tensor(0.0288)\n",
            "8247 Traning Loss: tensor(0.0288)\n",
            "8248 Traning Loss: tensor(0.0288)\n",
            "8249 Traning Loss: tensor(0.0288)\n",
            "8250 Traning Loss: tensor(0.0288)\n",
            "8251 Traning Loss: tensor(0.0288)\n",
            "8252 Traning Loss: tensor(0.0288)\n",
            "8253 Traning Loss: tensor(0.0288)\n",
            "8254 Traning Loss: tensor(0.0288)\n",
            "8255 Traning Loss: tensor(0.0288)\n",
            "8256 Traning Loss: tensor(0.0288)\n",
            "8257 Traning Loss: tensor(0.0288)\n",
            "8258 Traning Loss: tensor(0.0288)\n",
            "8259 Traning Loss: tensor(0.0288)\n",
            "8260 Traning Loss: tensor(0.0288)\n",
            "8261 Traning Loss: tensor(0.0288)\n",
            "8262 Traning Loss: tensor(0.0288)\n",
            "8263 Traning Loss: tensor(0.0288)\n",
            "8264 Traning Loss: tensor(0.0288)\n",
            "8265 Traning Loss: tensor(0.0287)\n",
            "8266 Traning Loss: tensor(0.0287)\n",
            "8267 Traning Loss: tensor(0.0287)\n",
            "8268 Traning Loss: tensor(0.0287)\n",
            "8269 Traning Loss: tensor(0.0287)\n",
            "8270 Traning Loss: tensor(0.0287)\n",
            "8271 Traning Loss: tensor(0.0287)\n",
            "8272 Traning Loss: tensor(0.0287)\n",
            "8273 Traning Loss: tensor(0.0287)\n",
            "8274 Traning Loss: tensor(0.0287)\n",
            "8275 Traning Loss: tensor(0.0287)\n",
            "8276 Traning Loss: tensor(0.0287)\n",
            "8277 Traning Loss: tensor(0.0287)\n",
            "8278 Traning Loss: tensor(0.0287)\n",
            "8279 Traning Loss: tensor(0.0287)\n",
            "8280 Traning Loss: tensor(0.0287)\n",
            "8281 Traning Loss: tensor(0.0287)\n",
            "8282 Traning Loss: tensor(0.0287)\n",
            "8283 Traning Loss: tensor(0.0287)\n",
            "8284 Traning Loss: tensor(0.0287)\n",
            "8285 Traning Loss: tensor(0.0287)\n",
            "8286 Traning Loss: tensor(0.0287)\n",
            "8287 Traning Loss: tensor(0.0287)\n",
            "8288 Traning Loss: tensor(0.0287)\n",
            "8289 Traning Loss: tensor(0.0287)\n",
            "8290 Traning Loss: tensor(0.0287)\n",
            "8291 Traning Loss: tensor(0.0287)\n",
            "8292 Traning Loss: tensor(0.0287)\n",
            "8293 Traning Loss: tensor(0.0287)\n",
            "8294 Traning Loss: tensor(0.0287)\n",
            "8295 Traning Loss: tensor(0.0287)\n",
            "8296 Traning Loss: tensor(0.0287)\n",
            "8297 Traning Loss: tensor(0.0287)\n",
            "8298 Traning Loss: tensor(0.0287)\n",
            "8299 Traning Loss: tensor(0.0287)\n",
            "8300 Traning Loss: tensor(0.0287)\n",
            "8301 Traning Loss: tensor(0.0287)\n",
            "8302 Traning Loss: tensor(0.0287)\n",
            "8303 Traning Loss: tensor(0.0287)\n",
            "8304 Traning Loss: tensor(0.0287)\n",
            "8305 Traning Loss: tensor(0.0287)\n",
            "8306 Traning Loss: tensor(0.0287)\n",
            "8307 Traning Loss: tensor(0.0287)\n",
            "8308 Traning Loss: tensor(0.0287)\n",
            "8309 Traning Loss: tensor(0.0287)\n",
            "8310 Traning Loss: tensor(0.0287)\n",
            "8311 Traning Loss: tensor(0.0287)\n",
            "8312 Traning Loss: tensor(0.0287)\n",
            "8313 Traning Loss: tensor(0.0287)\n",
            "8314 Traning Loss: tensor(0.0287)\n",
            "8315 Traning Loss: tensor(0.0287)\n",
            "8316 Traning Loss: tensor(0.0287)\n",
            "8317 Traning Loss: tensor(0.0287)\n",
            "8318 Traning Loss: tensor(0.0287)\n",
            "8319 Traning Loss: tensor(0.0287)\n",
            "8320 Traning Loss: tensor(0.0287)\n",
            "8321 Traning Loss: tensor(0.0287)\n",
            "8322 Traning Loss: tensor(0.0287)\n",
            "8323 Traning Loss: tensor(0.0287)\n",
            "8324 Traning Loss: tensor(0.0287)\n",
            "8325 Traning Loss: tensor(0.0287)\n",
            "8326 Traning Loss: tensor(0.0287)\n",
            "8327 Traning Loss: tensor(0.0287)\n",
            "8328 Traning Loss: tensor(0.0287)\n",
            "8329 Traning Loss: tensor(0.0287)\n",
            "8330 Traning Loss: tensor(0.0287)\n",
            "8331 Traning Loss: tensor(0.0287)\n",
            "8332 Traning Loss: tensor(0.0287)\n",
            "8333 Traning Loss: tensor(0.0286)\n",
            "8334 Traning Loss: tensor(0.0286)\n",
            "8335 Traning Loss: tensor(0.0286)\n",
            "8336 Traning Loss: tensor(0.0286)\n",
            "8337 Traning Loss: tensor(0.0286)\n",
            "8338 Traning Loss: tensor(0.0286)\n",
            "8339 Traning Loss: tensor(0.0286)\n",
            "8340 Traning Loss: tensor(0.0286)\n",
            "8341 Traning Loss: tensor(0.0286)\n",
            "8342 Traning Loss: tensor(0.0286)\n",
            "8343 Traning Loss: tensor(0.0286)\n",
            "8344 Traning Loss: tensor(0.0286)\n",
            "8345 Traning Loss: tensor(0.0286)\n",
            "8346 Traning Loss: tensor(0.0286)\n",
            "8347 Traning Loss: tensor(0.0286)\n",
            "8348 Traning Loss: tensor(0.0286)\n",
            "8349 Traning Loss: tensor(0.0286)\n",
            "8350 Traning Loss: tensor(0.0286)\n",
            "8351 Traning Loss: tensor(0.0286)\n",
            "8352 Traning Loss: tensor(0.0286)\n",
            "8353 Traning Loss: tensor(0.0286)\n",
            "8354 Traning Loss: tensor(0.0286)\n",
            "8355 Traning Loss: tensor(0.0286)\n",
            "8356 Traning Loss: tensor(0.0286)\n",
            "8357 Traning Loss: tensor(0.0286)\n",
            "8358 Traning Loss: tensor(0.0286)\n",
            "8359 Traning Loss: tensor(0.0286)\n",
            "8360 Traning Loss: tensor(0.0286)\n",
            "8361 Traning Loss: tensor(0.0286)\n",
            "8362 Traning Loss: tensor(0.0286)\n",
            "8363 Traning Loss: tensor(0.0286)\n",
            "8364 Traning Loss: tensor(0.0286)\n",
            "8365 Traning Loss: tensor(0.0286)\n",
            "8366 Traning Loss: tensor(0.0286)\n",
            "8367 Traning Loss: tensor(0.0286)\n",
            "8368 Traning Loss: tensor(0.0286)\n",
            "8369 Traning Loss: tensor(0.0286)\n",
            "8370 Traning Loss: tensor(0.0286)\n",
            "8371 Traning Loss: tensor(0.0286)\n",
            "8372 Traning Loss: tensor(0.0286)\n",
            "8373 Traning Loss: tensor(0.0286)\n",
            "8374 Traning Loss: tensor(0.0286)\n",
            "8375 Traning Loss: tensor(0.0286)\n",
            "8376 Traning Loss: tensor(0.0286)\n",
            "8377 Traning Loss: tensor(0.0286)\n",
            "8378 Traning Loss: tensor(0.0286)\n",
            "8379 Traning Loss: tensor(0.0286)\n",
            "8380 Traning Loss: tensor(0.0286)\n",
            "8381 Traning Loss: tensor(0.0286)\n",
            "8382 Traning Loss: tensor(0.0286)\n",
            "8383 Traning Loss: tensor(0.0286)\n",
            "8384 Traning Loss: tensor(0.0286)\n",
            "8385 Traning Loss: tensor(0.0286)\n",
            "8386 Traning Loss: tensor(0.0286)\n",
            "8387 Traning Loss: tensor(0.0286)\n",
            "8388 Traning Loss: tensor(0.0286)\n",
            "8389 Traning Loss: tensor(0.0286)\n",
            "8390 Traning Loss: tensor(0.0286)\n",
            "8391 Traning Loss: tensor(0.0286)\n",
            "8392 Traning Loss: tensor(0.0286)\n",
            "8393 Traning Loss: tensor(0.0286)\n",
            "8394 Traning Loss: tensor(0.0286)\n",
            "8395 Traning Loss: tensor(0.0286)\n",
            "8396 Traning Loss: tensor(0.0286)\n",
            "8397 Traning Loss: tensor(0.0286)\n",
            "8398 Traning Loss: tensor(0.0286)\n",
            "8399 Traning Loss: tensor(0.0286)\n",
            "8400 Traning Loss: tensor(0.0286)\n",
            "8401 Traning Loss: tensor(0.0286)\n",
            "8402 Traning Loss: tensor(0.0285)\n",
            "8403 Traning Loss: tensor(0.0285)\n",
            "8404 Traning Loss: tensor(0.0285)\n",
            "8405 Traning Loss: tensor(0.0285)\n",
            "8406 Traning Loss: tensor(0.0285)\n",
            "8407 Traning Loss: tensor(0.0285)\n",
            "8408 Traning Loss: tensor(0.0285)\n",
            "8409 Traning Loss: tensor(0.0285)\n",
            "8410 Traning Loss: tensor(0.0285)\n",
            "8411 Traning Loss: tensor(0.0285)\n",
            "8412 Traning Loss: tensor(0.0285)\n",
            "8413 Traning Loss: tensor(0.0285)\n",
            "8414 Traning Loss: tensor(0.0285)\n",
            "8415 Traning Loss: tensor(0.0285)\n",
            "8416 Traning Loss: tensor(0.0285)\n",
            "8417 Traning Loss: tensor(0.0285)\n",
            "8418 Traning Loss: tensor(0.0285)\n",
            "8419 Traning Loss: tensor(0.0285)\n",
            "8420 Traning Loss: tensor(0.0285)\n",
            "8421 Traning Loss: tensor(0.0285)\n",
            "8422 Traning Loss: tensor(0.0285)\n",
            "8423 Traning Loss: tensor(0.0285)\n",
            "8424 Traning Loss: tensor(0.0285)\n",
            "8425 Traning Loss: tensor(0.0285)\n",
            "8426 Traning Loss: tensor(0.0285)\n",
            "8427 Traning Loss: tensor(0.0285)\n",
            "8428 Traning Loss: tensor(0.0285)\n",
            "8429 Traning Loss: tensor(0.0285)\n",
            "8430 Traning Loss: tensor(0.0285)\n",
            "8431 Traning Loss: tensor(0.0285)\n",
            "8432 Traning Loss: tensor(0.0285)\n",
            "8433 Traning Loss: tensor(0.0285)\n",
            "8434 Traning Loss: tensor(0.0285)\n",
            "8435 Traning Loss: tensor(0.0285)\n",
            "8436 Traning Loss: tensor(0.0285)\n",
            "8437 Traning Loss: tensor(0.0285)\n",
            "8438 Traning Loss: tensor(0.0285)\n",
            "8439 Traning Loss: tensor(0.0285)\n",
            "8440 Traning Loss: tensor(0.0285)\n",
            "8441 Traning Loss: tensor(0.0285)\n",
            "8442 Traning Loss: tensor(0.0285)\n",
            "8443 Traning Loss: tensor(0.0285)\n",
            "8444 Traning Loss: tensor(0.0285)\n",
            "8445 Traning Loss: tensor(0.0285)\n",
            "8446 Traning Loss: tensor(0.0285)\n",
            "8447 Traning Loss: tensor(0.0285)\n",
            "8448 Traning Loss: tensor(0.0285)\n",
            "8449 Traning Loss: tensor(0.0285)\n",
            "8450 Traning Loss: tensor(0.0285)\n",
            "8451 Traning Loss: tensor(0.0285)\n",
            "8452 Traning Loss: tensor(0.0285)\n",
            "8453 Traning Loss: tensor(0.0285)\n",
            "8454 Traning Loss: tensor(0.0285)\n",
            "8455 Traning Loss: tensor(0.0285)\n",
            "8456 Traning Loss: tensor(0.0285)\n",
            "8457 Traning Loss: tensor(0.0285)\n",
            "8458 Traning Loss: tensor(0.0285)\n",
            "8459 Traning Loss: tensor(0.0285)\n",
            "8460 Traning Loss: tensor(0.0285)\n",
            "8461 Traning Loss: tensor(0.0285)\n",
            "8462 Traning Loss: tensor(0.0285)\n",
            "8463 Traning Loss: tensor(0.0285)\n",
            "8464 Traning Loss: tensor(0.0285)\n",
            "8465 Traning Loss: tensor(0.0285)\n",
            "8466 Traning Loss: tensor(0.0285)\n",
            "8467 Traning Loss: tensor(0.0285)\n",
            "8468 Traning Loss: tensor(0.0285)\n",
            "8469 Traning Loss: tensor(0.0285)\n",
            "8470 Traning Loss: tensor(0.0285)\n",
            "8471 Traning Loss: tensor(0.0285)\n",
            "8472 Traning Loss: tensor(0.0284)\n",
            "8473 Traning Loss: tensor(0.0284)\n",
            "8474 Traning Loss: tensor(0.0284)\n",
            "8475 Traning Loss: tensor(0.0284)\n",
            "8476 Traning Loss: tensor(0.0284)\n",
            "8477 Traning Loss: tensor(0.0284)\n",
            "8478 Traning Loss: tensor(0.0284)\n",
            "8479 Traning Loss: tensor(0.0284)\n",
            "8480 Traning Loss: tensor(0.0284)\n",
            "8481 Traning Loss: tensor(0.0284)\n",
            "8482 Traning Loss: tensor(0.0284)\n",
            "8483 Traning Loss: tensor(0.0284)\n",
            "8484 Traning Loss: tensor(0.0284)\n",
            "8485 Traning Loss: tensor(0.0284)\n",
            "8486 Traning Loss: tensor(0.0284)\n",
            "8487 Traning Loss: tensor(0.0284)\n",
            "8488 Traning Loss: tensor(0.0284)\n",
            "8489 Traning Loss: tensor(0.0284)\n",
            "8490 Traning Loss: tensor(0.0284)\n",
            "8491 Traning Loss: tensor(0.0284)\n",
            "8492 Traning Loss: tensor(0.0284)\n",
            "8493 Traning Loss: tensor(0.0284)\n",
            "8494 Traning Loss: tensor(0.0284)\n",
            "8495 Traning Loss: tensor(0.0284)\n",
            "8496 Traning Loss: tensor(0.0284)\n",
            "8497 Traning Loss: tensor(0.0284)\n",
            "8498 Traning Loss: tensor(0.0284)\n",
            "8499 Traning Loss: tensor(0.0284)\n",
            "8500 Traning Loss: tensor(0.0284)\n",
            "8501 Traning Loss: tensor(0.0284)\n",
            "8502 Traning Loss: tensor(0.0284)\n",
            "8503 Traning Loss: tensor(0.0284)\n",
            "8504 Traning Loss: tensor(0.0284)\n",
            "8505 Traning Loss: tensor(0.0284)\n",
            "8506 Traning Loss: tensor(0.0284)\n",
            "8507 Traning Loss: tensor(0.0284)\n",
            "8508 Traning Loss: tensor(0.0284)\n",
            "8509 Traning Loss: tensor(0.0284)\n",
            "8510 Traning Loss: tensor(0.0284)\n",
            "8511 Traning Loss: tensor(0.0284)\n",
            "8512 Traning Loss: tensor(0.0284)\n",
            "8513 Traning Loss: tensor(0.0284)\n",
            "8514 Traning Loss: tensor(0.0284)\n",
            "8515 Traning Loss: tensor(0.0284)\n",
            "8516 Traning Loss: tensor(0.0284)\n",
            "8517 Traning Loss: tensor(0.0284)\n",
            "8518 Traning Loss: tensor(0.0284)\n",
            "8519 Traning Loss: tensor(0.0284)\n",
            "8520 Traning Loss: tensor(0.0284)\n",
            "8521 Traning Loss: tensor(0.0284)\n",
            "8522 Traning Loss: tensor(0.0284)\n",
            "8523 Traning Loss: tensor(0.0284)\n",
            "8524 Traning Loss: tensor(0.0284)\n",
            "8525 Traning Loss: tensor(0.0284)\n",
            "8526 Traning Loss: tensor(0.0284)\n",
            "8527 Traning Loss: tensor(0.0284)\n",
            "8528 Traning Loss: tensor(0.0284)\n",
            "8529 Traning Loss: tensor(0.0284)\n",
            "8530 Traning Loss: tensor(0.0284)\n",
            "8531 Traning Loss: tensor(0.0284)\n",
            "8532 Traning Loss: tensor(0.0284)\n",
            "8533 Traning Loss: tensor(0.0284)\n",
            "8534 Traning Loss: tensor(0.0284)\n",
            "8535 Traning Loss: tensor(0.0284)\n",
            "8536 Traning Loss: tensor(0.0284)\n",
            "8537 Traning Loss: tensor(0.0284)\n",
            "8538 Traning Loss: tensor(0.0284)\n",
            "8539 Traning Loss: tensor(0.0284)\n",
            "8540 Traning Loss: tensor(0.0284)\n",
            "8541 Traning Loss: tensor(0.0284)\n",
            "8542 Traning Loss: tensor(0.0284)\n",
            "8543 Traning Loss: tensor(0.0284)\n",
            "8544 Traning Loss: tensor(0.0283)\n",
            "8545 Traning Loss: tensor(0.0283)\n",
            "8546 Traning Loss: tensor(0.0283)\n",
            "8547 Traning Loss: tensor(0.0283)\n",
            "8548 Traning Loss: tensor(0.0283)\n",
            "8549 Traning Loss: tensor(0.0283)\n",
            "8550 Traning Loss: tensor(0.0283)\n",
            "8551 Traning Loss: tensor(0.0283)\n",
            "8552 Traning Loss: tensor(0.0283)\n",
            "8553 Traning Loss: tensor(0.0283)\n",
            "8554 Traning Loss: tensor(0.0283)\n",
            "8555 Traning Loss: tensor(0.0283)\n",
            "8556 Traning Loss: tensor(0.0283)\n",
            "8557 Traning Loss: tensor(0.0283)\n",
            "8558 Traning Loss: tensor(0.0283)\n",
            "8559 Traning Loss: tensor(0.0283)\n",
            "8560 Traning Loss: tensor(0.0283)\n",
            "8561 Traning Loss: tensor(0.0283)\n",
            "8562 Traning Loss: tensor(0.0283)\n",
            "8563 Traning Loss: tensor(0.0283)\n",
            "8564 Traning Loss: tensor(0.0283)\n",
            "8565 Traning Loss: tensor(0.0283)\n",
            "8566 Traning Loss: tensor(0.0283)\n",
            "8567 Traning Loss: tensor(0.0283)\n",
            "8568 Traning Loss: tensor(0.0283)\n",
            "8569 Traning Loss: tensor(0.0283)\n",
            "8570 Traning Loss: tensor(0.0283)\n",
            "8571 Traning Loss: tensor(0.0283)\n",
            "8572 Traning Loss: tensor(0.0283)\n",
            "8573 Traning Loss: tensor(0.0283)\n",
            "8574 Traning Loss: tensor(0.0283)\n",
            "8575 Traning Loss: tensor(0.0283)\n",
            "8576 Traning Loss: tensor(0.0283)\n",
            "8577 Traning Loss: tensor(0.0283)\n",
            "8578 Traning Loss: tensor(0.0283)\n",
            "8579 Traning Loss: tensor(0.0283)\n",
            "8580 Traning Loss: tensor(0.0283)\n",
            "8581 Traning Loss: tensor(0.0283)\n",
            "8582 Traning Loss: tensor(0.0283)\n",
            "8583 Traning Loss: tensor(0.0283)\n",
            "8584 Traning Loss: tensor(0.0283)\n",
            "8585 Traning Loss: tensor(0.0283)\n",
            "8586 Traning Loss: tensor(0.0283)\n",
            "8587 Traning Loss: tensor(0.0283)\n",
            "8588 Traning Loss: tensor(0.0283)\n",
            "8589 Traning Loss: tensor(0.0283)\n",
            "8590 Traning Loss: tensor(0.0283)\n",
            "8591 Traning Loss: tensor(0.0283)\n",
            "8592 Traning Loss: tensor(0.0283)\n",
            "8593 Traning Loss: tensor(0.0283)\n",
            "8594 Traning Loss: tensor(0.0283)\n",
            "8595 Traning Loss: tensor(0.0283)\n",
            "8596 Traning Loss: tensor(0.0283)\n",
            "8597 Traning Loss: tensor(0.0283)\n",
            "8598 Traning Loss: tensor(0.0283)\n",
            "8599 Traning Loss: tensor(0.0283)\n",
            "8600 Traning Loss: tensor(0.0283)\n",
            "8601 Traning Loss: tensor(0.0283)\n",
            "8602 Traning Loss: tensor(0.0283)\n",
            "8603 Traning Loss: tensor(0.0283)\n",
            "8604 Traning Loss: tensor(0.0283)\n",
            "8605 Traning Loss: tensor(0.0283)\n",
            "8606 Traning Loss: tensor(0.0283)\n",
            "8607 Traning Loss: tensor(0.0283)\n",
            "8608 Traning Loss: tensor(0.0283)\n",
            "8609 Traning Loss: tensor(0.0283)\n",
            "8610 Traning Loss: tensor(0.0283)\n",
            "8611 Traning Loss: tensor(0.0283)\n",
            "8612 Traning Loss: tensor(0.0283)\n",
            "8613 Traning Loss: tensor(0.0283)\n",
            "8614 Traning Loss: tensor(0.0283)\n",
            "8615 Traning Loss: tensor(0.0283)\n",
            "8616 Traning Loss: tensor(0.0282)\n",
            "8617 Traning Loss: tensor(0.0282)\n",
            "8618 Traning Loss: tensor(0.0282)\n",
            "8619 Traning Loss: tensor(0.0282)\n",
            "8620 Traning Loss: tensor(0.0282)\n",
            "8621 Traning Loss: tensor(0.0282)\n",
            "8622 Traning Loss: tensor(0.0282)\n",
            "8623 Traning Loss: tensor(0.0282)\n",
            "8624 Traning Loss: tensor(0.0282)\n",
            "8625 Traning Loss: tensor(0.0282)\n",
            "8626 Traning Loss: tensor(0.0282)\n",
            "8627 Traning Loss: tensor(0.0282)\n",
            "8628 Traning Loss: tensor(0.0282)\n",
            "8629 Traning Loss: tensor(0.0282)\n",
            "8630 Traning Loss: tensor(0.0282)\n",
            "8631 Traning Loss: tensor(0.0282)\n",
            "8632 Traning Loss: tensor(0.0282)\n",
            "8633 Traning Loss: tensor(0.0282)\n",
            "8634 Traning Loss: tensor(0.0282)\n",
            "8635 Traning Loss: tensor(0.0282)\n",
            "8636 Traning Loss: tensor(0.0282)\n",
            "8637 Traning Loss: tensor(0.0282)\n",
            "8638 Traning Loss: tensor(0.0282)\n",
            "8639 Traning Loss: tensor(0.0282)\n",
            "8640 Traning Loss: tensor(0.0282)\n",
            "8641 Traning Loss: tensor(0.0282)\n",
            "8642 Traning Loss: tensor(0.0282)\n",
            "8643 Traning Loss: tensor(0.0282)\n",
            "8644 Traning Loss: tensor(0.0282)\n",
            "8645 Traning Loss: tensor(0.0282)\n",
            "8646 Traning Loss: tensor(0.0282)\n",
            "8647 Traning Loss: tensor(0.0282)\n",
            "8648 Traning Loss: tensor(0.0282)\n",
            "8649 Traning Loss: tensor(0.0282)\n",
            "8650 Traning Loss: tensor(0.0282)\n",
            "8651 Traning Loss: tensor(0.0282)\n",
            "8652 Traning Loss: tensor(0.0282)\n",
            "8653 Traning Loss: tensor(0.0282)\n",
            "8654 Traning Loss: tensor(0.0282)\n",
            "8655 Traning Loss: tensor(0.0282)\n",
            "8656 Traning Loss: tensor(0.0282)\n",
            "8657 Traning Loss: tensor(0.0282)\n",
            "8658 Traning Loss: tensor(0.0282)\n",
            "8659 Traning Loss: tensor(0.0282)\n",
            "8660 Traning Loss: tensor(0.0282)\n",
            "8661 Traning Loss: tensor(0.0282)\n",
            "8662 Traning Loss: tensor(0.0282)\n",
            "8663 Traning Loss: tensor(0.0282)\n",
            "8664 Traning Loss: tensor(0.0282)\n",
            "8665 Traning Loss: tensor(0.0282)\n",
            "8666 Traning Loss: tensor(0.0282)\n",
            "8667 Traning Loss: tensor(0.0282)\n",
            "8668 Traning Loss: tensor(0.0282)\n",
            "8669 Traning Loss: tensor(0.0282)\n",
            "8670 Traning Loss: tensor(0.0282)\n",
            "8671 Traning Loss: tensor(0.0282)\n",
            "8672 Traning Loss: tensor(0.0282)\n",
            "8673 Traning Loss: tensor(0.0282)\n",
            "8674 Traning Loss: tensor(0.0282)\n",
            "8675 Traning Loss: tensor(0.0282)\n",
            "8676 Traning Loss: tensor(0.0282)\n",
            "8677 Traning Loss: tensor(0.0282)\n",
            "8678 Traning Loss: tensor(0.0282)\n",
            "8679 Traning Loss: tensor(0.0282)\n",
            "8680 Traning Loss: tensor(0.0282)\n",
            "8681 Traning Loss: tensor(0.0282)\n",
            "8682 Traning Loss: tensor(0.0282)\n",
            "8683 Traning Loss: tensor(0.0282)\n",
            "8684 Traning Loss: tensor(0.0282)\n",
            "8685 Traning Loss: tensor(0.0282)\n",
            "8686 Traning Loss: tensor(0.0282)\n",
            "8687 Traning Loss: tensor(0.0282)\n",
            "8688 Traning Loss: tensor(0.0282)\n",
            "8689 Traning Loss: tensor(0.0281)\n",
            "8690 Traning Loss: tensor(0.0281)\n",
            "8691 Traning Loss: tensor(0.0281)\n",
            "8692 Traning Loss: tensor(0.0281)\n",
            "8693 Traning Loss: tensor(0.0281)\n",
            "8694 Traning Loss: tensor(0.0281)\n",
            "8695 Traning Loss: tensor(0.0281)\n",
            "8696 Traning Loss: tensor(0.0281)\n",
            "8697 Traning Loss: tensor(0.0281)\n",
            "8698 Traning Loss: tensor(0.0281)\n",
            "8699 Traning Loss: tensor(0.0281)\n",
            "8700 Traning Loss: tensor(0.0281)\n",
            "8701 Traning Loss: tensor(0.0281)\n",
            "8702 Traning Loss: tensor(0.0281)\n",
            "8703 Traning Loss: tensor(0.0281)\n",
            "8704 Traning Loss: tensor(0.0281)\n",
            "8705 Traning Loss: tensor(0.0281)\n",
            "8706 Traning Loss: tensor(0.0281)\n",
            "8707 Traning Loss: tensor(0.0281)\n",
            "8708 Traning Loss: tensor(0.0281)\n",
            "8709 Traning Loss: tensor(0.0281)\n",
            "8710 Traning Loss: tensor(0.0281)\n",
            "8711 Traning Loss: tensor(0.0281)\n",
            "8712 Traning Loss: tensor(0.0281)\n",
            "8713 Traning Loss: tensor(0.0281)\n",
            "8714 Traning Loss: tensor(0.0281)\n",
            "8715 Traning Loss: tensor(0.0281)\n",
            "8716 Traning Loss: tensor(0.0281)\n",
            "8717 Traning Loss: tensor(0.0281)\n",
            "8718 Traning Loss: tensor(0.0281)\n",
            "8719 Traning Loss: tensor(0.0281)\n",
            "8720 Traning Loss: tensor(0.0281)\n",
            "8721 Traning Loss: tensor(0.0281)\n",
            "8722 Traning Loss: tensor(0.0281)\n",
            "8723 Traning Loss: tensor(0.0281)\n",
            "8724 Traning Loss: tensor(0.0281)\n",
            "8725 Traning Loss: tensor(0.0281)\n",
            "8726 Traning Loss: tensor(0.0281)\n",
            "8727 Traning Loss: tensor(0.0281)\n",
            "8728 Traning Loss: tensor(0.0281)\n",
            "8729 Traning Loss: tensor(0.0281)\n",
            "8730 Traning Loss: tensor(0.0281)\n",
            "8731 Traning Loss: tensor(0.0281)\n",
            "8732 Traning Loss: tensor(0.0281)\n",
            "8733 Traning Loss: tensor(0.0281)\n",
            "8734 Traning Loss: tensor(0.0281)\n",
            "8735 Traning Loss: tensor(0.0281)\n",
            "8736 Traning Loss: tensor(0.0281)\n",
            "8737 Traning Loss: tensor(0.0281)\n",
            "8738 Traning Loss: tensor(0.0281)\n",
            "8739 Traning Loss: tensor(0.0281)\n",
            "8740 Traning Loss: tensor(0.0281)\n",
            "8741 Traning Loss: tensor(0.0281)\n",
            "8742 Traning Loss: tensor(0.0281)\n",
            "8743 Traning Loss: tensor(0.0281)\n",
            "8744 Traning Loss: tensor(0.0281)\n",
            "8745 Traning Loss: tensor(0.0281)\n",
            "8746 Traning Loss: tensor(0.0281)\n",
            "8747 Traning Loss: tensor(0.0281)\n",
            "8748 Traning Loss: tensor(0.0281)\n",
            "8749 Traning Loss: tensor(0.0281)\n",
            "8750 Traning Loss: tensor(0.0281)\n",
            "8751 Traning Loss: tensor(0.0281)\n",
            "8752 Traning Loss: tensor(0.0281)\n",
            "8753 Traning Loss: tensor(0.0281)\n",
            "8754 Traning Loss: tensor(0.0281)\n",
            "8755 Traning Loss: tensor(0.0281)\n",
            "8756 Traning Loss: tensor(0.0281)\n",
            "8757 Traning Loss: tensor(0.0281)\n",
            "8758 Traning Loss: tensor(0.0281)\n",
            "8759 Traning Loss: tensor(0.0281)\n",
            "8760 Traning Loss: tensor(0.0281)\n",
            "8761 Traning Loss: tensor(0.0281)\n",
            "8762 Traning Loss: tensor(0.0281)\n",
            "8763 Traning Loss: tensor(0.0281)\n",
            "8764 Traning Loss: tensor(0.0280)\n",
            "8765 Traning Loss: tensor(0.0280)\n",
            "8766 Traning Loss: tensor(0.0280)\n",
            "8767 Traning Loss: tensor(0.0280)\n",
            "8768 Traning Loss: tensor(0.0280)\n",
            "8769 Traning Loss: tensor(0.0280)\n",
            "8770 Traning Loss: tensor(0.0280)\n",
            "8771 Traning Loss: tensor(0.0280)\n",
            "8772 Traning Loss: tensor(0.0280)\n",
            "8773 Traning Loss: tensor(0.0280)\n",
            "8774 Traning Loss: tensor(0.0280)\n",
            "8775 Traning Loss: tensor(0.0280)\n",
            "8776 Traning Loss: tensor(0.0280)\n",
            "8777 Traning Loss: tensor(0.0280)\n",
            "8778 Traning Loss: tensor(0.0280)\n",
            "8779 Traning Loss: tensor(0.0280)\n",
            "8780 Traning Loss: tensor(0.0280)\n",
            "8781 Traning Loss: tensor(0.0280)\n",
            "8782 Traning Loss: tensor(0.0280)\n",
            "8783 Traning Loss: tensor(0.0280)\n",
            "8784 Traning Loss: tensor(0.0280)\n",
            "8785 Traning Loss: tensor(0.0280)\n",
            "8786 Traning Loss: tensor(0.0280)\n",
            "8787 Traning Loss: tensor(0.0280)\n",
            "8788 Traning Loss: tensor(0.0280)\n",
            "8789 Traning Loss: tensor(0.0280)\n",
            "8790 Traning Loss: tensor(0.0280)\n",
            "8791 Traning Loss: tensor(0.0280)\n",
            "8792 Traning Loss: tensor(0.0280)\n",
            "8793 Traning Loss: tensor(0.0280)\n",
            "8794 Traning Loss: tensor(0.0280)\n",
            "8795 Traning Loss: tensor(0.0280)\n",
            "8796 Traning Loss: tensor(0.0280)\n",
            "8797 Traning Loss: tensor(0.0280)\n",
            "8798 Traning Loss: tensor(0.0280)\n",
            "8799 Traning Loss: tensor(0.0280)\n",
            "8800 Traning Loss: tensor(0.0280)\n",
            "8801 Traning Loss: tensor(0.0280)\n",
            "8802 Traning Loss: tensor(0.0280)\n",
            "8803 Traning Loss: tensor(0.0280)\n",
            "8804 Traning Loss: tensor(0.0280)\n",
            "8805 Traning Loss: tensor(0.0280)\n",
            "8806 Traning Loss: tensor(0.0280)\n",
            "8807 Traning Loss: tensor(0.0280)\n",
            "8808 Traning Loss: tensor(0.0280)\n",
            "8809 Traning Loss: tensor(0.0280)\n",
            "8810 Traning Loss: tensor(0.0280)\n",
            "8811 Traning Loss: tensor(0.0280)\n",
            "8812 Traning Loss: tensor(0.0280)\n",
            "8813 Traning Loss: tensor(0.0280)\n",
            "8814 Traning Loss: tensor(0.0280)\n",
            "8815 Traning Loss: tensor(0.0280)\n",
            "8816 Traning Loss: tensor(0.0280)\n",
            "8817 Traning Loss: tensor(0.0280)\n",
            "8818 Traning Loss: tensor(0.0280)\n",
            "8819 Traning Loss: tensor(0.0280)\n",
            "8820 Traning Loss: tensor(0.0280)\n",
            "8821 Traning Loss: tensor(0.0280)\n",
            "8822 Traning Loss: tensor(0.0280)\n",
            "8823 Traning Loss: tensor(0.0280)\n",
            "8824 Traning Loss: tensor(0.0280)\n",
            "8825 Traning Loss: tensor(0.0280)\n",
            "8826 Traning Loss: tensor(0.0280)\n",
            "8827 Traning Loss: tensor(0.0280)\n",
            "8828 Traning Loss: tensor(0.0280)\n",
            "8829 Traning Loss: tensor(0.0280)\n",
            "8830 Traning Loss: tensor(0.0280)\n",
            "8831 Traning Loss: tensor(0.0280)\n",
            "8832 Traning Loss: tensor(0.0280)\n",
            "8833 Traning Loss: tensor(0.0280)\n",
            "8834 Traning Loss: tensor(0.0280)\n",
            "8835 Traning Loss: tensor(0.0280)\n",
            "8836 Traning Loss: tensor(0.0280)\n",
            "8837 Traning Loss: tensor(0.0280)\n",
            "8838 Traning Loss: tensor(0.0280)\n",
            "8839 Traning Loss: tensor(0.0279)\n",
            "8840 Traning Loss: tensor(0.0279)\n",
            "8841 Traning Loss: tensor(0.0279)\n",
            "8842 Traning Loss: tensor(0.0279)\n",
            "8843 Traning Loss: tensor(0.0279)\n",
            "8844 Traning Loss: tensor(0.0279)\n",
            "8845 Traning Loss: tensor(0.0279)\n",
            "8846 Traning Loss: tensor(0.0279)\n",
            "8847 Traning Loss: tensor(0.0279)\n",
            "8848 Traning Loss: tensor(0.0279)\n",
            "8849 Traning Loss: tensor(0.0279)\n",
            "8850 Traning Loss: tensor(0.0279)\n",
            "8851 Traning Loss: tensor(0.0279)\n",
            "8852 Traning Loss: tensor(0.0279)\n",
            "8853 Traning Loss: tensor(0.0279)\n",
            "8854 Traning Loss: tensor(0.0279)\n",
            "8855 Traning Loss: tensor(0.0279)\n",
            "8856 Traning Loss: tensor(0.0279)\n",
            "8857 Traning Loss: tensor(0.0279)\n",
            "8858 Traning Loss: tensor(0.0279)\n",
            "8859 Traning Loss: tensor(0.0279)\n",
            "8860 Traning Loss: tensor(0.0279)\n",
            "8861 Traning Loss: tensor(0.0279)\n",
            "8862 Traning Loss: tensor(0.0279)\n",
            "8863 Traning Loss: tensor(0.0279)\n",
            "8864 Traning Loss: tensor(0.0279)\n",
            "8865 Traning Loss: tensor(0.0279)\n",
            "8866 Traning Loss: tensor(0.0279)\n",
            "8867 Traning Loss: tensor(0.0279)\n",
            "8868 Traning Loss: tensor(0.0279)\n",
            "8869 Traning Loss: tensor(0.0279)\n",
            "8870 Traning Loss: tensor(0.0279)\n",
            "8871 Traning Loss: tensor(0.0279)\n",
            "8872 Traning Loss: tensor(0.0279)\n",
            "8873 Traning Loss: tensor(0.0279)\n",
            "8874 Traning Loss: tensor(0.0279)\n",
            "8875 Traning Loss: tensor(0.0279)\n",
            "8876 Traning Loss: tensor(0.0279)\n",
            "8877 Traning Loss: tensor(0.0279)\n",
            "8878 Traning Loss: tensor(0.0279)\n",
            "8879 Traning Loss: tensor(0.0279)\n",
            "8880 Traning Loss: tensor(0.0279)\n",
            "8881 Traning Loss: tensor(0.0279)\n",
            "8882 Traning Loss: tensor(0.0279)\n",
            "8883 Traning Loss: tensor(0.0279)\n",
            "8884 Traning Loss: tensor(0.0279)\n",
            "8885 Traning Loss: tensor(0.0279)\n",
            "8886 Traning Loss: tensor(0.0279)\n",
            "8887 Traning Loss: tensor(0.0279)\n",
            "8888 Traning Loss: tensor(0.0279)\n",
            "8889 Traning Loss: tensor(0.0279)\n",
            "8890 Traning Loss: tensor(0.0279)\n",
            "8891 Traning Loss: tensor(0.0279)\n",
            "8892 Traning Loss: tensor(0.0279)\n",
            "8893 Traning Loss: tensor(0.0279)\n",
            "8894 Traning Loss: tensor(0.0279)\n",
            "8895 Traning Loss: tensor(0.0279)\n",
            "8896 Traning Loss: tensor(0.0279)\n",
            "8897 Traning Loss: tensor(0.0279)\n",
            "8898 Traning Loss: tensor(0.0279)\n",
            "8899 Traning Loss: tensor(0.0279)\n",
            "8900 Traning Loss: tensor(0.0279)\n",
            "8901 Traning Loss: tensor(0.0279)\n",
            "8902 Traning Loss: tensor(0.0279)\n",
            "8903 Traning Loss: tensor(0.0279)\n",
            "8904 Traning Loss: tensor(0.0279)\n",
            "8905 Traning Loss: tensor(0.0279)\n",
            "8906 Traning Loss: tensor(0.0279)\n",
            "8907 Traning Loss: tensor(0.0279)\n",
            "8908 Traning Loss: tensor(0.0279)\n",
            "8909 Traning Loss: tensor(0.0279)\n",
            "8910 Traning Loss: tensor(0.0279)\n",
            "8911 Traning Loss: tensor(0.0279)\n",
            "8912 Traning Loss: tensor(0.0279)\n",
            "8913 Traning Loss: tensor(0.0279)\n",
            "8914 Traning Loss: tensor(0.0279)\n",
            "8915 Traning Loss: tensor(0.0279)\n",
            "8916 Traning Loss: tensor(0.0278)\n",
            "8917 Traning Loss: tensor(0.0278)\n",
            "8918 Traning Loss: tensor(0.0278)\n",
            "8919 Traning Loss: tensor(0.0278)\n",
            "8920 Traning Loss: tensor(0.0278)\n",
            "8921 Traning Loss: tensor(0.0278)\n",
            "8922 Traning Loss: tensor(0.0278)\n",
            "8923 Traning Loss: tensor(0.0278)\n",
            "8924 Traning Loss: tensor(0.0278)\n",
            "8925 Traning Loss: tensor(0.0278)\n",
            "8926 Traning Loss: tensor(0.0278)\n",
            "8927 Traning Loss: tensor(0.0278)\n",
            "8928 Traning Loss: tensor(0.0278)\n",
            "8929 Traning Loss: tensor(0.0278)\n",
            "8930 Traning Loss: tensor(0.0278)\n",
            "8931 Traning Loss: tensor(0.0278)\n",
            "8932 Traning Loss: tensor(0.0278)\n",
            "8933 Traning Loss: tensor(0.0278)\n",
            "8934 Traning Loss: tensor(0.0278)\n",
            "8935 Traning Loss: tensor(0.0278)\n",
            "8936 Traning Loss: tensor(0.0278)\n",
            "8937 Traning Loss: tensor(0.0278)\n",
            "8938 Traning Loss: tensor(0.0278)\n",
            "8939 Traning Loss: tensor(0.0278)\n",
            "8940 Traning Loss: tensor(0.0278)\n",
            "8941 Traning Loss: tensor(0.0278)\n",
            "8942 Traning Loss: tensor(0.0278)\n",
            "8943 Traning Loss: tensor(0.0278)\n",
            "8944 Traning Loss: tensor(0.0278)\n",
            "8945 Traning Loss: tensor(0.0278)\n",
            "8946 Traning Loss: tensor(0.0278)\n",
            "8947 Traning Loss: tensor(0.0278)\n",
            "8948 Traning Loss: tensor(0.0278)\n",
            "8949 Traning Loss: tensor(0.0278)\n",
            "8950 Traning Loss: tensor(0.0278)\n",
            "8951 Traning Loss: tensor(0.0278)\n",
            "8952 Traning Loss: tensor(0.0278)\n",
            "8953 Traning Loss: tensor(0.0278)\n",
            "8954 Traning Loss: tensor(0.0278)\n",
            "8955 Traning Loss: tensor(0.0278)\n",
            "8956 Traning Loss: tensor(0.0278)\n",
            "8957 Traning Loss: tensor(0.0278)\n",
            "8958 Traning Loss: tensor(0.0278)\n",
            "8959 Traning Loss: tensor(0.0278)\n",
            "8960 Traning Loss: tensor(0.0278)\n",
            "8961 Traning Loss: tensor(0.0278)\n",
            "8962 Traning Loss: tensor(0.0278)\n",
            "8963 Traning Loss: tensor(0.0278)\n",
            "8964 Traning Loss: tensor(0.0278)\n",
            "8965 Traning Loss: tensor(0.0278)\n",
            "8966 Traning Loss: tensor(0.0278)\n",
            "8967 Traning Loss: tensor(0.0278)\n",
            "8968 Traning Loss: tensor(0.0278)\n",
            "8969 Traning Loss: tensor(0.0278)\n",
            "8970 Traning Loss: tensor(0.0278)\n",
            "8971 Traning Loss: tensor(0.0278)\n",
            "8972 Traning Loss: tensor(0.0278)\n",
            "8973 Traning Loss: tensor(0.0278)\n",
            "8974 Traning Loss: tensor(0.0278)\n",
            "8975 Traning Loss: tensor(0.0278)\n",
            "8976 Traning Loss: tensor(0.0278)\n",
            "8977 Traning Loss: tensor(0.0278)\n",
            "8978 Traning Loss: tensor(0.0278)\n",
            "8979 Traning Loss: tensor(0.0278)\n",
            "8980 Traning Loss: tensor(0.0278)\n",
            "8981 Traning Loss: tensor(0.0278)\n",
            "8982 Traning Loss: tensor(0.0278)\n",
            "8983 Traning Loss: tensor(0.0278)\n",
            "8984 Traning Loss: tensor(0.0278)\n",
            "8985 Traning Loss: tensor(0.0278)\n",
            "8986 Traning Loss: tensor(0.0278)\n",
            "8987 Traning Loss: tensor(0.0278)\n",
            "8988 Traning Loss: tensor(0.0278)\n",
            "8989 Traning Loss: tensor(0.0278)\n",
            "8990 Traning Loss: tensor(0.0278)\n",
            "8991 Traning Loss: tensor(0.0278)\n",
            "8992 Traning Loss: tensor(0.0278)\n",
            "8993 Traning Loss: tensor(0.0278)\n",
            "8994 Traning Loss: tensor(0.0277)\n",
            "8995 Traning Loss: tensor(0.0277)\n",
            "8996 Traning Loss: tensor(0.0277)\n",
            "8997 Traning Loss: tensor(0.0277)\n",
            "8998 Traning Loss: tensor(0.0277)\n",
            "8999 Traning Loss: tensor(0.0277)\n",
            "9000 Traning Loss: tensor(0.0277)\n",
            "9001 Traning Loss: tensor(0.0277)\n",
            "9002 Traning Loss: tensor(0.0277)\n",
            "9003 Traning Loss: tensor(0.0277)\n",
            "9004 Traning Loss: tensor(0.0277)\n",
            "9005 Traning Loss: tensor(0.0277)\n",
            "9006 Traning Loss: tensor(0.0277)\n",
            "9007 Traning Loss: tensor(0.0277)\n",
            "9008 Traning Loss: tensor(0.0277)\n",
            "9009 Traning Loss: tensor(0.0277)\n",
            "9010 Traning Loss: tensor(0.0277)\n",
            "9011 Traning Loss: tensor(0.0277)\n",
            "9012 Traning Loss: tensor(0.0277)\n",
            "9013 Traning Loss: tensor(0.0277)\n",
            "9014 Traning Loss: tensor(0.0277)\n",
            "9015 Traning Loss: tensor(0.0277)\n",
            "9016 Traning Loss: tensor(0.0277)\n",
            "9017 Traning Loss: tensor(0.0277)\n",
            "9018 Traning Loss: tensor(0.0277)\n",
            "9019 Traning Loss: tensor(0.0277)\n",
            "9020 Traning Loss: tensor(0.0277)\n",
            "9021 Traning Loss: tensor(0.0277)\n",
            "9022 Traning Loss: tensor(0.0277)\n",
            "9023 Traning Loss: tensor(0.0277)\n",
            "9024 Traning Loss: tensor(0.0277)\n",
            "9025 Traning Loss: tensor(0.0277)\n",
            "9026 Traning Loss: tensor(0.0277)\n",
            "9027 Traning Loss: tensor(0.0277)\n",
            "9028 Traning Loss: tensor(0.0277)\n",
            "9029 Traning Loss: tensor(0.0277)\n",
            "9030 Traning Loss: tensor(0.0277)\n",
            "9031 Traning Loss: tensor(0.0277)\n",
            "9032 Traning Loss: tensor(0.0277)\n",
            "9033 Traning Loss: tensor(0.0277)\n",
            "9034 Traning Loss: tensor(0.0277)\n",
            "9035 Traning Loss: tensor(0.0277)\n",
            "9036 Traning Loss: tensor(0.0277)\n",
            "9037 Traning Loss: tensor(0.0277)\n",
            "9038 Traning Loss: tensor(0.0277)\n",
            "9039 Traning Loss: tensor(0.0277)\n",
            "9040 Traning Loss: tensor(0.0277)\n",
            "9041 Traning Loss: tensor(0.0277)\n",
            "9042 Traning Loss: tensor(0.0277)\n",
            "9043 Traning Loss: tensor(0.0277)\n",
            "9044 Traning Loss: tensor(0.0277)\n",
            "9045 Traning Loss: tensor(0.0277)\n",
            "9046 Traning Loss: tensor(0.0277)\n",
            "9047 Traning Loss: tensor(0.0277)\n",
            "9048 Traning Loss: tensor(0.0277)\n",
            "9049 Traning Loss: tensor(0.0277)\n",
            "9050 Traning Loss: tensor(0.0277)\n",
            "9051 Traning Loss: tensor(0.0277)\n",
            "9052 Traning Loss: tensor(0.0277)\n",
            "9053 Traning Loss: tensor(0.0277)\n",
            "9054 Traning Loss: tensor(0.0277)\n",
            "9055 Traning Loss: tensor(0.0277)\n",
            "9056 Traning Loss: tensor(0.0277)\n",
            "9057 Traning Loss: tensor(0.0277)\n",
            "9058 Traning Loss: tensor(0.0277)\n",
            "9059 Traning Loss: tensor(0.0277)\n",
            "9060 Traning Loss: tensor(0.0277)\n",
            "9061 Traning Loss: tensor(0.0277)\n",
            "9062 Traning Loss: tensor(0.0277)\n",
            "9063 Traning Loss: tensor(0.0277)\n",
            "9064 Traning Loss: tensor(0.0277)\n",
            "9065 Traning Loss: tensor(0.0277)\n",
            "9066 Traning Loss: tensor(0.0277)\n",
            "9067 Traning Loss: tensor(0.0277)\n",
            "9068 Traning Loss: tensor(0.0277)\n",
            "9069 Traning Loss: tensor(0.0277)\n",
            "9070 Traning Loss: tensor(0.0277)\n",
            "9071 Traning Loss: tensor(0.0277)\n",
            "9072 Traning Loss: tensor(0.0277)\n",
            "9073 Traning Loss: tensor(0.0276)\n",
            "9074 Traning Loss: tensor(0.0276)\n",
            "9075 Traning Loss: tensor(0.0276)\n",
            "9076 Traning Loss: tensor(0.0276)\n",
            "9077 Traning Loss: tensor(0.0276)\n",
            "9078 Traning Loss: tensor(0.0276)\n",
            "9079 Traning Loss: tensor(0.0276)\n",
            "9080 Traning Loss: tensor(0.0276)\n",
            "9081 Traning Loss: tensor(0.0276)\n",
            "9082 Traning Loss: tensor(0.0276)\n",
            "9083 Traning Loss: tensor(0.0276)\n",
            "9084 Traning Loss: tensor(0.0276)\n",
            "9085 Traning Loss: tensor(0.0276)\n",
            "9086 Traning Loss: tensor(0.0276)\n",
            "9087 Traning Loss: tensor(0.0276)\n",
            "9088 Traning Loss: tensor(0.0276)\n",
            "9089 Traning Loss: tensor(0.0276)\n",
            "9090 Traning Loss: tensor(0.0276)\n",
            "9091 Traning Loss: tensor(0.0276)\n",
            "9092 Traning Loss: tensor(0.0276)\n",
            "9093 Traning Loss: tensor(0.0276)\n",
            "9094 Traning Loss: tensor(0.0276)\n",
            "9095 Traning Loss: tensor(0.0276)\n",
            "9096 Traning Loss: tensor(0.0276)\n",
            "9097 Traning Loss: tensor(0.0276)\n",
            "9098 Traning Loss: tensor(0.0276)\n",
            "9099 Traning Loss: tensor(0.0276)\n",
            "9100 Traning Loss: tensor(0.0276)\n",
            "9101 Traning Loss: tensor(0.0276)\n",
            "9102 Traning Loss: tensor(0.0276)\n",
            "9103 Traning Loss: tensor(0.0276)\n",
            "9104 Traning Loss: tensor(0.0276)\n",
            "9105 Traning Loss: tensor(0.0276)\n",
            "9106 Traning Loss: tensor(0.0276)\n",
            "9107 Traning Loss: tensor(0.0276)\n",
            "9108 Traning Loss: tensor(0.0276)\n",
            "9109 Traning Loss: tensor(0.0276)\n",
            "9110 Traning Loss: tensor(0.0276)\n",
            "9111 Traning Loss: tensor(0.0276)\n",
            "9112 Traning Loss: tensor(0.0276)\n",
            "9113 Traning Loss: tensor(0.0276)\n",
            "9114 Traning Loss: tensor(0.0276)\n",
            "9115 Traning Loss: tensor(0.0276)\n",
            "9116 Traning Loss: tensor(0.0276)\n",
            "9117 Traning Loss: tensor(0.0276)\n",
            "9118 Traning Loss: tensor(0.0276)\n",
            "9119 Traning Loss: tensor(0.0276)\n",
            "9120 Traning Loss: tensor(0.0276)\n",
            "9121 Traning Loss: tensor(0.0276)\n",
            "9122 Traning Loss: tensor(0.0276)\n",
            "9123 Traning Loss: tensor(0.0276)\n",
            "9124 Traning Loss: tensor(0.0276)\n",
            "9125 Traning Loss: tensor(0.0276)\n",
            "9126 Traning Loss: tensor(0.0276)\n",
            "9127 Traning Loss: tensor(0.0276)\n",
            "9128 Traning Loss: tensor(0.0276)\n",
            "9129 Traning Loss: tensor(0.0276)\n",
            "9130 Traning Loss: tensor(0.0276)\n",
            "9131 Traning Loss: tensor(0.0276)\n",
            "9132 Traning Loss: tensor(0.0276)\n",
            "9133 Traning Loss: tensor(0.0276)\n",
            "9134 Traning Loss: tensor(0.0276)\n",
            "9135 Traning Loss: tensor(0.0276)\n",
            "9136 Traning Loss: tensor(0.0276)\n",
            "9137 Traning Loss: tensor(0.0276)\n",
            "9138 Traning Loss: tensor(0.0276)\n",
            "9139 Traning Loss: tensor(0.0276)\n",
            "9140 Traning Loss: tensor(0.0276)\n",
            "9141 Traning Loss: tensor(0.0276)\n",
            "9142 Traning Loss: tensor(0.0276)\n",
            "9143 Traning Loss: tensor(0.0276)\n",
            "9144 Traning Loss: tensor(0.0276)\n",
            "9145 Traning Loss: tensor(0.0276)\n",
            "9146 Traning Loss: tensor(0.0276)\n",
            "9147 Traning Loss: tensor(0.0276)\n",
            "9148 Traning Loss: tensor(0.0276)\n",
            "9149 Traning Loss: tensor(0.0276)\n",
            "9150 Traning Loss: tensor(0.0276)\n",
            "9151 Traning Loss: tensor(0.0276)\n",
            "9152 Traning Loss: tensor(0.0276)\n",
            "9153 Traning Loss: tensor(0.0275)\n",
            "9154 Traning Loss: tensor(0.0275)\n",
            "9155 Traning Loss: tensor(0.0275)\n",
            "9156 Traning Loss: tensor(0.0275)\n",
            "9157 Traning Loss: tensor(0.0275)\n",
            "9158 Traning Loss: tensor(0.0275)\n",
            "9159 Traning Loss: tensor(0.0275)\n",
            "9160 Traning Loss: tensor(0.0275)\n",
            "9161 Traning Loss: tensor(0.0275)\n",
            "9162 Traning Loss: tensor(0.0275)\n",
            "9163 Traning Loss: tensor(0.0275)\n",
            "9164 Traning Loss: tensor(0.0275)\n",
            "9165 Traning Loss: tensor(0.0275)\n",
            "9166 Traning Loss: tensor(0.0275)\n",
            "9167 Traning Loss: tensor(0.0275)\n",
            "9168 Traning Loss: tensor(0.0275)\n",
            "9169 Traning Loss: tensor(0.0275)\n",
            "9170 Traning Loss: tensor(0.0275)\n",
            "9171 Traning Loss: tensor(0.0275)\n",
            "9172 Traning Loss: tensor(0.0275)\n",
            "9173 Traning Loss: tensor(0.0275)\n",
            "9174 Traning Loss: tensor(0.0275)\n",
            "9175 Traning Loss: tensor(0.0275)\n",
            "9176 Traning Loss: tensor(0.0275)\n",
            "9177 Traning Loss: tensor(0.0275)\n",
            "9178 Traning Loss: tensor(0.0275)\n",
            "9179 Traning Loss: tensor(0.0275)\n",
            "9180 Traning Loss: tensor(0.0275)\n",
            "9181 Traning Loss: tensor(0.0275)\n",
            "9182 Traning Loss: tensor(0.0275)\n",
            "9183 Traning Loss: tensor(0.0275)\n",
            "9184 Traning Loss: tensor(0.0275)\n",
            "9185 Traning Loss: tensor(0.0275)\n",
            "9186 Traning Loss: tensor(0.0275)\n",
            "9187 Traning Loss: tensor(0.0275)\n",
            "9188 Traning Loss: tensor(0.0275)\n",
            "9189 Traning Loss: tensor(0.0275)\n",
            "9190 Traning Loss: tensor(0.0275)\n",
            "9191 Traning Loss: tensor(0.0275)\n",
            "9192 Traning Loss: tensor(0.0275)\n",
            "9193 Traning Loss: tensor(0.0275)\n",
            "9194 Traning Loss: tensor(0.0275)\n",
            "9195 Traning Loss: tensor(0.0275)\n",
            "9196 Traning Loss: tensor(0.0275)\n",
            "9197 Traning Loss: tensor(0.0275)\n",
            "9198 Traning Loss: tensor(0.0275)\n",
            "9199 Traning Loss: tensor(0.0275)\n",
            "9200 Traning Loss: tensor(0.0275)\n",
            "9201 Traning Loss: tensor(0.0275)\n",
            "9202 Traning Loss: tensor(0.0275)\n",
            "9203 Traning Loss: tensor(0.0275)\n",
            "9204 Traning Loss: tensor(0.0275)\n",
            "9205 Traning Loss: tensor(0.0275)\n",
            "9206 Traning Loss: tensor(0.0275)\n",
            "9207 Traning Loss: tensor(0.0275)\n",
            "9208 Traning Loss: tensor(0.0275)\n",
            "9209 Traning Loss: tensor(0.0275)\n",
            "9210 Traning Loss: tensor(0.0275)\n",
            "9211 Traning Loss: tensor(0.0275)\n",
            "9212 Traning Loss: tensor(0.0275)\n",
            "9213 Traning Loss: tensor(0.0275)\n",
            "9214 Traning Loss: tensor(0.0275)\n",
            "9215 Traning Loss: tensor(0.0275)\n",
            "9216 Traning Loss: tensor(0.0275)\n",
            "9217 Traning Loss: tensor(0.0275)\n",
            "9218 Traning Loss: tensor(0.0275)\n",
            "9219 Traning Loss: tensor(0.0275)\n",
            "9220 Traning Loss: tensor(0.0275)\n",
            "9221 Traning Loss: tensor(0.0275)\n",
            "9222 Traning Loss: tensor(0.0275)\n",
            "9223 Traning Loss: tensor(0.0275)\n",
            "9224 Traning Loss: tensor(0.0275)\n",
            "9225 Traning Loss: tensor(0.0275)\n",
            "9226 Traning Loss: tensor(0.0275)\n",
            "9227 Traning Loss: tensor(0.0275)\n",
            "9228 Traning Loss: tensor(0.0275)\n",
            "9229 Traning Loss: tensor(0.0275)\n",
            "9230 Traning Loss: tensor(0.0275)\n",
            "9231 Traning Loss: tensor(0.0275)\n",
            "9232 Traning Loss: tensor(0.0275)\n",
            "9233 Traning Loss: tensor(0.0275)\n",
            "9234 Traning Loss: tensor(0.0275)\n",
            "9235 Traning Loss: tensor(0.0274)\n",
            "9236 Traning Loss: tensor(0.0274)\n",
            "9237 Traning Loss: tensor(0.0274)\n",
            "9238 Traning Loss: tensor(0.0274)\n",
            "9239 Traning Loss: tensor(0.0274)\n",
            "9240 Traning Loss: tensor(0.0274)\n",
            "9241 Traning Loss: tensor(0.0274)\n",
            "9242 Traning Loss: tensor(0.0274)\n",
            "9243 Traning Loss: tensor(0.0274)\n",
            "9244 Traning Loss: tensor(0.0274)\n",
            "9245 Traning Loss: tensor(0.0274)\n",
            "9246 Traning Loss: tensor(0.0274)\n",
            "9247 Traning Loss: tensor(0.0274)\n",
            "9248 Traning Loss: tensor(0.0274)\n",
            "9249 Traning Loss: tensor(0.0274)\n",
            "9250 Traning Loss: tensor(0.0274)\n",
            "9251 Traning Loss: tensor(0.0274)\n",
            "9252 Traning Loss: tensor(0.0274)\n",
            "9253 Traning Loss: tensor(0.0274)\n",
            "9254 Traning Loss: tensor(0.0274)\n",
            "9255 Traning Loss: tensor(0.0274)\n",
            "9256 Traning Loss: tensor(0.0274)\n",
            "9257 Traning Loss: tensor(0.0274)\n",
            "9258 Traning Loss: tensor(0.0274)\n",
            "9259 Traning Loss: tensor(0.0274)\n",
            "9260 Traning Loss: tensor(0.0274)\n",
            "9261 Traning Loss: tensor(0.0274)\n",
            "9262 Traning Loss: tensor(0.0274)\n",
            "9263 Traning Loss: tensor(0.0274)\n",
            "9264 Traning Loss: tensor(0.0274)\n",
            "9265 Traning Loss: tensor(0.0274)\n",
            "9266 Traning Loss: tensor(0.0274)\n",
            "9267 Traning Loss: tensor(0.0274)\n",
            "9268 Traning Loss: tensor(0.0274)\n",
            "9269 Traning Loss: tensor(0.0274)\n",
            "9270 Traning Loss: tensor(0.0274)\n",
            "9271 Traning Loss: tensor(0.0274)\n",
            "9272 Traning Loss: tensor(0.0274)\n",
            "9273 Traning Loss: tensor(0.0274)\n",
            "9274 Traning Loss: tensor(0.0274)\n",
            "9275 Traning Loss: tensor(0.0274)\n",
            "9276 Traning Loss: tensor(0.0274)\n",
            "9277 Traning Loss: tensor(0.0274)\n",
            "9278 Traning Loss: tensor(0.0274)\n",
            "9279 Traning Loss: tensor(0.0274)\n",
            "9280 Traning Loss: tensor(0.0274)\n",
            "9281 Traning Loss: tensor(0.0274)\n",
            "9282 Traning Loss: tensor(0.0274)\n",
            "9283 Traning Loss: tensor(0.0274)\n",
            "9284 Traning Loss: tensor(0.0274)\n",
            "9285 Traning Loss: tensor(0.0274)\n",
            "9286 Traning Loss: tensor(0.0274)\n",
            "9287 Traning Loss: tensor(0.0274)\n",
            "9288 Traning Loss: tensor(0.0274)\n",
            "9289 Traning Loss: tensor(0.0274)\n",
            "9290 Traning Loss: tensor(0.0274)\n",
            "9291 Traning Loss: tensor(0.0274)\n",
            "9292 Traning Loss: tensor(0.0274)\n",
            "9293 Traning Loss: tensor(0.0274)\n",
            "9294 Traning Loss: tensor(0.0274)\n",
            "9295 Traning Loss: tensor(0.0274)\n",
            "9296 Traning Loss: tensor(0.0274)\n",
            "9297 Traning Loss: tensor(0.0274)\n",
            "9298 Traning Loss: tensor(0.0274)\n",
            "9299 Traning Loss: tensor(0.0274)\n",
            "9300 Traning Loss: tensor(0.0274)\n",
            "9301 Traning Loss: tensor(0.0274)\n",
            "9302 Traning Loss: tensor(0.0274)\n",
            "9303 Traning Loss: tensor(0.0274)\n",
            "9304 Traning Loss: tensor(0.0274)\n",
            "9305 Traning Loss: tensor(0.0274)\n",
            "9306 Traning Loss: tensor(0.0274)\n",
            "9307 Traning Loss: tensor(0.0274)\n",
            "9308 Traning Loss: tensor(0.0274)\n",
            "9309 Traning Loss: tensor(0.0274)\n",
            "9310 Traning Loss: tensor(0.0274)\n",
            "9311 Traning Loss: tensor(0.0274)\n",
            "9312 Traning Loss: tensor(0.0274)\n",
            "9313 Traning Loss: tensor(0.0274)\n",
            "9314 Traning Loss: tensor(0.0274)\n",
            "9315 Traning Loss: tensor(0.0274)\n",
            "9316 Traning Loss: tensor(0.0274)\n",
            "9317 Traning Loss: tensor(0.0274)\n",
            "9318 Traning Loss: tensor(0.0273)\n",
            "9319 Traning Loss: tensor(0.0273)\n",
            "9320 Traning Loss: tensor(0.0273)\n",
            "9321 Traning Loss: tensor(0.0273)\n",
            "9322 Traning Loss: tensor(0.0273)\n",
            "9323 Traning Loss: tensor(0.0273)\n",
            "9324 Traning Loss: tensor(0.0273)\n",
            "9325 Traning Loss: tensor(0.0273)\n",
            "9326 Traning Loss: tensor(0.0273)\n",
            "9327 Traning Loss: tensor(0.0273)\n",
            "9328 Traning Loss: tensor(0.0273)\n",
            "9329 Traning Loss: tensor(0.0273)\n",
            "9330 Traning Loss: tensor(0.0273)\n",
            "9331 Traning Loss: tensor(0.0273)\n",
            "9332 Traning Loss: tensor(0.0273)\n",
            "9333 Traning Loss: tensor(0.0273)\n",
            "9334 Traning Loss: tensor(0.0273)\n",
            "9335 Traning Loss: tensor(0.0273)\n",
            "9336 Traning Loss: tensor(0.0273)\n",
            "9337 Traning Loss: tensor(0.0273)\n",
            "9338 Traning Loss: tensor(0.0273)\n",
            "9339 Traning Loss: tensor(0.0273)\n",
            "9340 Traning Loss: tensor(0.0273)\n",
            "9341 Traning Loss: tensor(0.0273)\n",
            "9342 Traning Loss: tensor(0.0273)\n",
            "9343 Traning Loss: tensor(0.0273)\n",
            "9344 Traning Loss: tensor(0.0273)\n",
            "9345 Traning Loss: tensor(0.0273)\n",
            "9346 Traning Loss: tensor(0.0273)\n",
            "9347 Traning Loss: tensor(0.0273)\n",
            "9348 Traning Loss: tensor(0.0273)\n",
            "9349 Traning Loss: tensor(0.0273)\n",
            "9350 Traning Loss: tensor(0.0273)\n",
            "9351 Traning Loss: tensor(0.0273)\n",
            "9352 Traning Loss: tensor(0.0273)\n",
            "9353 Traning Loss: tensor(0.0273)\n",
            "9354 Traning Loss: tensor(0.0273)\n",
            "9355 Traning Loss: tensor(0.0273)\n",
            "9356 Traning Loss: tensor(0.0273)\n",
            "9357 Traning Loss: tensor(0.0273)\n",
            "9358 Traning Loss: tensor(0.0273)\n",
            "9359 Traning Loss: tensor(0.0273)\n",
            "9360 Traning Loss: tensor(0.0273)\n",
            "9361 Traning Loss: tensor(0.0273)\n",
            "9362 Traning Loss: tensor(0.0273)\n",
            "9363 Traning Loss: tensor(0.0273)\n",
            "9364 Traning Loss: tensor(0.0273)\n",
            "9365 Traning Loss: tensor(0.0273)\n",
            "9366 Traning Loss: tensor(0.0273)\n",
            "9367 Traning Loss: tensor(0.0273)\n",
            "9368 Traning Loss: tensor(0.0273)\n",
            "9369 Traning Loss: tensor(0.0273)\n",
            "9370 Traning Loss: tensor(0.0273)\n",
            "9371 Traning Loss: tensor(0.0273)\n",
            "9372 Traning Loss: tensor(0.0273)\n",
            "9373 Traning Loss: tensor(0.0273)\n",
            "9374 Traning Loss: tensor(0.0273)\n",
            "9375 Traning Loss: tensor(0.0273)\n",
            "9376 Traning Loss: tensor(0.0273)\n",
            "9377 Traning Loss: tensor(0.0273)\n",
            "9378 Traning Loss: tensor(0.0273)\n",
            "9379 Traning Loss: tensor(0.0273)\n",
            "9380 Traning Loss: tensor(0.0273)\n",
            "9381 Traning Loss: tensor(0.0273)\n",
            "9382 Traning Loss: tensor(0.0273)\n",
            "9383 Traning Loss: tensor(0.0273)\n",
            "9384 Traning Loss: tensor(0.0273)\n",
            "9385 Traning Loss: tensor(0.0273)\n",
            "9386 Traning Loss: tensor(0.0273)\n",
            "9387 Traning Loss: tensor(0.0273)\n",
            "9388 Traning Loss: tensor(0.0273)\n",
            "9389 Traning Loss: tensor(0.0273)\n",
            "9390 Traning Loss: tensor(0.0273)\n",
            "9391 Traning Loss: tensor(0.0273)\n",
            "9392 Traning Loss: tensor(0.0273)\n",
            "9393 Traning Loss: tensor(0.0273)\n",
            "9394 Traning Loss: tensor(0.0273)\n",
            "9395 Traning Loss: tensor(0.0273)\n",
            "9396 Traning Loss: tensor(0.0273)\n",
            "9397 Traning Loss: tensor(0.0273)\n",
            "9398 Traning Loss: tensor(0.0273)\n",
            "9399 Traning Loss: tensor(0.0273)\n",
            "9400 Traning Loss: tensor(0.0273)\n",
            "9401 Traning Loss: tensor(0.0272)\n",
            "9402 Traning Loss: tensor(0.0272)\n",
            "9403 Traning Loss: tensor(0.0272)\n",
            "9404 Traning Loss: tensor(0.0272)\n",
            "9405 Traning Loss: tensor(0.0272)\n",
            "9406 Traning Loss: tensor(0.0272)\n",
            "9407 Traning Loss: tensor(0.0272)\n",
            "9408 Traning Loss: tensor(0.0272)\n",
            "9409 Traning Loss: tensor(0.0272)\n",
            "9410 Traning Loss: tensor(0.0272)\n",
            "9411 Traning Loss: tensor(0.0272)\n",
            "9412 Traning Loss: tensor(0.0272)\n",
            "9413 Traning Loss: tensor(0.0272)\n",
            "9414 Traning Loss: tensor(0.0272)\n",
            "9415 Traning Loss: tensor(0.0272)\n",
            "9416 Traning Loss: tensor(0.0272)\n",
            "9417 Traning Loss: tensor(0.0272)\n",
            "9418 Traning Loss: tensor(0.0272)\n",
            "9419 Traning Loss: tensor(0.0272)\n",
            "9420 Traning Loss: tensor(0.0272)\n",
            "9421 Traning Loss: tensor(0.0272)\n",
            "9422 Traning Loss: tensor(0.0272)\n",
            "9423 Traning Loss: tensor(0.0272)\n",
            "9424 Traning Loss: tensor(0.0272)\n",
            "9425 Traning Loss: tensor(0.0272)\n",
            "9426 Traning Loss: tensor(0.0272)\n",
            "9427 Traning Loss: tensor(0.0272)\n",
            "9428 Traning Loss: tensor(0.0272)\n",
            "9429 Traning Loss: tensor(0.0272)\n",
            "9430 Traning Loss: tensor(0.0272)\n",
            "9431 Traning Loss: tensor(0.0272)\n",
            "9432 Traning Loss: tensor(0.0272)\n",
            "9433 Traning Loss: tensor(0.0272)\n",
            "9434 Traning Loss: tensor(0.0272)\n",
            "9435 Traning Loss: tensor(0.0272)\n",
            "9436 Traning Loss: tensor(0.0272)\n",
            "9437 Traning Loss: tensor(0.0272)\n",
            "9438 Traning Loss: tensor(0.0272)\n",
            "9439 Traning Loss: tensor(0.0272)\n",
            "9440 Traning Loss: tensor(0.0272)\n",
            "9441 Traning Loss: tensor(0.0272)\n",
            "9442 Traning Loss: tensor(0.0272)\n",
            "9443 Traning Loss: tensor(0.0272)\n",
            "9444 Traning Loss: tensor(0.0272)\n",
            "9445 Traning Loss: tensor(0.0272)\n",
            "9446 Traning Loss: tensor(0.0272)\n",
            "9447 Traning Loss: tensor(0.0272)\n",
            "9448 Traning Loss: tensor(0.0272)\n",
            "9449 Traning Loss: tensor(0.0272)\n",
            "9450 Traning Loss: tensor(0.0272)\n",
            "9451 Traning Loss: tensor(0.0272)\n",
            "9452 Traning Loss: tensor(0.0272)\n",
            "9453 Traning Loss: tensor(0.0272)\n",
            "9454 Traning Loss: tensor(0.0272)\n",
            "9455 Traning Loss: tensor(0.0272)\n",
            "9456 Traning Loss: tensor(0.0272)\n",
            "9457 Traning Loss: tensor(0.0272)\n",
            "9458 Traning Loss: tensor(0.0272)\n",
            "9459 Traning Loss: tensor(0.0272)\n",
            "9460 Traning Loss: tensor(0.0272)\n",
            "9461 Traning Loss: tensor(0.0272)\n",
            "9462 Traning Loss: tensor(0.0272)\n",
            "9463 Traning Loss: tensor(0.0272)\n",
            "9464 Traning Loss: tensor(0.0272)\n",
            "9465 Traning Loss: tensor(0.0272)\n",
            "9466 Traning Loss: tensor(0.0272)\n",
            "9467 Traning Loss: tensor(0.0272)\n",
            "9468 Traning Loss: tensor(0.0272)\n",
            "9469 Traning Loss: tensor(0.0272)\n",
            "9470 Traning Loss: tensor(0.0272)\n",
            "9471 Traning Loss: tensor(0.0272)\n",
            "9472 Traning Loss: tensor(0.0272)\n",
            "9473 Traning Loss: tensor(0.0272)\n",
            "9474 Traning Loss: tensor(0.0272)\n",
            "9475 Traning Loss: tensor(0.0272)\n",
            "9476 Traning Loss: tensor(0.0272)\n",
            "9477 Traning Loss: tensor(0.0272)\n",
            "9478 Traning Loss: tensor(0.0272)\n",
            "9479 Traning Loss: tensor(0.0272)\n",
            "9480 Traning Loss: tensor(0.0272)\n",
            "9481 Traning Loss: tensor(0.0272)\n",
            "9482 Traning Loss: tensor(0.0272)\n",
            "9483 Traning Loss: tensor(0.0272)\n",
            "9484 Traning Loss: tensor(0.0272)\n",
            "9485 Traning Loss: tensor(0.0272)\n",
            "9486 Traning Loss: tensor(0.0271)\n",
            "9487 Traning Loss: tensor(0.0271)\n",
            "9488 Traning Loss: tensor(0.0271)\n",
            "9489 Traning Loss: tensor(0.0271)\n",
            "9490 Traning Loss: tensor(0.0271)\n",
            "9491 Traning Loss: tensor(0.0271)\n",
            "9492 Traning Loss: tensor(0.0271)\n",
            "9493 Traning Loss: tensor(0.0271)\n",
            "9494 Traning Loss: tensor(0.0271)\n",
            "9495 Traning Loss: tensor(0.0271)\n",
            "9496 Traning Loss: tensor(0.0271)\n",
            "9497 Traning Loss: tensor(0.0271)\n",
            "9498 Traning Loss: tensor(0.0271)\n",
            "9499 Traning Loss: tensor(0.0271)\n",
            "9500 Traning Loss: tensor(0.0271)\n",
            "9501 Traning Loss: tensor(0.0271)\n",
            "9502 Traning Loss: tensor(0.0271)\n",
            "9503 Traning Loss: tensor(0.0271)\n",
            "9504 Traning Loss: tensor(0.0271)\n",
            "9505 Traning Loss: tensor(0.0271)\n",
            "9506 Traning Loss: tensor(0.0271)\n",
            "9507 Traning Loss: tensor(0.0271)\n",
            "9508 Traning Loss: tensor(0.0271)\n",
            "9509 Traning Loss: tensor(0.0271)\n",
            "9510 Traning Loss: tensor(0.0271)\n",
            "9511 Traning Loss: tensor(0.0271)\n",
            "9512 Traning Loss: tensor(0.0271)\n",
            "9513 Traning Loss: tensor(0.0271)\n",
            "9514 Traning Loss: tensor(0.0271)\n",
            "9515 Traning Loss: tensor(0.0271)\n",
            "9516 Traning Loss: tensor(0.0271)\n",
            "9517 Traning Loss: tensor(0.0271)\n",
            "9518 Traning Loss: tensor(0.0271)\n",
            "9519 Traning Loss: tensor(0.0271)\n",
            "9520 Traning Loss: tensor(0.0271)\n",
            "9521 Traning Loss: tensor(0.0271)\n",
            "9522 Traning Loss: tensor(0.0271)\n",
            "9523 Traning Loss: tensor(0.0271)\n",
            "9524 Traning Loss: tensor(0.0271)\n",
            "9525 Traning Loss: tensor(0.0271)\n",
            "9526 Traning Loss: tensor(0.0271)\n",
            "9527 Traning Loss: tensor(0.0271)\n",
            "9528 Traning Loss: tensor(0.0271)\n",
            "9529 Traning Loss: tensor(0.0271)\n",
            "9530 Traning Loss: tensor(0.0271)\n",
            "9531 Traning Loss: tensor(0.0271)\n",
            "9532 Traning Loss: tensor(0.0271)\n",
            "9533 Traning Loss: tensor(0.0271)\n",
            "9534 Traning Loss: tensor(0.0271)\n",
            "9535 Traning Loss: tensor(0.0271)\n",
            "9536 Traning Loss: tensor(0.0271)\n",
            "9537 Traning Loss: tensor(0.0271)\n",
            "9538 Traning Loss: tensor(0.0271)\n",
            "9539 Traning Loss: tensor(0.0271)\n",
            "9540 Traning Loss: tensor(0.0271)\n",
            "9541 Traning Loss: tensor(0.0271)\n",
            "9542 Traning Loss: tensor(0.0271)\n",
            "9543 Traning Loss: tensor(0.0271)\n",
            "9544 Traning Loss: tensor(0.0271)\n",
            "9545 Traning Loss: tensor(0.0271)\n",
            "9546 Traning Loss: tensor(0.0271)\n",
            "9547 Traning Loss: tensor(0.0271)\n",
            "9548 Traning Loss: tensor(0.0271)\n",
            "9549 Traning Loss: tensor(0.0271)\n",
            "9550 Traning Loss: tensor(0.0271)\n",
            "9551 Traning Loss: tensor(0.0271)\n",
            "9552 Traning Loss: tensor(0.0271)\n",
            "9553 Traning Loss: tensor(0.0271)\n",
            "9554 Traning Loss: tensor(0.0271)\n",
            "9555 Traning Loss: tensor(0.0271)\n",
            "9556 Traning Loss: tensor(0.0271)\n",
            "9557 Traning Loss: tensor(0.0271)\n",
            "9558 Traning Loss: tensor(0.0271)\n",
            "9559 Traning Loss: tensor(0.0271)\n",
            "9560 Traning Loss: tensor(0.0271)\n",
            "9561 Traning Loss: tensor(0.0271)\n",
            "9562 Traning Loss: tensor(0.0271)\n",
            "9563 Traning Loss: tensor(0.0271)\n",
            "9564 Traning Loss: tensor(0.0271)\n",
            "9565 Traning Loss: tensor(0.0271)\n",
            "9566 Traning Loss: tensor(0.0271)\n",
            "9567 Traning Loss: tensor(0.0271)\n",
            "9568 Traning Loss: tensor(0.0271)\n",
            "9569 Traning Loss: tensor(0.0271)\n",
            "9570 Traning Loss: tensor(0.0271)\n",
            "9571 Traning Loss: tensor(0.0271)\n",
            "9572 Traning Loss: tensor(0.0271)\n",
            "9573 Traning Loss: tensor(0.0270)\n",
            "9574 Traning Loss: tensor(0.0270)\n",
            "9575 Traning Loss: tensor(0.0270)\n",
            "9576 Traning Loss: tensor(0.0270)\n",
            "9577 Traning Loss: tensor(0.0270)\n",
            "9578 Traning Loss: tensor(0.0270)\n",
            "9579 Traning Loss: tensor(0.0270)\n",
            "9580 Traning Loss: tensor(0.0270)\n",
            "9581 Traning Loss: tensor(0.0270)\n",
            "9582 Traning Loss: tensor(0.0270)\n",
            "9583 Traning Loss: tensor(0.0270)\n",
            "9584 Traning Loss: tensor(0.0270)\n",
            "9585 Traning Loss: tensor(0.0270)\n",
            "9586 Traning Loss: tensor(0.0270)\n",
            "9587 Traning Loss: tensor(0.0270)\n",
            "9588 Traning Loss: tensor(0.0270)\n",
            "9589 Traning Loss: tensor(0.0270)\n",
            "9590 Traning Loss: tensor(0.0270)\n",
            "9591 Traning Loss: tensor(0.0270)\n",
            "9592 Traning Loss: tensor(0.0270)\n",
            "9593 Traning Loss: tensor(0.0270)\n",
            "9594 Traning Loss: tensor(0.0270)\n",
            "9595 Traning Loss: tensor(0.0270)\n",
            "9596 Traning Loss: tensor(0.0270)\n",
            "9597 Traning Loss: tensor(0.0270)\n",
            "9598 Traning Loss: tensor(0.0270)\n",
            "9599 Traning Loss: tensor(0.0270)\n",
            "9600 Traning Loss: tensor(0.0270)\n",
            "9601 Traning Loss: tensor(0.0270)\n",
            "9602 Traning Loss: tensor(0.0270)\n",
            "9603 Traning Loss: tensor(0.0270)\n",
            "9604 Traning Loss: tensor(0.0270)\n",
            "9605 Traning Loss: tensor(0.0270)\n",
            "9606 Traning Loss: tensor(0.0270)\n",
            "9607 Traning Loss: tensor(0.0270)\n",
            "9608 Traning Loss: tensor(0.0270)\n",
            "9609 Traning Loss: tensor(0.0270)\n",
            "9610 Traning Loss: tensor(0.0270)\n",
            "9611 Traning Loss: tensor(0.0270)\n",
            "9612 Traning Loss: tensor(0.0270)\n",
            "9613 Traning Loss: tensor(0.0270)\n",
            "9614 Traning Loss: tensor(0.0270)\n",
            "9615 Traning Loss: tensor(0.0270)\n",
            "9616 Traning Loss: tensor(0.0270)\n",
            "9617 Traning Loss: tensor(0.0270)\n",
            "9618 Traning Loss: tensor(0.0270)\n",
            "9619 Traning Loss: tensor(0.0270)\n",
            "9620 Traning Loss: tensor(0.0270)\n",
            "9621 Traning Loss: tensor(0.0270)\n",
            "9622 Traning Loss: tensor(0.0270)\n",
            "9623 Traning Loss: tensor(0.0270)\n",
            "9624 Traning Loss: tensor(0.0270)\n",
            "9625 Traning Loss: tensor(0.0270)\n",
            "9626 Traning Loss: tensor(0.0270)\n",
            "9627 Traning Loss: tensor(0.0270)\n",
            "9628 Traning Loss: tensor(0.0270)\n",
            "9629 Traning Loss: tensor(0.0270)\n",
            "9630 Traning Loss: tensor(0.0270)\n",
            "9631 Traning Loss: tensor(0.0270)\n",
            "9632 Traning Loss: tensor(0.0270)\n",
            "9633 Traning Loss: tensor(0.0270)\n",
            "9634 Traning Loss: tensor(0.0270)\n",
            "9635 Traning Loss: tensor(0.0270)\n",
            "9636 Traning Loss: tensor(0.0270)\n",
            "9637 Traning Loss: tensor(0.0270)\n",
            "9638 Traning Loss: tensor(0.0270)\n",
            "9639 Traning Loss: tensor(0.0270)\n",
            "9640 Traning Loss: tensor(0.0270)\n",
            "9641 Traning Loss: tensor(0.0270)\n",
            "9642 Traning Loss: tensor(0.0270)\n",
            "9643 Traning Loss: tensor(0.0270)\n",
            "9644 Traning Loss: tensor(0.0270)\n",
            "9645 Traning Loss: tensor(0.0270)\n",
            "9646 Traning Loss: tensor(0.0270)\n",
            "9647 Traning Loss: tensor(0.0270)\n",
            "9648 Traning Loss: tensor(0.0270)\n",
            "9649 Traning Loss: tensor(0.0270)\n",
            "9650 Traning Loss: tensor(0.0270)\n",
            "9651 Traning Loss: tensor(0.0270)\n",
            "9652 Traning Loss: tensor(0.0270)\n",
            "9653 Traning Loss: tensor(0.0270)\n",
            "9654 Traning Loss: tensor(0.0270)\n",
            "9655 Traning Loss: tensor(0.0270)\n",
            "9656 Traning Loss: tensor(0.0270)\n",
            "9657 Traning Loss: tensor(0.0270)\n",
            "9658 Traning Loss: tensor(0.0270)\n",
            "9659 Traning Loss: tensor(0.0270)\n",
            "9660 Traning Loss: tensor(0.0269)\n",
            "9661 Traning Loss: tensor(0.0269)\n",
            "9662 Traning Loss: tensor(0.0269)\n",
            "9663 Traning Loss: tensor(0.0269)\n",
            "9664 Traning Loss: tensor(0.0269)\n",
            "9665 Traning Loss: tensor(0.0269)\n",
            "9666 Traning Loss: tensor(0.0269)\n",
            "9667 Traning Loss: tensor(0.0269)\n",
            "9668 Traning Loss: tensor(0.0269)\n",
            "9669 Traning Loss: tensor(0.0269)\n",
            "9670 Traning Loss: tensor(0.0269)\n",
            "9671 Traning Loss: tensor(0.0269)\n",
            "9672 Traning Loss: tensor(0.0269)\n",
            "9673 Traning Loss: tensor(0.0269)\n",
            "9674 Traning Loss: tensor(0.0269)\n",
            "9675 Traning Loss: tensor(0.0269)\n",
            "9676 Traning Loss: tensor(0.0269)\n",
            "9677 Traning Loss: tensor(0.0269)\n",
            "9678 Traning Loss: tensor(0.0269)\n",
            "9679 Traning Loss: tensor(0.0269)\n",
            "9680 Traning Loss: tensor(0.0269)\n",
            "9681 Traning Loss: tensor(0.0269)\n",
            "9682 Traning Loss: tensor(0.0269)\n",
            "9683 Traning Loss: tensor(0.0269)\n",
            "9684 Traning Loss: tensor(0.0269)\n",
            "9685 Traning Loss: tensor(0.0269)\n",
            "9686 Traning Loss: tensor(0.0269)\n",
            "9687 Traning Loss: tensor(0.0269)\n",
            "9688 Traning Loss: tensor(0.0269)\n",
            "9689 Traning Loss: tensor(0.0269)\n",
            "9690 Traning Loss: tensor(0.0269)\n",
            "9691 Traning Loss: tensor(0.0269)\n",
            "9692 Traning Loss: tensor(0.0269)\n",
            "9693 Traning Loss: tensor(0.0269)\n",
            "9694 Traning Loss: tensor(0.0269)\n",
            "9695 Traning Loss: tensor(0.0269)\n",
            "9696 Traning Loss: tensor(0.0269)\n",
            "9697 Traning Loss: tensor(0.0269)\n",
            "9698 Traning Loss: tensor(0.0269)\n",
            "9699 Traning Loss: tensor(0.0269)\n",
            "9700 Traning Loss: tensor(0.0269)\n",
            "9701 Traning Loss: tensor(0.0269)\n",
            "9702 Traning Loss: tensor(0.0269)\n",
            "9703 Traning Loss: tensor(0.0269)\n",
            "9704 Traning Loss: tensor(0.0269)\n",
            "9705 Traning Loss: tensor(0.0269)\n",
            "9706 Traning Loss: tensor(0.0269)\n",
            "9707 Traning Loss: tensor(0.0269)\n",
            "9708 Traning Loss: tensor(0.0269)\n",
            "9709 Traning Loss: tensor(0.0269)\n",
            "9710 Traning Loss: tensor(0.0269)\n",
            "9711 Traning Loss: tensor(0.0269)\n",
            "9712 Traning Loss: tensor(0.0269)\n",
            "9713 Traning Loss: tensor(0.0269)\n",
            "9714 Traning Loss: tensor(0.0269)\n",
            "9715 Traning Loss: tensor(0.0269)\n",
            "9716 Traning Loss: tensor(0.0269)\n",
            "9717 Traning Loss: tensor(0.0269)\n",
            "9718 Traning Loss: tensor(0.0269)\n",
            "9719 Traning Loss: tensor(0.0269)\n",
            "9720 Traning Loss: tensor(0.0269)\n",
            "9721 Traning Loss: tensor(0.0269)\n",
            "9722 Traning Loss: tensor(0.0269)\n",
            "9723 Traning Loss: tensor(0.0269)\n",
            "9724 Traning Loss: tensor(0.0269)\n",
            "9725 Traning Loss: tensor(0.0269)\n",
            "9726 Traning Loss: tensor(0.0269)\n",
            "9727 Traning Loss: tensor(0.0269)\n",
            "9728 Traning Loss: tensor(0.0269)\n",
            "9729 Traning Loss: tensor(0.0269)\n",
            "9730 Traning Loss: tensor(0.0269)\n",
            "9731 Traning Loss: tensor(0.0269)\n",
            "9732 Traning Loss: tensor(0.0269)\n",
            "9733 Traning Loss: tensor(0.0269)\n",
            "9734 Traning Loss: tensor(0.0269)\n",
            "9735 Traning Loss: tensor(0.0269)\n",
            "9736 Traning Loss: tensor(0.0269)\n",
            "9737 Traning Loss: tensor(0.0269)\n",
            "9738 Traning Loss: tensor(0.0269)\n",
            "9739 Traning Loss: tensor(0.0269)\n",
            "9740 Traning Loss: tensor(0.0269)\n",
            "9741 Traning Loss: tensor(0.0269)\n",
            "9742 Traning Loss: tensor(0.0269)\n",
            "9743 Traning Loss: tensor(0.0269)\n",
            "9744 Traning Loss: tensor(0.0269)\n",
            "9745 Traning Loss: tensor(0.0269)\n",
            "9746 Traning Loss: tensor(0.0269)\n",
            "9747 Traning Loss: tensor(0.0269)\n",
            "9748 Traning Loss: tensor(0.0269)\n",
            "9749 Traning Loss: tensor(0.0268)\n",
            "9750 Traning Loss: tensor(0.0268)\n",
            "9751 Traning Loss: tensor(0.0268)\n",
            "9752 Traning Loss: tensor(0.0268)\n",
            "9753 Traning Loss: tensor(0.0268)\n",
            "9754 Traning Loss: tensor(0.0268)\n",
            "9755 Traning Loss: tensor(0.0268)\n",
            "9756 Traning Loss: tensor(0.0268)\n",
            "9757 Traning Loss: tensor(0.0268)\n",
            "9758 Traning Loss: tensor(0.0268)\n",
            "9759 Traning Loss: tensor(0.0268)\n",
            "9760 Traning Loss: tensor(0.0268)\n",
            "9761 Traning Loss: tensor(0.0268)\n",
            "9762 Traning Loss: tensor(0.0268)\n",
            "9763 Traning Loss: tensor(0.0268)\n",
            "9764 Traning Loss: tensor(0.0268)\n",
            "9765 Traning Loss: tensor(0.0268)\n",
            "9766 Traning Loss: tensor(0.0268)\n",
            "9767 Traning Loss: tensor(0.0268)\n",
            "9768 Traning Loss: tensor(0.0268)\n",
            "9769 Traning Loss: tensor(0.0268)\n",
            "9770 Traning Loss: tensor(0.0268)\n",
            "9771 Traning Loss: tensor(0.0268)\n",
            "9772 Traning Loss: tensor(0.0268)\n",
            "9773 Traning Loss: tensor(0.0268)\n",
            "9774 Traning Loss: tensor(0.0268)\n",
            "9775 Traning Loss: tensor(0.0268)\n",
            "9776 Traning Loss: tensor(0.0268)\n",
            "9777 Traning Loss: tensor(0.0268)\n",
            "9778 Traning Loss: tensor(0.0268)\n",
            "9779 Traning Loss: tensor(0.0268)\n",
            "9780 Traning Loss: tensor(0.0268)\n",
            "9781 Traning Loss: tensor(0.0268)\n",
            "9782 Traning Loss: tensor(0.0268)\n",
            "9783 Traning Loss: tensor(0.0268)\n",
            "9784 Traning Loss: tensor(0.0268)\n",
            "9785 Traning Loss: tensor(0.0268)\n",
            "9786 Traning Loss: tensor(0.0268)\n",
            "9787 Traning Loss: tensor(0.0268)\n",
            "9788 Traning Loss: tensor(0.0268)\n",
            "9789 Traning Loss: tensor(0.0268)\n",
            "9790 Traning Loss: tensor(0.0268)\n",
            "9791 Traning Loss: tensor(0.0268)\n",
            "9792 Traning Loss: tensor(0.0268)\n",
            "9793 Traning Loss: tensor(0.0268)\n",
            "9794 Traning Loss: tensor(0.0268)\n",
            "9795 Traning Loss: tensor(0.0268)\n",
            "9796 Traning Loss: tensor(0.0268)\n",
            "9797 Traning Loss: tensor(0.0268)\n",
            "9798 Traning Loss: tensor(0.0268)\n",
            "9799 Traning Loss: tensor(0.0268)\n",
            "9800 Traning Loss: tensor(0.0268)\n",
            "9801 Traning Loss: tensor(0.0268)\n",
            "9802 Traning Loss: tensor(0.0268)\n",
            "9803 Traning Loss: tensor(0.0268)\n",
            "9804 Traning Loss: tensor(0.0268)\n",
            "9805 Traning Loss: tensor(0.0268)\n",
            "9806 Traning Loss: tensor(0.0268)\n",
            "9807 Traning Loss: tensor(0.0268)\n",
            "9808 Traning Loss: tensor(0.0268)\n",
            "9809 Traning Loss: tensor(0.0268)\n",
            "9810 Traning Loss: tensor(0.0268)\n",
            "9811 Traning Loss: tensor(0.0268)\n",
            "9812 Traning Loss: tensor(0.0268)\n",
            "9813 Traning Loss: tensor(0.0268)\n",
            "9814 Traning Loss: tensor(0.0268)\n",
            "9815 Traning Loss: tensor(0.0268)\n",
            "9816 Traning Loss: tensor(0.0268)\n",
            "9817 Traning Loss: tensor(0.0268)\n",
            "9818 Traning Loss: tensor(0.0268)\n",
            "9819 Traning Loss: tensor(0.0268)\n",
            "9820 Traning Loss: tensor(0.0268)\n",
            "9821 Traning Loss: tensor(0.0268)\n",
            "9822 Traning Loss: tensor(0.0268)\n",
            "9823 Traning Loss: tensor(0.0268)\n",
            "9824 Traning Loss: tensor(0.0268)\n",
            "9825 Traning Loss: tensor(0.0268)\n",
            "9826 Traning Loss: tensor(0.0268)\n",
            "9827 Traning Loss: tensor(0.0268)\n",
            "9828 Traning Loss: tensor(0.0268)\n",
            "9829 Traning Loss: tensor(0.0268)\n",
            "9830 Traning Loss: tensor(0.0268)\n",
            "9831 Traning Loss: tensor(0.0268)\n",
            "9832 Traning Loss: tensor(0.0268)\n",
            "9833 Traning Loss: tensor(0.0268)\n",
            "9834 Traning Loss: tensor(0.0268)\n",
            "9835 Traning Loss: tensor(0.0268)\n",
            "9836 Traning Loss: tensor(0.0268)\n",
            "9837 Traning Loss: tensor(0.0268)\n",
            "9838 Traning Loss: tensor(0.0268)\n",
            "9839 Traning Loss: tensor(0.0268)\n",
            "9840 Traning Loss: tensor(0.0267)\n",
            "9841 Traning Loss: tensor(0.0267)\n",
            "9842 Traning Loss: tensor(0.0267)\n",
            "9843 Traning Loss: tensor(0.0267)\n",
            "9844 Traning Loss: tensor(0.0267)\n",
            "9845 Traning Loss: tensor(0.0267)\n",
            "9846 Traning Loss: tensor(0.0267)\n",
            "9847 Traning Loss: tensor(0.0267)\n",
            "9848 Traning Loss: tensor(0.0267)\n",
            "9849 Traning Loss: tensor(0.0267)\n",
            "9850 Traning Loss: tensor(0.0267)\n",
            "9851 Traning Loss: tensor(0.0267)\n",
            "9852 Traning Loss: tensor(0.0267)\n",
            "9853 Traning Loss: tensor(0.0267)\n",
            "9854 Traning Loss: tensor(0.0267)\n",
            "9855 Traning Loss: tensor(0.0267)\n",
            "9856 Traning Loss: tensor(0.0267)\n",
            "9857 Traning Loss: tensor(0.0267)\n",
            "9858 Traning Loss: tensor(0.0267)\n",
            "9859 Traning Loss: tensor(0.0267)\n",
            "9860 Traning Loss: tensor(0.0267)\n",
            "9861 Traning Loss: tensor(0.0267)\n",
            "9862 Traning Loss: tensor(0.0267)\n",
            "9863 Traning Loss: tensor(0.0267)\n",
            "9864 Traning Loss: tensor(0.0267)\n",
            "9865 Traning Loss: tensor(0.0267)\n",
            "9866 Traning Loss: tensor(0.0267)\n",
            "9867 Traning Loss: tensor(0.0267)\n",
            "9868 Traning Loss: tensor(0.0267)\n",
            "9869 Traning Loss: tensor(0.0267)\n",
            "9870 Traning Loss: tensor(0.0267)\n",
            "9871 Traning Loss: tensor(0.0267)\n",
            "9872 Traning Loss: tensor(0.0267)\n",
            "9873 Traning Loss: tensor(0.0267)\n",
            "9874 Traning Loss: tensor(0.0267)\n",
            "9875 Traning Loss: tensor(0.0267)\n",
            "9876 Traning Loss: tensor(0.0267)\n",
            "9877 Traning Loss: tensor(0.0267)\n",
            "9878 Traning Loss: tensor(0.0267)\n",
            "9879 Traning Loss: tensor(0.0267)\n",
            "9880 Traning Loss: tensor(0.0267)\n",
            "9881 Traning Loss: tensor(0.0267)\n",
            "9882 Traning Loss: tensor(0.0267)\n",
            "9883 Traning Loss: tensor(0.0267)\n",
            "9884 Traning Loss: tensor(0.0267)\n",
            "9885 Traning Loss: tensor(0.0267)\n",
            "9886 Traning Loss: tensor(0.0267)\n",
            "9887 Traning Loss: tensor(0.0267)\n",
            "9888 Traning Loss: tensor(0.0267)\n",
            "9889 Traning Loss: tensor(0.0267)\n",
            "9890 Traning Loss: tensor(0.0267)\n",
            "9891 Traning Loss: tensor(0.0267)\n",
            "9892 Traning Loss: tensor(0.0267)\n",
            "9893 Traning Loss: tensor(0.0267)\n",
            "9894 Traning Loss: tensor(0.0267)\n",
            "9895 Traning Loss: tensor(0.0267)\n",
            "9896 Traning Loss: tensor(0.0267)\n",
            "9897 Traning Loss: tensor(0.0267)\n",
            "9898 Traning Loss: tensor(0.0267)\n",
            "9899 Traning Loss: tensor(0.0267)\n",
            "9900 Traning Loss: tensor(0.0267)\n",
            "9901 Traning Loss: tensor(0.0267)\n",
            "9902 Traning Loss: tensor(0.0267)\n",
            "9903 Traning Loss: tensor(0.0267)\n",
            "9904 Traning Loss: tensor(0.0267)\n",
            "9905 Traning Loss: tensor(0.0267)\n",
            "9906 Traning Loss: tensor(0.0267)\n",
            "9907 Traning Loss: tensor(0.0267)\n",
            "9908 Traning Loss: tensor(0.0267)\n",
            "9909 Traning Loss: tensor(0.0267)\n",
            "9910 Traning Loss: tensor(0.0267)\n",
            "9911 Traning Loss: tensor(0.0267)\n",
            "9912 Traning Loss: tensor(0.0267)\n",
            "9913 Traning Loss: tensor(0.0267)\n",
            "9914 Traning Loss: tensor(0.0267)\n",
            "9915 Traning Loss: tensor(0.0267)\n",
            "9916 Traning Loss: tensor(0.0267)\n",
            "9917 Traning Loss: tensor(0.0267)\n",
            "9918 Traning Loss: tensor(0.0267)\n",
            "9919 Traning Loss: tensor(0.0267)\n",
            "9920 Traning Loss: tensor(0.0267)\n",
            "9921 Traning Loss: tensor(0.0267)\n",
            "9922 Traning Loss: tensor(0.0267)\n",
            "9923 Traning Loss: tensor(0.0267)\n",
            "9924 Traning Loss: tensor(0.0267)\n",
            "9925 Traning Loss: tensor(0.0267)\n",
            "9926 Traning Loss: tensor(0.0267)\n",
            "9927 Traning Loss: tensor(0.0267)\n",
            "9928 Traning Loss: tensor(0.0267)\n",
            "9929 Traning Loss: tensor(0.0267)\n",
            "9930 Traning Loss: tensor(0.0267)\n",
            "9931 Traning Loss: tensor(0.0266)\n",
            "9932 Traning Loss: tensor(0.0266)\n",
            "9933 Traning Loss: tensor(0.0266)\n",
            "9934 Traning Loss: tensor(0.0266)\n",
            "9935 Traning Loss: tensor(0.0266)\n",
            "9936 Traning Loss: tensor(0.0266)\n",
            "9937 Traning Loss: tensor(0.0266)\n",
            "9938 Traning Loss: tensor(0.0266)\n",
            "9939 Traning Loss: tensor(0.0266)\n",
            "9940 Traning Loss: tensor(0.0266)\n",
            "9941 Traning Loss: tensor(0.0266)\n",
            "9942 Traning Loss: tensor(0.0266)\n",
            "9943 Traning Loss: tensor(0.0266)\n",
            "9944 Traning Loss: tensor(0.0266)\n",
            "9945 Traning Loss: tensor(0.0266)\n",
            "9946 Traning Loss: tensor(0.0266)\n",
            "9947 Traning Loss: tensor(0.0266)\n",
            "9948 Traning Loss: tensor(0.0266)\n",
            "9949 Traning Loss: tensor(0.0266)\n",
            "9950 Traning Loss: tensor(0.0266)\n",
            "9951 Traning Loss: tensor(0.0266)\n",
            "9952 Traning Loss: tensor(0.0266)\n",
            "9953 Traning Loss: tensor(0.0266)\n",
            "9954 Traning Loss: tensor(0.0266)\n",
            "9955 Traning Loss: tensor(0.0266)\n",
            "9956 Traning Loss: tensor(0.0266)\n",
            "9957 Traning Loss: tensor(0.0266)\n",
            "9958 Traning Loss: tensor(0.0266)\n",
            "9959 Traning Loss: tensor(0.0266)\n",
            "9960 Traning Loss: tensor(0.0266)\n",
            "9961 Traning Loss: tensor(0.0266)\n",
            "9962 Traning Loss: tensor(0.0266)\n",
            "9963 Traning Loss: tensor(0.0266)\n",
            "9964 Traning Loss: tensor(0.0266)\n",
            "9965 Traning Loss: tensor(0.0266)\n",
            "9966 Traning Loss: tensor(0.0266)\n",
            "9967 Traning Loss: tensor(0.0266)\n",
            "9968 Traning Loss: tensor(0.0266)\n",
            "9969 Traning Loss: tensor(0.0266)\n",
            "9970 Traning Loss: tensor(0.0266)\n",
            "9971 Traning Loss: tensor(0.0266)\n",
            "9972 Traning Loss: tensor(0.0266)\n",
            "9973 Traning Loss: tensor(0.0266)\n",
            "9974 Traning Loss: tensor(0.0266)\n",
            "9975 Traning Loss: tensor(0.0266)\n",
            "9976 Traning Loss: tensor(0.0266)\n",
            "9977 Traning Loss: tensor(0.0266)\n",
            "9978 Traning Loss: tensor(0.0266)\n",
            "9979 Traning Loss: tensor(0.0266)\n",
            "9980 Traning Loss: tensor(0.0266)\n",
            "9981 Traning Loss: tensor(0.0266)\n",
            "9982 Traning Loss: tensor(0.0266)\n",
            "9983 Traning Loss: tensor(0.0266)\n",
            "9984 Traning Loss: tensor(0.0266)\n",
            "9985 Traning Loss: tensor(0.0266)\n",
            "9986 Traning Loss: tensor(0.0266)\n",
            "9987 Traning Loss: tensor(0.0266)\n",
            "9988 Traning Loss: tensor(0.0266)\n",
            "9989 Traning Loss: tensor(0.0266)\n",
            "9990 Traning Loss: tensor(0.0266)\n",
            "9991 Traning Loss: tensor(0.0266)\n",
            "9992 Traning Loss: tensor(0.0266)\n",
            "9993 Traning Loss: tensor(0.0266)\n",
            "9994 Traning Loss: tensor(0.0266)\n",
            "9995 Traning Loss: tensor(0.0266)\n",
            "9996 Traning Loss: tensor(0.0266)\n",
            "9997 Traning Loss: tensor(0.0266)\n",
            "9998 Traning Loss: tensor(0.0266)\n",
            "9999 Traning Loss: tensor(0.0266)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "eta66=model(torch.ones(1,1) * 6.66)\n",
        "print(eta66)"
      ],
      "metadata": {
        "id": "TXDWlgT8qFiN",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d4de52a9-8255-4554-915b-482e503b6550"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[-0.1135,  0.0201,  0.0348, -0.0004, -0.0200, -0.1064,  0.0974,  0.0363,\n",
            "         -0.2246,  0.2128, -0.0124, -0.0060,  0.1370, -0.0149, -0.0346, -0.1016,\n",
            "         -0.1165, -0.0784, -0.0353, -0.0965,  0.1081, -0.1024,  0.0937,  0.1700,\n",
            "         -0.0590,  0.1662, -0.1450,  0.1046, -0.1680,  0.1018]],\n",
            "       grad_fn=<TanhBackward0>)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        " model(torch.ones(1,1) * 6.66)@ B"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WCU9fJ34YRoK",
        "outputId": "c09354c9-2018-4af5-d64d-1946b704ddce"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[ 0.1472, -0.1720,  0.0300, -0.1068,  0.0830]], grad_fn=<MmBackward0>)"
            ]
          },
          "metadata": {},
          "execution_count": 52
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model = Net()\n"
      ],
      "metadata": {
        "id": "kbrpvA3MvQGo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(eta)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pGBaYs8aqpS7",
        "outputId": "f60d7816-df98-40e3-84d7-9df22f0dae21"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[-0.0135,  0.0086,  0.0015,  ..., -0.0110,  0.0027,  0.0128],\n",
            "        [ 0.0049, -0.0050, -0.0173,  ..., -0.0055, -0.0067,  0.0024],\n",
            "        [-0.0001,  0.0190,  0.0218,  ...,  0.0068,  0.0013,  0.0042],\n",
            "        ...,\n",
            "        [ 0.0729,  0.0256, -0.0772,  ...,  0.0140,  0.0638,  0.0152],\n",
            "        [-0.0292, -0.0009, -0.0025,  ...,  0.0282, -0.0701,  0.0235],\n",
            "        [ 0.0533,  0.0456, -0.0013,  ...,  0.0258,  0.0545,  0.0304]])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#import torch  \n",
        "#import torch.nn as nn  \n",
        "\n",
        "\n",
        "class ProjectionActivation(torch.autograd.Function):  \n",
        "    @staticmethod  \n",
        "    def forward(ctx, input, constraint_matrix):  \n",
        "        # Compute the projection of the input onto the feasible region  \n",
        "        projection = input - constraint_matrix @ (constraint_matrix.t() @ input)  \n",
        "        # Ensure that the projection satisfies the constraint  \n",
        "        #projection -= constraint_matrix @ (constraint_matrix @ projection)  \n",
        "        ctx.save_for_backward(input, constraint_matrix)  \n",
        "        return projection  \n",
        "    @staticmethod  \n",
        "    def backward(ctx, grad_output):  \n",
        "        input, constraint_matrix = ctx.saved_tensors  \n",
        "        # Compute the gradient of the projection with respect to the input  \n",
        "        grad_input = grad_output - constraint_matrix @ (constraint_matrix.t() @ grad_output)  \n",
        "        return grad_input, None \n",
        "\n",
        "        \n",
        "         \n",
        "class ConstrainedNetwork(nn.Module):  \n",
        "    def __init__(self, constraint_matrix):  \n",
        "        super(ConstrainedNetwork, self).__init__()  \n",
        "        self.fc1 = nn.Linear(1, 5)  \n",
        "        self.fc2 = nn.Linear(5, 25)\n",
        "\n",
        "        # self.fc1 = nn.Linear(1, 25)\n",
        "        # self.fc2 = nn.Linear(25, 5)  \n",
        "        # self.fc3 = nn.Linear(5, 5)\n",
        "        # self.fc4 = nn.Linear(5, 5)   \n",
        "        # self.fc5 = nn.Linear(5, 1)   \n",
        "        self.constraint_matrix = constraint_matrix  \n",
        "\n",
        "\n",
        "    def forward(self, x):  \n",
        "        x = self.fc1(x)  \n",
        "        x = ProjectionActivation.apply(x, self.constraint_matrix)  \n",
        "        x = self.fc2(x)\n",
        "        x = torch.tanh(x)\n",
        "      #  # x = ProjectionActivation.apply(x, self.constraint_matrix)  \n",
        "      #   x = self.fc3(x)\n",
        "      #   #x = ProjectionActivation.apply(x, self.constraint_matrix)  \n",
        "      #   x = self.fc4(x)\n",
        "      #   #x = ProjectionActivation.apply(x, self.constraint_matrix)  \n",
        "      #   x = self.fc5(x)  \n",
        "  \n",
        "        return x  \n",
        "# Create the constraint matrix  \n",
        "#constraint_matrix = torch.randn(25, 5)\n",
        "constraint_matrix = B \n",
        "\n",
        "\n",
        "# Create the network  \n",
        "model = ConstrainedNetwork(constraint_matrix)  \n",
        "# Generate a random input  \n",
        "input = torch.randn(25,1)  \n",
        "# Compute the output of the network  \n",
        "output = model(input)  \n",
        "# Check that the output satisfies the constraint  \n",
        "constraint_violation = constraint_matrix.t() @ output  # la dimension est bonne ici\n",
        "print(constraint_violation)  # Should be close to zero"
      ],
      "metadata": {
        "id": "GZk4Z07hctUr"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}