{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nimport matplotlib.pyplot as plt\nimport numpy as np  # linear algebra\nimport pandas as pd  # data processing, CSV file I/O (e.g. pd.read_csv)\nimport torch\nimport torch.nn as nn\nimport torch.nn.functional as F\nfrom accelerate import Accelerator\nfrom accelerate.utils import ProjectConfiguration\nfrom torch.optim import Adam\nfrom torch.optim.lr_scheduler import ReduceLROnPlateau\nfrom torch.utils.data import Dataset, DataLoader\nfrom torchvision.transforms import Normalize, Compose, ToTensor\nfrom tqdm import tqdm\n\n\n# for dirname, _, filenames in os.walk('/kaggle/input'):\n#     for filename in filenames:\n#         print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2023-09-13T10:10:03.833580Z","iopub.execute_input":"2023-09-13T10:10:03.834678Z","iopub.status.idle":"2023-09-13T10:10:03.843000Z","shell.execute_reply.started":"2023-09-13T10:10:03.834630Z","shell.execute_reply":"2023-09-13T10:10:03.841859Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"!pip install names_generator","metadata":{"execution":{"iopub.status.busy":"2023-09-13T10:10:47.505235Z","iopub.execute_input":"2023-09-13T10:10:47.505616Z","iopub.status.idle":"2023-09-13T10:10:59.673937Z","shell.execute_reply.started":"2023-09-13T10:10:47.505586Z","shell.execute_reply":"2023-09-13T10:10:59.672747Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Clean up output dir:\n!rm -rf /kaggle/working/outputs","metadata":{"execution":{"iopub.status.busy":"2023-09-13T10:10:59.676363Z","iopub.execute_input":"2023-09-13T10:10:59.676773Z","iopub.status.idle":"2023-09-13T10:11:00.788279Z","shell.execute_reply.started":"2023-09-13T10:10:59.676724Z","shell.execute_reply":"2023-09-13T10:11:00.786893Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from names_generator import generate_name","metadata":{"execution":{"iopub.status.busy":"2023-09-13T08:08:58.247575Z","iopub.execute_input":"2023-09-13T08:08:58.247954Z","iopub.status.idle":"2023-09-13T08:08:58.252725Z","shell.execute_reply.started":"2023-09-13T08:08:58.247923Z","shell.execute_reply":"2023-09-13T08:08:58.251693Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Reading and plotting data:","metadata":{}},{"cell_type":"code","source":"base_path = \"/kaggle/input/2023-flame-ai-challenge/\"\nworking_dir = \"/kaggle/working/\"\ninput_path = base_path + \"dataset/\"\n#output_path = working_dir + \"outputs/\" #bug ici on retire output \noutput_path = working_dir\n\n\n# create directories for checkpoints and logs\nlog_dir = output_path + \"logs/\"\ncheckpoint_dir = output_path + \"ckpt/\"\nif not os.path.exists(checkpoint_dir):\n    os.makedirs(checkpoint_dir)\nif not os.path.exists(log_dir):\n    os.makedirs(log_dir)\n\ntrain_df = pd.read_csv(input_path + \"train.csv\")\nval_df = pd.read_csv(input_path + \"val.csv\")\ntest_df = pd.read_csv(input_path + \"test.csv\")","metadata":{"execution":{"iopub.status.busy":"2023-09-13T10:35:58.052766Z","iopub.execute_input":"2023-09-13T10:35:58.053313Z","iopub.status.idle":"2023-09-13T10:35:58.085572Z","shell.execute_reply.started":"2023-09-13T10:35:58.053276Z","shell.execute_reply":"2023-09-13T10:35:58.084708Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# print 5 rows of pandas dataframe\ntrain_df.head()","metadata":{"execution":{"iopub.status.busy":"2023-09-13T08:10:45.104138Z","iopub.execute_input":"2023-09-13T08:10:45.104599Z","iopub.status.idle":"2023-09-13T08:10:45.129558Z","shell.execute_reply.started":"2023-09-13T08:10:45.104562Z","shell.execute_reply":"2023-09-13T08:10:45.128654Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"idx = np.random.choice(range(len(train_df)))\nprint(f\"Index:{idx}\")\ndata_path = input_path + \"flowfields/HR/train\"\nRHO_filename = train_df['rho_filename'][idx]\nUX_filename = train_df['ux_filename'][idx]\nUY_filename = train_df['uy_filename'][idx]\nUZ_filename = train_df['uz_filename'][idx]\nRHO = np.fromfile(data_path + \"/\" + RHO_filename, dtype=\"<f4\")\nUX = np.fromfile(data_path + \"/\" + UX_filename, dtype=\"<f4\")\nUY = np.fromfile(data_path + \"/\" + UY_filename, dtype=\"<f4\")\nUZ = np.fromfile(data_path + \"/\" + UZ_filename, dtype=\"<f4\")\n\nfig, axs = plt.subplots(1, 4, figsize=(20, 5))\naxs[0].imshow(RHO.reshape(128, 128), cmap='jet')\naxs[0].set_title('Density')\naxs[1].imshow(UX.reshape(128, 128), cmap='jet')\naxs[1].set_title('X-Velocity')\naxs[2].imshow(UY.reshape(128, 128), cmap='jet')\naxs[2].set_title('Y-Velocity')\naxs[3].imshow(UZ.reshape(128, 128), cmap='jet')\naxs[3].set_title('Z-Velocity')\nplt.show()\n\nHR_X = np.concatenate([RHO.reshape(128, 128, 1), UX.reshape(128, 128, 1),\n                       UY.reshape(128, 128, 1), UZ.reshape(128, 128, 1)], axis=-1)\n\n# plot LR features\n\ndata_path = input_path + \"flowfields/LR/train\"\nRHO_filename = train_df['rho_filename'][idx]\nUX_filename = train_df['ux_filename'][idx]\nUY_filename = train_df['uy_filename'][idx]\nUZ_filename = train_df['uz_filename'][idx]\nRHO = np.fromfile(data_path + \"/\" + RHO_filename, dtype=\"<f4\")\nUX = np.fromfile(data_path + \"/\" + UX_filename, dtype=\"<f4\")\nUY = np.fromfile(data_path + \"/\" + UY_filename, dtype=\"<f4\")\nUZ = np.fromfile(data_path + \"/\" + UZ_filename, dtype=\"<f4\")\n\nLR_X = np.concatenate([RHO.reshape(16, 16, 1), UX.reshape(16, 16, 1),\n                       UY.reshape(16, 16, 1), UZ.reshape(16, 16, 1)], axis=-1)\n\nfig, axs = plt.subplots(1, 4, figsize=(20, 5))\naxs[0].imshow(RHO.reshape(16, 16), cmap='jet')\naxs[0].set_title('RHO')\naxs[1].imshow(UX.reshape(16, 16), cmap='jet')\naxs[1].set_title('UX')\naxs[2].imshow(UY.reshape(16, 16), cmap='jet')\naxs[2].set_title('UY')\naxs[3].imshow(UZ.reshape(16, 16), cmap='jet')\naxs[3].set_title('UZ')\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2023-09-13T08:10:47.787127Z","iopub.execute_input":"2023-09-13T08:10:47.787498Z","iopub.status.idle":"2023-09-13T08:10:49.557409Z","shell.execute_reply.started":"2023-09-13T08:10:47.787449Z","shell.execute_reply":"2023-09-13T08:10:49.555065Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Setup PyTorch dataset and dataloaders:","metadata":{}},{"cell_type":"code","source":"class FlowFieldDataset(Dataset):\n    def __init__(self, input_path, mode):\n        assert mode in [\"train\", \"val\", \"test\"]\n        self.mode = mode\n        self.csv_file = pd.read_csv(input_path + f\"{mode}.csv\")\n        if mode == \"test\":\n            self.csv_file = pd.read_csv(input_path + f\"{mode}.csv\")\n        self.LR_path = input_path + \"flowfields/LR/\" + mode\n        self.HR_path = input_path + \"flowfields/HR/\" + mode\n\n        self.mean = np.array([0.24, 28.0, 28.0, 28.0])\n        self.std = np.array([0.068, 48.0, 48.0, 48.0])\n\n    def transform(self, x):\n        return Compose([ToTensor(), Normalize(self.mean, self.std, inplace=True)])(x)\n\n    def __len__(self):\n        return len(self.csv_file)\n\n    def __getitem__(self, idx):\n        # input\n        if self.mode == \"test\":\n            id = self.csv_file[\"id\"][idx]\n            rho_i = np.fromfile(self.LR_path + \"/\" + self.csv_file[\"rho_filename\"][idx], dtype=\"<f4\").reshape(16, 16)\n            ux_i = np.fromfile(self.LR_path + \"/\" + self.csv_file[\"ux_filename\"][idx], dtype=\"<f4\").reshape(16, 16)\n            uy_i = np.fromfile(self.LR_path + \"/\" + self.csv_file[\"uy_filename\"][idx], dtype=\"<f4\").reshape(16, 16)\n            uz_i = np.fromfile(self.LR_path + \"/\" + self.csv_file[\"uz_filename\"][idx], dtype=\"<f4\").reshape(16, 16)\n            X = np.stack([rho_i, ux_i, uy_i, uz_i], axis=2)\n            return id, self.transform(X)\n\n        rho_i = np.fromfile(self.LR_path + \"/\" + self.csv_file[\"rho_filename\"][idx], dtype=\"<f4\").reshape(16, 16)\n        ux_i = np.fromfile(self.LR_path + \"/\" + self.csv_file[\"ux_filename\"][idx], dtype=\"<f4\").reshape(16, 16)\n        uy_i = np.fromfile(self.LR_path + \"/\" + self.csv_file[\"uy_filename\"][idx], dtype=\"<f4\").reshape(16, 16)\n        uz_i = np.fromfile(self.LR_path + \"/\" + self.csv_file[\"uz_filename\"][idx], dtype=\"<f4\").reshape(16, 16)\n        # output\n        rho_o = np.fromfile(self.HR_path + \"/\" + self.csv_file[\"rho_filename\"][idx], dtype=\"<f4\").reshape(128, 128)\n        ux_o = np.fromfile(self.HR_path + \"/\" + self.csv_file[\"ux_filename\"][idx], dtype=\"<f4\").reshape(128, 128)\n        uy_o = np.fromfile(self.HR_path + \"/\" + self.csv_file[\"uy_filename\"][idx], dtype=\"<f4\").reshape(128, 128)\n        uz_o = np.fromfile(self.HR_path + \"/\" + self.csv_file[\"uz_filename\"][idx], dtype=\"<f4\").reshape(128, 128)\n        X = np.stack([rho_i, ux_i, uy_i, uz_i], axis=2)\n        Y = np.stack([rho_o, ux_o, uy_o, uz_o], axis=2)\n        return self.transform(X), self.transform(Y)\n","metadata":{"execution":{"iopub.status.busy":"2023-09-13T08:10:53.646858Z","iopub.execute_input":"2023-09-13T08:10:53.647214Z","iopub.status.idle":"2023-09-13T08:10:53.665710Z","shell.execute_reply.started":"2023-09-13T08:10:53.647183Z","shell.execute_reply":"2023-09-13T08:10:53.664773Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"num_filters = 64*4\nnum_of_residual_blocks = 30\nbatch_size = 256\n\ntrain_dataset = FlowFieldDataset(input_path=input_path, mode=\"train\")\nval_dataset = FlowFieldDataset(input_path=input_path, mode=\"val\")\ntest_dataset = FlowFieldDataset(input_path=input_path, mode=\"test\")\ntrain_dataloader = DataLoader(dataset=train_dataset, batch_size=batch_size, shuffle=True, pin_memory=True)\nval_dataloader = DataLoader(dataset=val_dataset, batch_size=batch_size, shuffle=True, pin_memory=True)\ntest_dataloader = DataLoader(dataset=test_dataset, batch_size=1, shuffle=False, pin_memory=False)","metadata":{"execution":{"iopub.status.busy":"2023-09-13T13:30:18.464636Z","iopub.execute_input":"2023-09-13T13:30:18.465323Z","iopub.status.idle":"2023-09-13T13:30:18.496152Z","shell.execute_reply.started":"2023-09-13T13:30:18.465280Z","shell.execute_reply":"2023-09-13T13:30:18.495224Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Setup model:","metadata":{}},{"cell_type":"code","source":"class ResNetBlock(nn.Module):\n    def __init__(self, in_channels, num_filters, kernel_size=3):\n        super(ResNetBlock, self).__init__()\n        self.resnet_block = torch.nn.Sequential(\n            *[\n                nn.Conv2d(num_filters, num_filters, kernel_size, padding=\"same\"),\n                nn.Conv2d(num_filters, num_filters, kernel_size, padding=\"same\"),\n            ]\n        )\n        self.input = nn.Sequential()\n\n    def forward(self, x):\n        inp = self.input(x)\n        x = self.resnet_block(x)\n        return x + inp\n\nclass Model(nn.Module):\n    def __init__(\n        self, in_channels=4, factor=2, scale=3, num_of_residual_blocks=16, num_filters=64, kernel_size=3, **kwargs\n    ):\n        super().__init__()\n        self.num_of_residual_blocks = num_of_residual_blocks\n        self.scale = scale\n        self.factor = factor\n        self.in_channels = in_channels\n        self.num_filters = num_filters\n        self.kernel_size = kernel_size\n        self.res_blocks = nn.Sequential(\n            *[\n                ResNetBlock(\n                    in_channels=in_channels,\n                    num_filters=num_filters,\n                    kernel_size=kernel_size,\n                )\n            ]\n            * num_of_residual_blocks\n        )\n        # Upsampling (factor ** 2) ** scale times : (2**2)**3 : 16*16 -> 128 * 128\n        self.upsample = nn.Sequential(\n            *[\n                nn.Conv2d(num_filters, num_filters * (factor**2), kernel_size, padding=\"same\", **kwargs),\n                nn.PixelShuffle(upscale_factor=factor),\n            ]\n            * scale\n        )\n        self.resnet_input = nn.Conv2d(in_channels, num_filters, 1, padding=\"same\")\n        self.output_layer = nn.Conv2d(num_filters, in_channels, 3, padding=\"same\")\n        self.resnet_out = nn.Conv2d(self.num_filters, self.num_filters, self.kernel_size, padding=\"same\")\n\n    def forward(self, x):\n        x = self.resnet_input(x)\n        x_res = self.res_blocks(x)\n        x_res = self.resnet_out(x_res)\n        out = x + x_res\n        out = self.upsample(out)\n        return self.output_layer(out)","metadata":{"execution":{"iopub.status.busy":"2023-09-13T13:30:21.124530Z","iopub.execute_input":"2023-09-13T13:30:21.125640Z","iopub.status.idle":"2023-09-13T13:30:21.138701Z","shell.execute_reply.started":"2023-09-13T13:30:21.125596Z","shell.execute_reply":"2023-09-13T13:30:21.137705Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Setup Accelerator and checkpointing:","metadata":{}},{"cell_type":"code","source":"ckpt_name = f\"{generate_name()}\"\nnum_epochs = 80\nlearning_rate = 0.098e-3\nhyper_parameters = {\"num_epochs\": num_epochs, \"learning_rate\":learning_rate}\n\nconfig = ProjectConfiguration(project_dir=working_dir, logging_dir=log_dir+ckpt_name)\n\n#model = Model()\nloss_fn = torch.nn.MSELoss()\noptimizer = Adam(params=model.parameters(), lr=learning_rate)\nscheduler = ReduceLROnPlateau(optimizer=optimizer)\n\naccelerator = Accelerator(log_with=\"tensorboard\", project_config=config)\naccelerator.init_trackers(log_dir+ckpt_name, config=hyper_parameters)\nmodel, optimizer, train_dataloader, val_dataloader, test_dataloader, scheduler = accelerator.prepare(\n    model, optimizer, train_dataloader, val_dataloader, test_dataloader, scheduler\n)\n\n\n# Register the LR scheduler\naccelerator.register_for_checkpointing(scheduler)\n# Save the starting state\n\naccelerator.save_state(output_dir=checkpoint_dir+ckpt_name)","metadata":{"execution":{"iopub.status.busy":"2023-09-13T13:30:23.807358Z","iopub.execute_input":"2023-09-13T13:30:23.808302Z","iopub.status.idle":"2023-09-13T13:30:23.835175Z","shell.execute_reply.started":"2023-09-13T13:30:23.808259Z","shell.execute_reply":"2023-09-13T13:30:23.834291Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"ckpt_name","metadata":{"execution":{"iopub.status.busy":"2023-09-13T12:41:00.795988Z","iopub.execute_input":"2023-09-13T12:41:00.796731Z","iopub.status.idle":"2023-09-13T12:41:00.803358Z","shell.execute_reply.started":"2023-09-13T12:41:00.796697Z","shell.execute_reply":"2023-09-13T12:41:00.802350Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Train model:","metadata":{}},{"cell_type":"code","source":"torch.nn.L1Loss","metadata":{"execution":{"iopub.status.busy":"2023-09-13T12:44:56.495953Z","iopub.execute_input":"2023-09-13T12:44:56.496342Z","iopub.status.idle":"2023-09-13T12:44:56.503707Z","shell.execute_reply.started":"2023-09-13T12:44:56.496311Z","shell.execute_reply":"2023-09-13T12:44:56.502531Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"criterion = torch.nn.L1Loss()\n\nfor step, batch in enumerate(val_dataloader):\n    inputs, targets = batch\n    outputs = model(inputs)\n    val_loss_mae = criterion(outputs, targets)\n","metadata":{"execution":{"iopub.status.busy":"2023-09-13T12:48:26.097660Z","iopub.execute_input":"2023-09-13T12:48:26.098017Z","iopub.status.idle":"2023-09-13T12:48:27.012061Z","shell.execute_reply.started":"2023-09-13T12:48:26.097988Z","shell.execute_reply":"2023-09-13T12:48:27.011044Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"val_loss_mae","metadata":{"execution":{"iopub.status.busy":"2023-09-13T12:48:40.878096Z","iopub.execute_input":"2023-09-13T12:48:40.878681Z","iopub.status.idle":"2023-09-13T12:48:40.888251Z","shell.execute_reply.started":"2023-09-13T12:48:40.878648Z","shell.execute_reply":"2023-09-13T12:48:40.887163Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"for step, batch in enumerate(val_dataloader):\n    inputs, targets = batch\n    outputs = model(inputs)\n    val_loss_mae = torch.nn.L1Loss(outputs, targets)","metadata":{"execution":{"iopub.status.busy":"2023-09-13T12:45:12.459267Z","iopub.execute_input":"2023-09-13T12:45:12.459704Z","iopub.status.idle":"2023-09-13T12:45:13.438136Z","shell.execute_reply.started":"2023-09-13T12:45:12.459669Z","shell.execute_reply":"2023-09-13T12:45:13.436846Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"\ntorch.mean(torch.abs(inputs - model(inputs)))","metadata":{"execution":{"iopub.status.busy":"2023-09-13T12:37:56.628187Z","iopub.execute_input":"2023-09-13T12:37:56.628601Z","iopub.status.idle":"2023-09-13T12:37:56.700681Z","shell.execute_reply.started":"2023-09-13T12:37:56.628570Z","shell.execute_reply":"2023-09-13T12:37:56.699410Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"progress_bar = tqdm(range(num_epochs))\ncriterion = torch.nn.L1Loss()\n\nfor epoch in range(num_epochs):\n    model.train()\n    for step, batch in enumerate(train_dataloader):\n        inputs, targets = batch\n        outputs = model(inputs)\n        loss = F.mse_loss(outputs, targets)\n        #loss_mae = criterion(outputs, targets)\n        # with torch.autograd.set_detect_anomaly(True):\n        optimizer.zero_grad()\n        accelerator.backward(loss)\n        # loss.backward(retain_graph=True)\n        optimizer.step()\n        progress_bar.set_description(f\"epoch : {epoch} | loss : {loss.detach().cpu()}\")\n        accelerator.log({\"epoch\": epoch, \"train_loss\":loss.detach().cpu()}, step=step)\n        #progress_bar.set_description(f\"epoch : {epoch} | loss_mae : {loss_mae.detach().cpu()}\")\n\n        \n    scheduler.step(loss.detach().cpu())\n    \n    model.eval()\n    for step, batch in enumerate(val_dataloader):\n        inputs, targets = batch\n        outputs = model(inputs)\n        val_loss = F.mse_loss(outputs, targets)\n        val_loss_mae = criterion(outputs, targets)\n\n        progress_bar.set_description(f\"epoch : {epoch} | val_loss_mse : {val_loss.detach().cpu()}\")\n        progress_bar.update(1)\n        accelerator.log({\"epoch\": epoch, \"val_loss_mse\":val_loss.detach().cpu()}, step=step)\n        progress_bar.set_description(f\"epoch : {epoch} | val_loss_mae : {val_loss_mae.detach().cpu()}\")\n\n        \naccelerator.end_training()","metadata":{"execution":{"iopub.status.busy":"2023-09-13T13:33:00.305078Z","iopub.execute_input":"2023-09-13T13:33:00.306109Z","iopub.status.idle":"2023-09-13T13:46:27.118449Z","shell.execute_reply.started":"2023-09-13T13:33:00.306064Z","shell.execute_reply":"2023-09-13T13:46:27.117488Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Generate submissions:","metadata":{}},{"cell_type":"code","source":"progress_bar = tqdm(range(len(test_dataloader)))\npredictions = {}\nids = []\nfor idx, batch in enumerate(test_dataloader):\n    id, inputs = batch\n    outputs = model(inputs)\n    outputs = outputs.permute(0, 2, 3, 1)\n    predictions[idx] = outputs.cpu().detach().numpy().flatten(order=\"C\").astype(np.float32)\n    ids.append(id.cpu().detach().numpy()[0])\n    progress_bar.set_description(f\"test prediction: {idx}\")\n    progress_bar.update(1)\nprogress_bar.close()\n\n\n","metadata":{"execution":{"iopub.status.busy":"2023-09-13T13:15:34.079515Z","iopub.execute_input":"2023-09-13T13:15:34.079883Z","iopub.status.idle":"2023-09-13T13:15:35.395005Z","shell.execute_reply.started":"2023-09-13T13:15:34.079853Z","shell.execute_reply":"2023-09-13T13:15:35.394044Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#qui ne tente rien n'a rien mdr\n\ncriterion = torch.nn.L1Loss()\n\nfor step, batch in enumerate(test_dataloader):\n    idinputs, targets = batch\n    outputs = model(inputs)\n    test_loss_mae = criterion(outputs, targets)\n    test_loss_mse = F.mse_loss(outputs, targets)\n\n\nprint(test_loss_mae, test_loss_mse)","metadata":{"execution":{"iopub.status.busy":"2023-09-13T13:13:47.338021Z","iopub.execute_input":"2023-09-13T13:13:47.338940Z","iopub.status.idle":"2023-09-13T13:13:47.482573Z","shell.execute_reply.started":"2023-09-13T13:13:47.338895Z","shell.execute_reply":"2023-09-13T13:13:47.481174Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model","metadata":{"execution":{"iopub.status.busy":"2023-09-13T11:27:09.842794Z","iopub.execute_input":"2023-09-13T11:27:09.843295Z","iopub.status.idle":"2023-09-13T11:27:09.853036Z","shell.execute_reply.started":"2023-09-13T11:27:09.843267Z","shell.execute_reply":"2023-09-13T11:27:09.850461Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df = pd.DataFrame.from_dict(predictions).T\ndf[\"id\"] = ids","metadata":{"execution":{"iopub.status.busy":"2023-09-13T13:16:00.371501Z","iopub.execute_input":"2023-09-13T13:16:00.371874Z","iopub.status.idle":"2023-09-13T13:16:00.427664Z","shell.execute_reply.started":"2023-09-13T13:16:00.371845Z","shell.execute_reply":"2023-09-13T13:16:00.426692Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# move id to first column\ncols = df.columns.tolist()\ncols = cols[-1:] + cols[:-1]\ndf = df[cols]","metadata":{"execution":{"iopub.status.busy":"2023-09-13T13:16:02.147856Z","iopub.execute_input":"2023-09-13T13:16:02.148214Z","iopub.status.idle":"2023-09-13T13:16:02.222071Z","shell.execute_reply.started":"2023-09-13T13:16:02.148184Z","shell.execute_reply":"2023-09-13T13:16:02.221066Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# reset index\ndf = df.reset_index(drop=True)\ndf.to_csv(f\"{output_path}{ckpt_name}.csv\", index=False) #pb ici\naccelerator.load_state(checkpoint_dir + ckpt_name)\n\n","metadata":{"execution":{"iopub.status.busy":"2023-09-13T13:16:04.309253Z","iopub.execute_input":"2023-09-13T13:16:04.310341Z","iopub.status.idle":"2023-09-13T13:16:45.602553Z","shell.execute_reply.started":"2023-09-13T13:16:04.310299Z","shell.execute_reply":"2023-09-13T13:16:45.601281Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"\nprint(\"Generating predictions\")\ndf = pd.DataFrame.from_dict(predictions).T\ndf[\"id\"] = ids\n# move id to first column\ncols = df.columns.tolist()\ncols = cols[-1:] + cols[:-1]\ndf = df[cols]\n# reset index\ndf = df.reset_index(drop=True)\ndf.to_csv(f\"{output_path}{ckpt_name}.csv\", index=False)\naccelerator.load_state(checkpoint_dir + ckpt_name)","metadata":{"execution":{"iopub.status.busy":"2023-09-13T10:36:54.648599Z","iopub.status.idle":"2023-09-13T10:36:54.649055Z","shell.execute_reply.started":"2023-09-13T10:36:54.648821Z","shell.execute_reply":"2023-09-13T10:36:54.648843Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(ckpt_name)\ndf.head()","metadata":{"execution":{"iopub.status.busy":"2023-09-13T11:52:39.000389Z","iopub.execute_input":"2023-09-13T11:52:39.000765Z","iopub.status.idle":"2023-09-13T11:52:39.029135Z","shell.execute_reply.started":"2023-09-13T11:52:39.000737Z","shell.execute_reply":"2023-09-13T11:52:39.028114Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df.shape","metadata":{"execution":{"iopub.status.busy":"2023-09-13T10:01:27.110854Z","iopub.execute_input":"2023-09-13T10:01:27.111226Z","iopub.status.idle":"2023-09-13T10:01:27.118745Z","shell.execute_reply.started":"2023-09-13T10:01:27.111196Z","shell.execute_reply":"2023-09-13T10:01:27.117718Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df.to_csv(output_path + 'my_submission.csv',index=False)\n","metadata":{"execution":{"iopub.status.busy":"2023-09-13T11:49:29.398046Z","iopub.execute_input":"2023-09-13T11:49:29.399133Z","iopub.status.idle":"2023-09-13T11:50:10.412718Z","shell.execute_reply.started":"2023-09-13T11:49:29.399098Z","shell.execute_reply":"2023-09-13T11:50:10.411695Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df.head()","metadata":{"execution":{"iopub.status.busy":"2023-09-13T11:52:31.082678Z","iopub.execute_input":"2023-09-13T11:52:31.083043Z","iopub.status.idle":"2023-09-13T11:52:31.118144Z","shell.execute_reply.started":"2023-09-13T11:52:31.083014Z","shell.execute_reply":"2023-09-13T11:52:31.117164Z"},"trusted":true},"execution_count":null,"outputs":[]}],"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}}